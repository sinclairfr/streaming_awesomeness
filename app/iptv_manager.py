# iptv_manager.py
import os
import sys
import time
import glob
import shutil
import signal
import random
import psutil
import traceback
import subprocess
from queue import Queue, Empty
from pathlib import Path
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
import threading
from file_event_handler import FileEventHandler
from ready_content_handler import ReadyContentHandler
from hls_cleaner import HLSCleaner
from client_monitor import ClientMonitor
from resource_monitor import ResourceMonitor
from iptv_channel import IPTVChannel
import signal
from ffmpeg_monitor import FFmpegMonitor
from config import (
    CONTENT_DIR,
    NGINX_ACCESS_LOG,
    SERVER_URL,
    logger,
    VIDEO_EXTENSIONS,
    CPU_THRESHOLD,
    SEGMENT_AGE_THRESHOLD,
    SUMMARY_CYCLE,
    WATCHERS_LOG_CYCLE,
    CHANNELS_STATUS_FILE,
)
from stats_collector import StatsCollector
from channel_status_manager import ChannelStatusManager
import json
import re
from log_utils import parse_access_log


class IPTVManager:
    """Gestionnaire centralis√© des cha√Ænes IPTV"""

    def __init__(self, content_dir: str, use_gpu: bool = False):
        # Assurons-nous que la valeur de USE_GPU est bien prise de l'environnement
        use_gpu_env = os.getenv("USE_GPU", "false").lower() == "true"
        
        # Initialize ready_event_handler first
        try:
            self.ready_event_handler = ReadyContentHandler(self)
            logger.info("‚úÖ ReadyContentHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing ReadyContentHandler: {e}")
            self.ready_event_handler = None
        
        # Initialize file_event_handler
        try:
            self.file_event_handler = FileEventHandler(self)
            logger.info("‚úÖ FileEventHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing FileEventHandler: {e}")
            self.file_event_handler = None
        
        # Configuration
        self.content_dir = content_dir
        self.use_gpu = use_gpu or use_gpu_env
        self.channels = {}
        self.channel_ready_status = {}
        self.log_path = NGINX_ACCESS_LOG
        
        # Initialisation de last_position pour le suivi des logs
        self.last_position = 0
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                f.seek(0, 2)
                self.last_position = f.tell()
                logger.info(f"üìù Position initiale de lecture des logs: {self.last_position} bytes")
        
        # Initialisation des verrous et structures de donn√©es
        self.lock = threading.Lock()
        self._active_watchers = {}
        self.watchers = {}
        
        # Verrou et cooldown pour les scans
        self.scan_lock = threading.Lock()
        self.last_scan_time = 0
        self.scan_cooldown = 60
        self.scan_queue = Queue()
        self.failing_channels = set()

        # Queue pour les cha√Ænes √† initialiser en parall√®le
        self.channel_init_queue = Queue()
        self.max_parallel_inits = 5
        self.active_init_threads = 0
        self.init_threads_lock = threading.Lock()

        # Initialize channel status manager first
        self.channel_status = None  # Initialiser √† None
        self.init_channel_status_manager()

        # Initialisation des composants
        try:
            self.stats_collector = StatsCollector()
            logger.info("üìä StatsCollector initialis√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation StatsCollector: {e}")
            self.stats_collector = None

        # Initialize client monitor
        try:
            self.client_monitor = ClientMonitor(
                log_path=self.log_path,
                update_watchers_callback=self.update_watchers,
                manager=self,
                stats_collector=self.stats_collector
            )
            self.client_monitor.start()
            logger.info("üëÅÔ∏è ClientMonitor initialis√© et d√©marr√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation ClientMonitor: {e}")
            self.client_monitor = None

        # Moniteur FFmpeg
        self.ffmpeg_monitor = FFmpegMonitor(self.channels)
        self.ffmpeg_monitor.start()

        # On initialise le nettoyeur HLS avec le bon chemin
        self.hls_cleaner = HLSCleaner("/app/hls")
        # Le nettoyage initial sera fait dans _clean_startup

        # Initialisation des threads
        self.stop_scan_thread = threading.Event()
        self.stop_init_thread = threading.Event()
        self.stop_watchers = threading.Event()
        self.stop_status_update = threading.Event()

        # Thread de surveillance des watchers
        self.watchers_thread = threading.Thread(
            target=self._watchers_loop,
            daemon=True
        )

        # Thread de scan unifi√©
        self.scan_thread = threading.Thread(
            target=self._scan_worker,
            daemon=True
        )

        # Thread d'initialisation des cha√Ænes
        self.channel_init_thread = threading.Thread(
            target=self._process_channel_init_queue,
            daemon=True
        )

        # Thread de nettoyage des watchers inactifs
        self.cleanup_thread = threading.Thread(
            target=self._cleanup_thread_loop,
            daemon=True
        )

        # Thread de mise √† jour des statuts
        self.status_update_thread = threading.Thread(
            target=self._status_update_loop,
            daemon=True
        )

        logger.info("Initialisation du gestionnaire IPTV am√©lior√©")
        self._clean_startup()

        # Observer
        self.observer = Observer()
        event_handler = FileEventHandler(self)
        self.observer.schedule(event_handler, self.content_dir, recursive=True)
        logger.info(f"üëÅÔ∏è Observer configur√© pour surveiller {self.content_dir} en mode r√©cursif")

        # D√©marrage des threads dans l'ordre correct
        self.scan_thread.start()
        logger.info("üîÑ Thread de scan unifi√© d√©marr√©")

        self.channel_init_thread.start()
        logger.info("üîÑ Thread d'initialisation des cha√Ænes d√©marr√©")

        self.cleanup_thread.start()
        logger.info("üßπ Thread de nettoyage des watchers d√©marr√©")

        self.watchers_thread.start()
        logger.info("üë• Thread de surveillance des watchers d√©marr√©")

        self.status_update_thread.start()
        logger.info("üìä Thread de mise √† jour des statuts d√©marr√©")

        # Force un scan initial
        logger.info("üîç For√ßage du scan initial des cha√Ænes...")
        self._do_scan(force=True)
        logger.info("‚úÖ Scan initial termin√©")

    def request_scan(self, force: bool = False):
        """Demande un scan en le mettant dans la queue"""
        self.scan_queue.put(force)
        logger.debug("Scan demand√©" + (" (forc√©)" if force else ""))

    def _scan_worker(self):
        """Thread qui g√®re les scans de mani√®re centralis√©e"""
        logger.info("üîç D√©marrage du thread de scan worker")
        while not self.stop_scan_thread.is_set():
            try:
                # Attendre une demande de scan ou le d√©lai p√©riodique
                try:
                    force = self.scan_queue.get(timeout=30)  # 30 secondes de d√©lai par d√©faut
                except Empty:  # Fixed: Using imported Empty instead of Queue.Empty
                    force = False  # Scan p√©riodique normal

                current_time = time.time()
                
                # V√©rifier le cooldown sauf si scan forc√©
                if not force and (current_time - self.last_scan_time) < 15:
                    logger.debug("‚è≠Ô∏è Scan ignor√© (cooldown)")
                    continue

                with self.scan_lock:
                    logger.info("üîç D√©marrage du scan" + (" forc√©" if force else ""))
                    self._do_scan(force)
                    self.last_scan_time = time.time()

            except Exception as e:
                logger.error(f"‚ùå Erreur dans le thread de scan: {e}")
                time.sleep(5)

    def _do_scan(self, force: bool = False):
        """Effectue le scan r√©el des cha√Ænes"""
        try:
            content_path = Path(self.content_dir)
            if not content_path.exists():
                logger.error(f"Le dossier {content_path} n'existe pas!")
                return

            # Scan des dossiers de cha√Ænes
            channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
            logger.info(f"üìÇ {len(channel_dirs)} dossiers de cha√Ænes trouv√©s: {[d.name for d in channel_dirs]}")
            
            # Pour suivre les nouvelles cha√Ænes d√©tect√©es
            new_channels = []

            for channel_dir in channel_dirs:
                channel_name = channel_dir.name
                
                if channel_name in self.channels:
                    # Mise √† jour des cha√Ænes existantes
                    if force:
                        logger.info(f"üîÑ Rafra√Æchissement de la cha√Æne {channel_name}")
                        channel = self.channels[channel_name]
                        if hasattr(channel, "_scan_videos"):
                            channel._scan_videos()
                    continue

                # Nouvelle cha√Æne d√©tect√©e
                logger.info(f"‚úÖ Nouvelle cha√Æne trouv√©e: {channel_name}")
                # --- Add Placeholder ---
                with self.scan_lock: # Use the same lock as _init_channel_async
                    if channel_name not in self.channels: # Double check inside lock
                         self.channels[channel_name] = None # Add placeholder
                # --- End Add Placeholder ---
                new_channels.append(channel_name)
                
                # Si c'est un scan forc√©, on initialise imm√©diatement
                if force:
                    logger.info(f"üöÄ Initialisation forc√©e de la cha√Æne {channel_name}")
                    self._init_channel_async({
                        "name": channel_name,
                        "dir": channel_dir,
                        "from_queue": False  # Indique que ce n'est pas de la queue
                    })
                else:
                    # Sinon on met dans la queue pour initialisation diff√©r√©e
                    logger.info(f"‚è≥ Mise en file d'attente pour initialisation de la cha√Æne {channel_name}")
                    self.channel_init_queue.put({
                        "name": channel_name,
                        "dir": channel_dir,
                        "from_queue": True  # Indique que c'est de la queue
                    })

            # Mise √† jour de la playlist ma√Ætre
            self._update_master_playlist()
            
            # NOUVEAU: D√©marrer les streams des nouvelles cha√Ænes apr√®s un d√©lai pour laisser le temps √† l'initialisation
            if new_channels:
                logger.info(f"üöÄ Planification du d√©marrage diff√©r√© pour les nouvelles cha√Ænes: {new_channels}")
                def delayed_start_streams():
                    # Attendre 10 secondes pour laisser le temps aux cha√Ænes de s'initialiser
                    time.sleep(10)
                    for channel_name in new_channels:
                        if channel_name in self.channels:
                            channel = self.channels[channel_name]
                            if hasattr(channel, "ready_for_streaming") and channel.ready_for_streaming:
                                logger.info(f"[{channel_name}] üöÄ D√©marrage diff√©r√© du stream apr√®s scan")
                                if hasattr(channel, "start_stream"):
                                    success = channel.start_stream()
                                    if success:
                                        logger.info(f"[{channel_name}] ‚úÖ Stream d√©marr√© avec succ√®s apr√®s scan diff√©r√©")
                                    else:
                                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage diff√©r√© du stream")
                                else:
                                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Channel does not have start_stream method")
                            else:
                                logger.warning(f"[{channel_name}] ‚ö†Ô∏è La cha√Æne n'est pas pr√™te pour le streaming ou ready_for_streaming n'est pas d√©fini")
                        else:
                            logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne non trouv√©e dans le dictionnaire des cha√Ænes pour le d√©marrage diff√©r√©")
                
                # D√©marrer dans un thread s√©par√© pour ne pas bloquer
                threading.Thread(target=delayed_start_streams, daemon=True).start()
                
        except Exception as e:
            logger.error(f"‚ùå Erreur scan des cha√Ænes: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        self.stop_scan_thread.set()
        self.stop_init_thread.set()
        
        if hasattr(self, 'scan_thread'):
            self.scan_thread.join(timeout=5)
            
        if hasattr(self, 'channel_init_thread'):
            self.channel_init_thread.join(timeout=5)

        # Arr√™t des autres composants...

    def _get_active_watcher_ips(self, channel_name):
        """R√©cup√®re la liste des IPs actives pour une cha√Æne"""
        with self.lock:
            # Si la cha√Æne est dans notre dictionnaire, renvoyer les IPs actifs
            if channel_name in self._active_watchers:
                return self._active_watchers[channel_name]
            
            # Sinon, tenter de r√©cup√©rer depuis client_monitor
            if hasattr(self, 'client_monitor') and hasattr(self.client_monitor, 'watchers'):
                active_ips = set()
                for ip, data in self.client_monitor.watchers.items():
                    if data.get("current_channel") == channel_name:
                        active_ips.add(ip)
                return active_ips
                
            # Aucune information trouv√©e
            return set()

    def update_watchers(self, channel_name: str, watcher_count: int, path: str = "/hls/"):
        """Met √† jour le nombre de watchers pour une cha√Æne"""
        try:
            # Ignorer les mises √† jour si le channel_name ressemble √† une IP
            if channel_name and any(c.isdigit() for c in channel_name.split('.')):
                logger.debug(f"‚è≠Ô∏è Ignor√© mise √† jour watchers pour IP: {channel_name}")
                return

            # --- Modified Check ---
            if channel_name not in self.channels:
                logger.warning(f"‚ö†Ô∏è Tentative de mise √† jour des watchers pour une cha√Æne vraiment inexistante (pas scann√©e): {channel_name}")
                return
                
            channel = self.channels.get(channel_name)
            if channel is None:
                logger.debug(f"‚è≥ Cha√Æne {channel_name} en cours d'initialisation, mise √† jour des watchers diff√©r√©e")
                return
            # --- End Modified Check ---

            # Mise √† jour du compteur de watchers
            # channel = self.channels[channel_name] # No longer needed, already fetched
            old_count = getattr(channel, 'watchers_count', 0)
            
            # Toujours mettre √† jour le timestamp de dernier watcher
            channel.last_watcher_time = time.time()
            
            # Le nombre a-t-il r√©ellement chang√©?
            count_changed = old_count != watcher_count
            
            # Mettre √† jour le compteur seulement si n√©cessaire
            if count_changed:
                # Stocker l'heure du dernier changement de watchers
                if not hasattr(channel, 'last_watcher_change_time'):
                    channel.last_watcher_change_time = time.time()
                else:
                    channel.last_watcher_change_time = time.time()
                    
                # Mettre √† jour le compteur
                channel.watchers_count = watcher_count
                
                # Log pour les changements significatifs
                logger.info(f"[{channel_name}] üëÅÔ∏è Changement watchers: {old_count} ‚Üí {watcher_count}")
                
                # Log plus d√©taill√© pour diagnostic
                logger.debug(f"[{channel_name}] üîç √âtat des watchers actuels: {self._active_watchers.get(channel_name, set())}")
            else:
                # Mettre √† jour sans log si pas de changement
                channel.watchers_count = watcher_count

            # Forcer une mise √† jour imm√©diate du statut
            if hasattr(self, "channel_status") and self.channel_status is not None:
                is_active = bool(getattr(channel, "ready_for_streaming", False))
                is_streaming = bool(channel.process_manager.is_running() if hasattr(channel, "process_manager") else False)
                
                # R√©cup√©rer la liste des watchers actifs
                active_watchers_set = self._active_watchers.get(channel_name, set())
                active_watchers_list = list(active_watchers_set)
                
                # R√©cup√©rer l'√©tat pr√©c√©dent pour comparaison
                previous_status = self.channel_status.channels.get(channel_name, {})
                previous_watchers_set = set(previous_status.get('watchers', []))
                previous_viewer_count = previous_status.get('viewers', 0)
                
                # V√©rifier si la liste des watchers ou le compteur a chang√©
                watchers_changed = active_watchers_set != previous_watchers_set
                count_changed_now = watcher_count != previous_viewer_count # Re-check count against stored status

                # Mettre √† jour le statut seulement si n√©cessaire
                if watchers_changed or count_changed_now:
                    logger.debug(f"[{channel_name}] üîÑ Mise √† jour du statut: Watchers chang√©={watchers_changed}, Compteur chang√©={count_changed_now}")
                    update_successful = self.channel_status.update_channel(
                        channel_name, 
                        is_active=is_active,
                        viewers=watcher_count,  
                        streaming=is_streaming,
                        watchers=active_watchers_list
                    )
                    if not update_successful:
                        logger.warning(f"[{channel_name}] ‚ö†Ô∏è √âchec de la mise √† jour du statut via ChannelStatusManager")
                else:
                     logger.debug(f"[{channel_name}] ‚è≠Ô∏è Statut inchang√©, mise √† jour ignor√©e")

            # V√©rifier si la cha√Æne est arr√™t√©e mais devrait √™tre active
            if watcher_count > 0 and not channel.process_manager.is_running():
                # V√©rifier quand √©tait le dernier red√©marrage pour √©viter les red√©marrages trop fr√©quents
                last_restart_time = getattr(channel, 'last_restart_time', 0)
                current_time = time.time()
                restart_delay = 30  # 30 secondes minimum entre tentatives de red√©marrage
                
                if current_time - last_restart_time > restart_delay:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne arr√™t√©e avec {watcher_count} watchers actifs")
                    
                    if channel.ready_for_streaming:
                        logger.info(f"[{channel_name}] üîÑ Red√©marrage automatique de la cha√Æne")
                        
                        # Marquer l'heure du red√©marrage
                        channel.last_restart_time = current_time
                        
                        # Tenter le red√©marrage avec un retardateur pour √©viter les red√©marrages en cascade
                        def delayed_restart():
                            time.sleep(1.5)  # Petit d√©lai pour √©viter les d√©marrages simultan√©s
                            result = channel.start_stream()
                            if result:
                                logger.info(f"[{channel_name}] ‚úÖ Cha√Æne red√©marr√©e avec succ√®s")
                            else:
                                logger.error(f"[{channel_name}] ‚ùå √âchec du red√©marrage de la cha√Æne")
                        
                        restart_thread = threading.Thread(target=delayed_restart)
                        restart_thread.daemon = True
                        restart_thread.start()
                    else:
                        logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne non pr√™te pour le streaming")
                else:
                    logger.debug(f"[{channel_name}] ‚è≥ D√©lai min. entre red√©marrages pas √©coul√© ({current_time - last_restart_time:.1f}s < {restart_delay}s)")

            # Mise √† jour des statistiques seulement en cas de watchers actifs
            if hasattr(self, 'stats_collector') and self.stats_collector and watcher_count > 0:
                # Mise √† jour du temps de visionnage pour chaque IP active
                if active_watchers := self._active_watchers.get(channel_name, set()):
                    for ip in active_watchers:
                        self.stats_collector.add_watch_time(channel_name, ip, 5.0)
                    
                    # Ne pas sauvegarder les stats √† chaque mise √† jour pour √©viter la surcharge d'I/O
                    if count_changed:
                        self.stats_collector.save_stats()
                        self.stats_collector.save_user_stats()

        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour watchers pour {channel_name}: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _reset_channel_statuses(self):
        """Reset all channel statuses to inactive with zero viewers at startup"""
        if hasattr(self, "channel_status"):
            for name in self.channels:
                self.channel_status.update_channel(
                    name,
                    is_active=False,
                    viewers=0,
                    streaming=False
                )
            logger.info("üîÑ All channel statuses reset at startup")

    def _log_channels_summary(self):
        """G√©n√®re et affiche un r√©capitulatif de l'√©tat des cha√Ænes"""
        try:
            if not self.channels:
                logger.info("üìä Aucune cha√Æne disponible pour le r√©capitulatif")
                return

            # Organiser les cha√Ænes par √©tat
            active_with_viewers = []  # Cha√Ænes actives avec viewers
            active_without_viewers = []  # Cha√Ænes actives sans viewers
            stopped_channels = []  # Cha√Ænes arr√™t√©es

            for name, channel in sorted(self.channels.items()):
                watchers_count = getattr(channel, "watchers_count", 0)
                is_streaming = (
                    channel.process_manager.is_running()
                    if hasattr(channel, "process_manager")
                    else False
                )

                channel_info = {
                    "name": name,
                    "watchers": watchers_count,
                    "streaming": is_streaming,
                    "last_activity": getattr(channel, "last_watcher_time", 0),
                }

                if is_streaming:  # Si la cha√Æne est en streaming
                    if watchers_count > 0:  # Et qu'elle a des viewers
                        active_with_viewers.append(channel_info)
                    else:  # En streaming mais sans viewers
                        active_without_viewers.append(channel_info)
                else:  # Cha√Æne arr√™t√©e
                    stopped_channels.append(channel_info)

            # Construire le r√©capitulatif
            summary_lines = ["üìä R√âCAPITULATIF DES CHA√éNES:"]

            # Afficher les cha√Ænes actives avec viewers
            if active_with_viewers:
                active_parts = []
                for ch in active_with_viewers:
                    active_parts.append(f"üü¢ {ch['name']}: {ch['watchers']} viewers")

                summary_lines.append(
                    "CHA√éNES AVEC VIEWERS: " + " | ".join(active_parts)
                )
            else:
                summary_lines.append("CHA√éNES AVEC VIEWERS: Aucune")

            # Afficher les cha√Ænes actives sans viewers
            if active_without_viewers:
                inactive_parts = []
                for ch in active_without_viewers[
                    :5
                ]:  # Limiter √† 5 pour √©viter des logs trop longs
                    inactive_parts.append(f"{ch['name']}")

                remaining = len(active_without_viewers) - 5
                if remaining > 0:
                    inactive_parts.append(f"et {remaining} autres")

                summary_lines.append(
                    f"CHA√éNES ACTIVES SANS VIEWERS: {len(active_without_viewers)} ({', '.join(inactive_parts)})"
                )

            # Nombre total de cha√Ænes arr√™t√©es
            if stopped_channels:
                stopped_names = [ch['name'] for ch in stopped_channels]
                summary_lines.append(f"CHA√éNES ARR√äT√âES: {len(stopped_channels)} ({', '.join(stopped_names)})")
            else:
                summary_lines.append("CHA√éNES ARR√äT√âES: Aucune")

            # Stats globales
            total_viewers = sum(ch["watchers"] for ch in active_with_viewers)
            total_streams = len(active_with_viewers) + len(active_without_viewers)
            summary_lines.append(
                f"TOTAL: {total_viewers} viewers sur {total_streams} streams actifs ({len(self.channels)} cha√Ænes)"
            )

            # Afficher le r√©capitulatif
            logger.info("\n".join(summary_lines))

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©capitulatif: {e}")

    def _clean_startup(self):
        """Nettoyage initial optimis√©"""
        try:
            logger.info("üßπ Nettoyage initial...")
            
            # Nettoyage des dossiers HLS
            self.hls_cleaner.initial_cleanup()
            self.hls_cleaner.start()
            logger.info("‚úÖ Nettoyage initial termin√©")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du nettoyage initial: {e}")

    def scan_channels(self, force: bool = False, initial: bool = False):
        """
        Scanne le contenu pour d√©tecter les nouveaux dossiers (cha√Ænes).
        Version am√©lior√©e avec limitation de fr√©quence et debug pour isolation du probl√®me
        """
        # Limiter la fr√©quence des scans
        current_time = time.time()
        scan_cooldown = 30  # 30s entre scans complets (sauf si force=True)

        if (
            not force
            and not initial
            and hasattr(self, "last_scan_time")
            and current_time - self.last_scan_time < scan_cooldown
        ):
            logger.debug(
                f"Scan ignor√©: dernier scan il y a {current_time - self.last_scan_time:.1f}s"
            )
            return

        setattr(self, "last_scan_time", current_time)

        with self.scan_lock:
            try:
                content_path = Path(self.content_dir)
                if not content_path.exists():
                    logger.error(f"Le dossier {content_path} n'existe pas!")
                    return

                # Debugging: log the directory and its existence
                logger.info(f"üîç Scanning content directory: {content_path} (exists: {content_path.exists()})")
                
                # Get all subdirectories 
                channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
                
                # Debug the found directories
                logger.info(f"üìÇ Found {len(channel_dirs)} potential channel directories: {[d.name for d in channel_dirs]}")

                logger.info(f"üì° Scan des cha√Ænes disponibles...")
                for channel_dir in channel_dirs:
                    channel_name = channel_dir.name
                    
                    # Debug: check if this directory should be a channel
                    logger.debug(f"Examining directory: {channel_name} ({channel_dir})")

                    if channel_name in self.channels:
                        # Si la cha√Æne existe d√©j√†, on v√©rifie son √©tat
                        if force:
                            logger.info(
                                f"üîÑ Rafra√Æchissement de la cha√Æne {channel_name}"
                            )
                            channel = self.channels[channel_name]
                            if hasattr(channel, "refresh_videos"):
                                channel.refresh_videos()
                        else:
                            logger.info(f"‚úÖ Cha√Æne existante: {channel_name}")
                        continue

                    logger.info(f"‚úÖ Nouvelle cha√Æne trouv√©e: {channel_name}")

                    # Ajoute la cha√Æne √† la queue d'initialisation
                    self.channel_init_queue.put(
                        {"name": channel_name, "dir": channel_dir}
                    )

                logger.info(f"üì° Scan termin√©, {len(channel_dirs)} cha√Ænes identifi√©es")

            except Exception as e:
                logger.error(f"Erreur scan des cha√Ænes: {e}")
                import traceback
                logger.error(traceback.format_exc())

    def ensure_hls_directory(self, channel_name: str = None):
        """Cr√©e et configure les dossiers HLS avec les bonnes permissions"""
        try:
            # Dossier HLS principal
            base_hls = Path("/app/hls")
            if not base_hls.exists():
                logger.info("üìÇ Cr√©ation du dossier HLS principal...")
                base_hls.mkdir(parents=True, exist_ok=True)
                os.chmod(base_hls, 0o777)

            # Dossier sp√©cifique √† une cha√Æne si demand√©
            if channel_name:
                channel_hls = base_hls / channel_name
                if not channel_hls.exists():
                    logger.info(f"üìÇ Cr√©ation du dossier HLS pour {channel_name}")
                    channel_hls.mkdir(parents=True, exist_ok=True)
                    os.chmod(channel_hls, 0o777)
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation dossiers HLS: {e}")

    def _manage_master_playlist(self):
        """G√®re la mise √† jour p√©riodique de la playlist principale"""
        logger.info("üîÑ D√©marrage thread de mise √† jour de la playlist principale")
        
        # S'assurer que la playlist existe avec des permissions correctes d√®s le d√©part
        playlist_path = os.path.abspath("/app/hls/playlist.m3u")
        if not os.path.exists(playlist_path):
            try:
                # Cr√©er un contenu minimal
                with open(playlist_path, "w", encoding="utf-8") as f:
                    f.write("#EXTM3U\n")
                os.chmod(playlist_path, 0o777)  # Permissions larges pour le debug
                logger.info(f"‚úÖ Playlist initiale cr√©√©e: {playlist_path}")
            except Exception as e:
                logger.error(f"‚ùå Erreur cr√©ation playlist initiale: {e}")
        
        # Mise √† jour imm√©diate au d√©marrage
        try:
            self._update_master_playlist()
            logger.info("‚úÖ Premi√®re mise √† jour de la playlist effectu√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur premi√®re mise √† jour playlist: {e}")
        
        # Mises √† jour fr√©quentes au d√©marrage
        for _ in range(3):
            try:
                # Attendre un peu entre les mises √† jour
                time.sleep(10)
                self._update_master_playlist()
                logger.info("‚úÖ Mise √† jour de d√©marrage de la playlist effectu√©e")
            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour playlist de d√©marrage: {e}")
        
        # Continuer avec des mises √† jour p√©riodiques
        while True:
            try:
                self._update_master_playlist()
                time.sleep(60)  # On attend 60s avant la prochaine mise √† jour
            except Exception as e:
                logger.error(f"‚ùå Erreur maj master playlist: {e}")
                logger.error(traceback.format_exc())
                time.sleep(60)  # On attend m√™me en cas d'erreur

    def _update_master_playlist(self):
        """Effectue la mise √† jour de la playlist principale"""
        playlist_path = os.path.abspath("/app/hls/playlist.m3u")
        logger.info(f"üîÑ Master playlist maj.: {playlist_path}")
        
        try:
            # On sauvegarde d'abord le contenu actuel au cas o√π
            existing_content = "#EXTM3U\n"
            if os.path.exists(playlist_path) and os.path.getsize(playlist_path) > 0:
                try:
                    with open(playlist_path, "r", encoding="utf-8") as f:
                        existing_content = f.read()
                    logger.info(f"‚úÖ Contenu actuel sauvegard√©: {len(existing_content)} octets")
                except Exception as e:
                    logger.error(f"‚ùå Erreur lecture playlist existante: {e}")
            
            # Pr√©paration du nouveau contenu
            content = "#EXTM3U\n"

            # Re-v√©rifie chaque cha√Æne pour confirmer qu'elle est pr√™te
            with self.scan_lock:
                ready_channels = []
                
                # M√©thode 1: V√©rification directe des fichiers dans le dossier HLS
                hls_dir = Path("/app/hls")
                for channel_dir in hls_dir.iterdir():
                    if channel_dir.is_dir() and channel_dir.name != "stats" and (channel_dir / "playlist.m3u8").exists():
                        channel_name = channel_dir.name
                        # V√©rifier qu'il y a au moins un segment
                        segments = list(channel_dir.glob("segment_*.ts"))
                        if segments:
                            ready_channels.append((channel_name, None))
                            logger.info(f"[{channel_name}] ‚úÖ Cha√Æne pr√™te (v√©rification directe HLS)")
                
                # M√©thode 2: V√©rification bas√©e sur les fichiers dans ready_to_stream
                if not ready_channels:
                    for name, channel in sorted(self.channels.items()):
                        # V√©rification directe des fichiers
                        ready_dir = Path(channel.video_dir) / "ready_to_stream"
                        has_videos = (
                            list(ready_dir.glob("*.mp4")) if ready_dir.exists() else []
                        )

                        # Mise √† jour du statut si n√©cessaire
                        if has_videos:
                            logger.info(f"[{name}] ‚úÖ Cha√Æne pr√™te avec {len(has_videos)} vid√©os")
                            self.channel_ready_status[name] = True
                            channel.ready_for_streaming = True
                            ready_channels.append((name, channel))
                        else:
                            logger.warning(f"[{name}] ‚ö†Ô∏è Cha√Æne non pr√™te (aucune vid√©o)")
                            self.channel_ready_status[name] = False
                            channel.ready_for_streaming = False

            # √âcriture des cha√Ænes pr√™tes
            server_url = os.getenv("SERVER_URL", "192.168.10.183")
            if ready_channels:
                for name, _ in ready_channels:
                    content += f'#EXTINF:-1 tvg-id="{name}" tvg-name="{name}",{name}\n'
                    content += f"http://{server_url}/hls/{name}/playlist.m3u8\n"
            else:
                # Si aucune cha√Æne n'est pr√™te, ajouter un commentaire
                content += "# Aucune cha√Æne active pour le moment\n"
                logger.warning("‚ö†Ô∏è Aucune cha√Æne active d√©tect√©e pour la playlist")
            
            # Log du contenu qui sera √©crit
            logger.info(f"üìù Contenu de la playlist √† √©crire:\n{content}")
            
            # √âcrire dans un fichier temporaire d'abord
            temp_path = f"{playlist_path}.tmp"
            with open(temp_path, "w", encoding="utf-8") as f:
                f.write(content)
            
            # V√©rifier que le fichier temporaire a √©t√© cr√©√© correctement
            if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
                # Remplacer l'ancien fichier
                os.replace(temp_path, playlist_path)
                logger.info(f"‚úÖ Playlist remplac√©e avec succ√®s")
            else:
                logger.error(f"‚ùå Fichier temporaire vide ou non cr√©√©: {temp_path}")
                # Ne pas remplacer l'ancien fichier si le temporaire est vide
                raise Exception("Fichier temporaire vide ou non cr√©√©")
            
            # V√©rifier permissions et que le fichier a bien √©t√© √©crit
            os.chmod(playlist_path, 0o777)  # Permissions larges pour le debug
            
            # V√©rification que le fichier a √©t√© correctement √©crit
            if os.path.exists(playlist_path):
                size = os.path.getsize(playlist_path)
                logger.info(f"‚úÖ Playlist √©crite: {playlist_path}, taille: {size} octets")
                
                # Lire le contenu pour v√©rification
                with open(playlist_path, "r", encoding="utf-8") as f:
                    read_content = f.read()
                    if read_content == content:
                        logger.info("‚úÖ Contenu v√©rifi√©, identique √† ce qui devait √™tre √©crit")
                    else:
                        logger.error("‚ùå Contenu lu diff√©rent du contenu qui devait √™tre √©crit")
                        logger.error(f"üìÑ Contenu lu:\n{read_content}")
                        # Essayer d'√©crire directement
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write(content)
                        logger.info("üîÑ Tentative d'√©criture directe effectu√©e")
            else:
                logger.error(f"‚ùå Fichier non trouv√© apr√®s √©criture: {playlist_path}")
                # Recr√©er avec le contenu existant
                with open(playlist_path, "w", encoding="utf-8") as f:
                    f.write(existing_content)
                logger.warning("üîÑ Restauration du contenu pr√©c√©dent")

            logger.info(
                f"‚úÖ Playlist mise √† jour avec {len(ready_channels)} cha√Ænes pr√™tes sur {len(self.channels)} totales"
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour playlist: {e}")
            logger.error(traceback.format_exc())
            
            # En cas d'erreur, v√©rifier si le fichier existe toujours
            if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                # Restaurer le contenu pr√©c√©dent s'il existe
                if existing_content and len(existing_content) > 8:  # Plus que juste "#EXTM3U\n"
                    try:
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write(existing_content)
                        os.chmod(playlist_path, 0o777)
                        logger.info("‚úÖ Contenu pr√©c√©dent restaur√©")
                    except Exception as restore_e:
                        logger.error(f"‚ùå Erreur restauration contenu: {restore_e}")
                
                # Si pas de contenu pr√©c√©dent ou erreur, cr√©er une playlist minimale
                if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                    try:
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write("#EXTM3U\n# Playlist de secours\n")
                        os.chmod(playlist_path, 0o777)
                        logger.info("‚úÖ Playlist minimale cr√©√©e en fallback")
                    except Exception as inner_e:
                        logger.error(f"‚ùå √âchec cr√©ation playlist minimale: {inner_e}")
        
        # V√©rifier et d√©marrer les streams des cha√Ænes pr√™tes qui ne sont pas encore en cours d'ex√©cution
        for name, channel in ready_channels:
            if channel and hasattr(channel, "process_manager") and not channel.process_manager.is_running():
                logger.info(f"[{name}] üöÄ D√©marrage automatique du stream apr√®s mise √† jour de la playlist")
                if hasattr(channel, "start_stream"):
                    try:
                        # D√©marrer directement sans thread pour s'assurer que √ßa fonctionne
                        success = channel.start_stream()
                        if success:
                            logger.info(f"[{name}] ‚úÖ Stream d√©marr√© avec succ√®s")
                        else:
                            logger.error(f"[{name}] ‚ùå √âchec du d√©marrage du stream")
                    except Exception as e:
                        logger.error(f"[{name}] ‚ùå Erreur lors du d√©marrage du stream: {e}")

    def cleanup_manager(self):
        """Cleanup everything before shutdown"""
        logger.info("D√©but du nettoyage...")
        
        # Stop all threads first
        self.stop_scan_thread.set()
        self.stop_init_thread.set()
        self.stop_watchers.set()
        self.stop_status_update.set()

        # Stop components that might be None
        try:
            if self.channel_status is not None:
                self.channel_status.stop()
                logger.info("‚úÖ Channel status manager stopped")
        except:
            pass

        try:
            if self.stats_collector is not None:
                self.stats_collector.stop()
                logger.info("üìä StatsCollector arr√™t√©")
        except:
            pass

        try:
            if self.hls_cleaner is not None:
                self.hls_cleaner.stop_cleaner()
                logger.info("üßπ HLS Cleaner arr√™t√©")
        except:
            pass

        # Join threads with timeout
        threads_to_join = [
            (self.channel_init_thread, "Channel init thread"),
            (self.scan_thread, "Scan thread"),
            (self.watchers_thread, "Watchers thread"),
            (self.cleanup_thread, "Cleanup thread"),
            (self.status_update_thread, "Status update thread")
        ]

        for thread, name in threads_to_join:
            try:
                if thread and thread.is_alive():
                    thread.join(timeout=5)
                    logger.info(f"‚úÖ {name} stopped")
            except:
                pass

        # Stop observers
        try:
            if hasattr(self, "observer"):
                self.observer.stop()
                self.observer.join(timeout=5)
                logger.info("‚úÖ Main observer stopped")
        except:
            pass

        try:
            if hasattr(self, "ready_observer"):
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)
                logger.info("‚úÖ Ready observer stopped")
        except:
            pass

        # Clean up channels
        for name, channel in self.channels.items():
            try:
                channel._clean_processes()
                logger.info(f"‚úÖ Channel {name} cleaned up")
            except:
                pass

        logger.info("‚úÖ Nettoyage termin√©")

    def _setup_ready_observer(self):
        """Configure l'observateur pour les dossiers ready_to_stream de chaque cha√Æne"""
        try:
            # D'abord, arr√™ter et recr√©er l'observateur si n√©cessaire pour √©viter les doublons
            if hasattr(self, "ready_observer") and self.ready_observer.is_alive():
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)

            self.ready_observer = Observer()

            # Pour chaque cha√Æne existante
            paths_scheduled = set()  # Pour √©viter les doublons

            for name, channel in self.channels.items():
                ready_dir = Path(channel.video_dir) / "ready_to_stream"
                ready_dir.mkdir(
                    parents=True, exist_ok=True
                )  # S'assurer que le dossier existe

                if ready_dir.exists() and str(ready_dir) not in paths_scheduled:
                    self.ready_observer.schedule(
                        self.ready_event_handler, str(ready_dir), recursive=False
                    )
                    paths_scheduled.add(str(ready_dir))
                    logger.debug(
                        f"üëÅÔ∏è Surveillance ready_to_stream configur√©e pour {name}: {ready_dir}"
                    )

            # D√©marrage de l'observateur
            self.ready_observer.start()
            logger.info(
                f"üöÄ Observateur ready_to_stream d√©marr√© pour {len(paths_scheduled)} chemins"
            )

        except Exception as e:
            logger.error(f"‚ùå Erreur configuration surveillance ready_to_stream: {e}")
            import traceback

            logger.error(traceback.format_exc())

    def _parse_access_log(self, line: str) -> tuple:
        """Parse une ligne de log nginx en utilisant la fonction utilitaire 
        
        Retourne: (ip, channel, request_type, is_valid, path)
        """
        return parse_access_log(line)

    def process_iptv_log_lines(self):
        logger.debug(f"[IPTV_MANAGER] üîÑ D√©but process_iptv_log_lines")

        try:
            # V√©rifier si on doit logger (au moins 2 secondes entre les logs)
            current_time = time.time()
            if hasattr(self, "last_log_time") and current_time - self.last_log_time < 2.0:
                return True

            # Lecture des nouvelles lignes
            with open(self.log_path, "r") as f:
                f.seek(self.last_position)
                new_lines = f.readlines()

                # Mise √† jour de la position
                self.last_position = f.tell()

                # Traitement des nouvelles lignes
                channel_updates = {}  # {channel_name: count}
                for line in new_lines:
                    if not line.strip():
                        continue

                    # Traiter la ligne
                    ip, channel, request_type, is_valid, _ = self._parse_access_log(
                        line
                    )

                    if is_valid and channel:
                        # On met √† jour le timestamp pour ce watcher
                        current_time = time.time()
                        self.watchers[(channel, ip)] = current_time

                        # Regrouper par cha√Æne pour ne faire qu'une mise √† jour
                        if channel not in channel_updates:
                            channel_updates[channel] = set()
                        channel_updates[channel].add(ip)

                # Mise √† jour group√©e par cha√Æne
                for channel, ips in channel_updates.items():
                    count = len(ips)
                    # Log uniquement si le nombre a chang√©
                    if not hasattr(self, "last_watcher_counts"):
                        self.last_watcher_counts = {}
                    
                    if channel not in self.last_watcher_counts or self.last_watcher_counts[channel] != count:
                        logger.info(
                            f"[{channel}] üëÅÔ∏è MAJ watchers: {count} actifs - {list(ips)}"
                        )
                        self.last_watcher_counts[channel] = count
                        self.update_watchers(channel, count, "/hls/")

                self.last_log_time = current_time
                return True

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement nouvelles lignes: {e}")
            import traceback

            logger.error(traceback.format_exc())
            return False

    def _monitor_nginx_logs(self):
        """Surveillance des logs nginx en temps r√©el avec watchdog"""
        try:
            from watchdog.observers import Observer
            from watchdog.events import FileSystemEventHandler

            class LogHandler(FileSystemEventHandler):
                def __init__(self, manager):
                    self.manager = manager
                    self.last_position = 0
                    self._init_position()

                def _init_position(self):
                    """Initialise la position de lecture"""
                    if os.path.exists(self.manager.log_path):
                        with open(self.manager.log_path, "r") as f:
                            f.seek(0, 2)  # Positionnement √† la fin
                            self.last_position = f.tell()

                def on_modified(self, event):
                    if event.src_path == self.manager.log_path:
                        self.manager.process_iptv_log_lines()

            # Initialiser l'observer
            observer = Observer()
            observer.schedule(LogHandler(self), os.path.dirname(self.log_path), recursive=False)
            observer.start()
            logger.info(f"üîç Surveillance des logs nginx d√©marr√©e: {self.log_path}")

            # Boucle de surveillance
            while True:
                time.sleep(1)

        except Exception as e:
            logger.error(f"‚ùå Erreur surveillance logs: {e}")
            # En cas d'erreur, on attend un peu avant de r√©essayer
            time.sleep(5)

    def _cleanup_inactive_watchers(self):
        """Nettoie les watchers inactifs du IPTVManager"""
        current_time = time.time()
        inactive_watchers = []
        
        # V√©rifier si TimeTracker est disponible pour communiquer avec son buffer
        has_time_tracker_buffer = False
        for channel_name, channel in self.channels.items():
            if hasattr(channel, "time_tracker") and hasattr(channel.time_tracker, "is_being_removed"):
                has_time_tracker_buffer = True
                break
        
        # Dur√©e d'inactivit√© plus longue pour √©viter les suppressions pr√©matur√©es
        inactivity_threshold = 300  # 5 minutes d'inactivit√©

        # Identifier les watchers inactifs
        with self.lock:
            for (channel, ip), last_seen_time in self.watchers.items():
                # P√©riode d'inactivit√©
                inactivity_time = current_time - last_seen_time
                
                # Si l'IP est dans le buffer de suppression de TimeTracker, on ne la supprime pas encore
                if has_time_tracker_buffer:
                    time_tracker = next((ch.time_tracker for ch_name, ch in self.channels.items() 
                                         if hasattr(ch, "time_tracker")), None)
                    if time_tracker and hasattr(time_tracker, "is_being_removed") and time_tracker.is_being_removed(ip):
                        logger.debug(f"‚è±Ô∏è Manager: Watcher {ip} dans le buffer de TimeTracker, suppression diff√©r√©e")
                        continue
                
                # Si pas d'activit√© depuis plus de la p√©riode d'inactivit√© d√©finie
                if inactivity_time > inactivity_threshold:
                    inactive_watchers.append((channel, ip))
                    logger.debug(f"‚è±Ô∏è Manager: Watcher {ip} inactif depuis {inactivity_time:.1f}s sur {channel}")

            # Si aucun watcher inactif, on arr√™te ici
            if not inactive_watchers:
                return
                
            # Supprimer les watchers inactifs et mettre √† jour les cha√Ænes affect√©es
            channels_to_update = set()
            for (channel, ip) in inactive_watchers:
                # Supprimer des watchers
                if (channel, ip) in self.watchers:
                    del self.watchers[(channel, ip)]
                
                # Supprimer de _active_watchers
                if channel in self._active_watchers and ip in self._active_watchers[channel]:
                    self._active_watchers[channel].remove(ip)
                    channels_to_update.add(channel)
                    logger.info(f"üßπ Manager: Suppression du watcher inactif: {ip} sur {channel} (inactif depuis plus de {inactivity_threshold}s)")

            # Mettre √† jour les compteurs de watchers pour les cha√Ænes affect√©es
            for channel in channels_to_update:
                if channel in self.channels:
                    watcher_count = len(self._active_watchers.get(channel, set()))
                    
                    # Ne pas mettre √† jour si √ßa fait passer de quelque chose √† z√©ro
                    old_count = getattr(self.channels[channel], 'watchers_count', 0)
                    
                    if watcher_count > 0 or old_count == 0:
                        self.channels[channel].watchers_count = watcher_count
                        self.channels[channel].last_watcher_time = current_time
                        logger.info(f"[{channel}] üëÅÔ∏è Manager: Mise √† jour apr√®s nettoyage: {watcher_count} watchers actifs (ancien: {old_count})")
                    else:
                        # Si on passe de viewers √† z√©ro, on log mais on ne met pas √† jour pour √©viter les arr√™ts intempestifs
                        logger.warning(f"[{channel}] ‚ö†Ô∏è Manager: D√©tection chute de viewers √† z√©ro, v√©rification suppl√©mentaire n√©cessaire")

    def _cleanup_thread_loop(self):
        """Thread de nettoyage p√©riodique"""
        logger.info("üßπ D√©marrage de la boucle de nettoyage")
        
        while not self.stop_watchers.is_set():
            try:
                # Nettoyage des watchers inactifs
                self._cleanup_inactive_watchers()
                
                # V√©rification des timeouts des cha√Ænes
                self._check_channels_timeout()
                
                # Pauser entre les nettoyages
                time.sleep(30)
                
            except Exception as e:
                logger.error(f"‚ùå Erreur dans la boucle de nettoyage: {e}")
                import traceback
                logger.error(traceback.format_exc())
                time.sleep(10)  # Pause en cas d'erreur

    def _update_channel_status(self):
        """Update channel status for dashboard"""
        try:
            if not self.channel_status:
                logger.warning("‚ö†Ô∏è Channel status manager not initialized")
                return False
                
            # Ensure stats directory exists and has proper permissions
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            os.chmod(stats_dir, 0o777)
            
            # Prepare channel status data
            channels_dict = {}
            for channel_name, channel in self.channels.items():
                if channel and hasattr(channel, 'is_ready'):
                    channels_dict[channel_name] = {
                        "active": channel.is_ready(),
                        "viewers": len(channel.watchers) if hasattr(channel, 'watchers') else 0,
                        "streaming": channel.is_streaming() if hasattr(channel, 'is_streaming') else False,
                        "watchers": [w.client_id for w in channel.watchers] if hasattr(channel, 'watchers') else []
                    }
            
            # Update status with retry logic
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    success = self.channel_status.update_all_channels(channels_dict)
                    if success:
                        logger.debug("‚úÖ Channel status updated successfully")
                        return True
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error updating channel status (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to update channel status after all retries")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error in _update_channel_status: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _status_update_loop(self):
        """Background thread to periodically update channel status"""
        update_interval = 1  # Update every second
        logger.info("üîÑ D√©marrage de la boucle de mise √† jour des statuts")
        
        while not self.stop_status_update.is_set():
            try:
                # V√©rifier que le channel_status est bien initialis√©
                if self.channel_status is None:
                    logger.warning("‚ö†Ô∏è Channel status manager non initialis√©, tentative de r√©initialisation")
                    self.init_channel_status_manager()
                    time.sleep(1)
                    continue

                # Ensure stats directory exists and has proper permissions
                stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
                stats_dir.mkdir(parents=True, exist_ok=True)
                os.chmod(stats_dir, 0o777)
                
                # Update channel status with retry logic
                max_retries = 3
                retry_delay = 1
                
                for attempt in range(max_retries):
                    try:
                        success = self._update_channel_status()
                        if success:
                            logger.debug("‚úÖ Channel status updated successfully")
                            break
                        else:
                            logger.warning(f"‚ö†Ô∏è Failed to update channel status (attempt {attempt + 1}/{max_retries})")
                            if attempt < max_retries - 1:
                                time.sleep(retry_delay)
                    except Exception as e:
                        logger.error(f"‚ùå Error updating channel status (attempt {attempt + 1}/{max_retries}): {e}")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                
                # Sleep until next update
                time.sleep(update_interval)
                
            except Exception as e:
                logger.error(f"‚ùå Error in status update loop: {e}")
                import traceback
                logger.error(traceback.format_exc())
                time.sleep(1)  # Reduced from 10s to 1s on error

    def init_channel_status_manager(self):
        """Initialize the channel status manager for dashboard"""
        try:
            # Si d√©j√† initialis√©, ne pas r√©initialiser
            if self.channel_status is not None:
                logger.info("‚ÑπÔ∏è Channel status manager d√©j√† initialis√©, skip")
                return

            logger.info("üöÄ Initialisation du gestionnaire de statuts des cha√Ænes")
            
            # Cr√©er le dossier stats s'il n'existe pas
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            os.chmod(stats_dir, 0o777)
            
            # Cr√©er le fichier de statut s'il n'existe pas
            if not os.path.exists(CHANNELS_STATUS_FILE):
                with open(CHANNELS_STATUS_FILE, 'w') as f:
                    json.dump({
                        'channels': {},
                        'last_updated': int(time.time()),
                        'active_viewers': 0
                    }, f, indent=2)
                os.chmod(CHANNELS_STATUS_FILE, 0o666)
            
            # Initialiser le gestionnaire de statuts
            from channel_status_manager import ChannelStatusManager
            self.channel_status = ChannelStatusManager(
                status_file=CHANNELS_STATUS_FILE
            )
            
            # Faire une mise √† jour initiale avec retry
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    success = self._update_channel_status()
                    if success:
                        logger.info("‚úÖ Channel status manager initialized for dashboard")
                        return
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error updating channel status (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to initialize channel status manager after all retries")
            self.channel_status = None
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing channel status manager: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.channel_status = None

    def _check_channels_timeout(self):
        """V√©rifie p√©riodiquement les timeouts des cha√Ænes sans watchers"""
        try:
            for channel_name, channel in self.channels.items():
                channel.check_watchers_timeout()
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification timeouts: {e}")

    def run_manager_loop(self):
        try:
            # Initialize channel status manager
            self.init_channel_status_manager()
            
            # D√©marrer la boucle de surveillance des watchers
            if not self.watchers_thread.is_alive():
                self.watchers_thread.start()
                logger.info("üîÑ Boucle de surveillance des watchers d√©marr√©e")

            # D√©marrer la surveillance des logs nginx
            nginx_monitor_thread = threading.Thread(target=self._monitor_nginx_logs, daemon=True)
            nginx_monitor_thread.start()
            logger.info("üîç Surveillance des logs nginx d√©marr√©e")

            # Configurer l'observateur pour ready_to_stream
            self._setup_ready_observer()

            # D√©marrer l'observer principal s'il n'est pas d√©j√† en cours
            if not self.observer.is_alive():
                self.observer.start()

            # Attente dynamique pour l'initialisation des cha√Ænes
            max_wait_time = 10  # R√©duit de 15 √† 10 secondes
            check_interval = 0.5  # R√©duit de 1 √† 0.5 secondes pour des v√©rifications plus fr√©quentes
            start_time = time.time()
            
            logger.info(f"‚è≥ Attente de l'initialisation des cha√Ænes (max {max_wait_time}s)...")
            
            while time.time() - start_time < max_wait_time:
                # Compter les cha√Ænes pr√™tes
                ready_channels = sum(1 for name, is_ready in self.channel_ready_status.items() 
                                  if is_ready and name in self.channels 
                                  and self.channels[name].ready_for_streaming)
                
                total_channels = len(self.channels)
                
                if total_channels > 0:
                    ready_percentage = (ready_channels / total_channels) * 100
                    logger.info(f"üìä Progression: {ready_channels}/{total_channels} cha√Ænes pr√™tes ({ready_percentage:.1f}%)")
                    
                    # R√©duire le seuil √† 50% pour d√©marrer plus t√¥t
                    if ready_percentage >= 50:
                        logger.info("‚úÖ Seuil de cha√Ænes pr√™tes atteint, continuation...")
                        break
                    
                    # Si on a au moins une cha√Æne pr√™te et qu'on attend depuis plus de 5 secondes,
                    # on continue quand m√™me
                    elif ready_channels > 0 and (time.time() - start_time) > 5:
                        logger.info(f"‚úÖ Continuation avec {ready_channels} cha√Ænes pr√™tes apr√®s 5s d'attente")
                        break
                
                time.sleep(check_interval)
            
            # D√©marrage automatique des cha√Ænes pr√™tes
            self.auto_start_ready_channels()

            # Boucle principale avec v√©rification des timeouts
            while True:
                self._check_channels_timeout()
                time.sleep(60)  # V√©rification toutes les minutes

        except KeyboardInterrupt:
            self.cleanup_manager()
        except Exception as e:
            logger.error(f"üî• Erreur manager : {e}")
            self.cleanup_manager()

    def _periodic_scan(self):
        """Effectue un scan p√©riodique des cha√Ænes pour d√©tecter les changements"""
        while not self.stop_periodic_scan.is_set():
            try:
                logger.debug(f"üîÑ Scan p√©riodique des cha√Ænes en cours...")
                self.scan_channels(force=True)
                
                # NOUVEAU: Resynchronisation p√©riodique des playlists
                self._resync_all_playlists()
                
                # Attente jusqu'au prochain scan
                self.stop_periodic_scan.wait(self.periodic_scan_interval)
            except Exception as e:
                logger.error(f"‚ùå Erreur scan p√©riodique: {e}")
                self.stop_periodic_scan.wait(60)  # En cas d'erreur, on attend 1 minute

    def _resync_all_playlists(self):
        """Force la resynchronisation des playlists pour toutes les cha√Ænes"""
        try:
            resync_count = 0
            for channel_name, channel in self.channels.items():
                # V√©rifier si la cha√Æne a une m√©thode de cr√©ation de playlist
                if hasattr(channel, "_create_concat_file"):
                    # On ne recr√©√© pas toutes les playlists √† chaque fois, on alterne
                    # 1/4 des cha√Ænes √† chaque cycle pour ne pas surcharger le syst√®me
                    if random.randint(1, 4) == 1:  
                        logger.debug(f"[{channel_name}] üîÑ Resynchronisation p√©riodique de la playlist")
                        
                        # Cr√©er un thread d√©di√© pour resynchroniser et red√©marrer si n√©cessaire
                        def resync_and_restart(ch_name, ch):
                            try:
                                # 1. V√©rifier l'√©tat actuel de la playlist
                                playlist_path = Path(ch.video_dir) / "_playlist.txt"
                                old_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        old_content = f.read()
                                
                                # 2. Mettre √† jour la playlist
                                ch._create_concat_file()
                                
                                # 3. V√©rifier si la playlist a chang√©
                                new_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        new_content = f.read()
                                
                                # 4. Red√©marrer seulement si le contenu a chang√©
                                if old_content != new_content:
                                    logger.info(f"[{ch_name}] üîÑ Playlist modifi√©e, red√©marrage du stream n√©cessaire")
                                    if hasattr(ch, "_restart_stream") and ch.process_manager.is_running():
                                        logger.info(f"[{ch_name}] üîÑ Red√©marrage du stream apr√®s mise √† jour p√©riodique de la playlist")
                                        ch._restart_stream()
                                else:
                                    logger.debug(f"[{ch_name}] ‚úì Playlist inchang√©e, pas de red√©marrage n√©cessaire")
                            except Exception as e:
                                logger.error(f"[{ch_name}] ‚ùå Erreur pendant la resynchronisation: {e}")
                        
                        # Lancer le thread de resynchronisation
                        threading.Thread(
                            target=resync_and_restart,
                            args=(channel_name, channel),
                            daemon=True
                        ).start()
                        
                        resync_count += 1
            
            if resync_count > 0:
                logger.info(f"‚úÖ Resynchronisation et red√©marrage de {resync_count} cha√Ænes effectu√©s")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur resynchronisation playlists: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire IPTV"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        
        # Arr√™t du scan p√©riodique
        self.stop_periodic_scan.set()
        if hasattr(self, 'periodic_scan_thread'):
            self.periodic_scan_thread.join(timeout=5)

    def _process_channel_init_queue(self):
        """Thread qui traite la queue d'initialisation des cha√Ænes en parall√®le"""
        logger.info("üîÑ D√©marrage du thread de traitement de la queue d'initialisation des cha√Ænes")
        while not self.stop_init_thread.is_set():
            try:
                # Limite le nombre d'initialisations parall√®les
                with self.init_threads_lock:
                    if self.active_init_threads >= self.max_parallel_inits:
                        logger.debug(f"‚è≥ Limite d'initialisations parall√®les atteinte ({self.active_init_threads}/{self.max_parallel_inits}), attente...")
                        time.sleep(0.5)
                        continue

                # Essaie de r√©cup√©rer une cha√Æne de la queue
                try:
                    channel_data = self.channel_init_queue.get(timeout=5)
                    logger.info(f"üì• R√©cup√©ration de {channel_data.get('name', 'unknown')} depuis la queue d'initialisation")
                except Empty:
                    time.sleep(0.5)
                    continue

                # Incr√©mente le compteur de threads actifs
                with self.init_threads_lock:
                    self.active_init_threads += 1
                    logger.debug(f"‚ûï Incr√©mentation du compteur de threads actifs: {self.active_init_threads}/{self.max_parallel_inits}")

                # Lance un thread pour initialiser cette cha√Æne
                logger.info(f"üßµ D√©marrage d'un thread pour initialiser {channel_data.get('name', 'unknown')}")
                threading.Thread(
                    target=self._init_channel_async,
                    args=(channel_data,),
                    daemon=True
                ).start()

            except Exception as e:
                logger.error(f"‚ùå Erreur dans le thread d'initialisation: {e}")
                time.sleep(1)

    def _init_channel_async(self, channel_data):
        """Initialise une cha√Æne de mani√®re asynchrone"""
        try:
            channel_name = channel_data["name"]
            channel_dir = channel_data["dir"]
            from_queue = channel_data.get("from_queue", True)  # Par d√©faut, on suppose que c'est de la queue

            logger.info(f"[{channel_name}] üîÑ Initialisation asynchrone de la cha√Æne")

            # Cr√©e l'objet cha√Æne
            channel = IPTVChannel(
                channel_name,
                str(channel_dir),
                hls_cleaner=self.hls_cleaner,
                use_gpu=self.use_gpu,
                stats_collector=self.stats_collector,
            )

            # Ajoute la r√©f√©rence au manager
            channel.manager = self

            # Ajoute la cha√Æne au dictionnaire
            with self.scan_lock:
                self.channels[channel_name] = channel
                self.channel_ready_status[channel_name] = False  # Pas encore pr√™te

            # Attente que la cha√Æne soit pr√™te (max 10 secondes)
            ready = False
            for _ in range(10):
                if hasattr(channel, "ready_for_streaming") and channel.ready_for_streaming:
                    with self.scan_lock:
                        self.channel_ready_status[channel_name] = True
                    logger.info(f"‚úÖ Cha√Æne {channel_name} pr√™te pour le streaming")
                    ready = True
                    break
                time.sleep(1)

            if not ready:
                logger.warning(f"‚ö†Ô∏è Timeout d'initialisation pour la cha√Æne {channel_name}")
            else:
                # D√©marrer imm√©diatement le stream si la cha√Æne est pr√™te
                logger.info(f"[{channel_name}] üöÄ D√©marrage imm√©diat du stream")
                if hasattr(channel, "start_stream"):
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] ‚úÖ Stream d√©marr√© avec succ√®s")
                        # Trigger master playlist update AFTER successful start
                        if hasattr(self, "_manage_master_playlist"):
                            logger.info(f"[{channel_name}] üîÑ Mise √† jour de la playlist ma√Ætre apr√®s d√©marrage")
                            threading.Thread(target=self._manage_master_playlist, daemon=True).start()
                    else:
                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage du stream")
                else:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Channel does not have start_stream method")

            logger.info(f"[{channel_name}] ‚úÖ Initialisation termin√©e")

        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation de la cha√Æne {channel_data.get('name')}: {e}")
        finally:
            # D√©cr√©mente le compteur de threads actifs
            with self.init_threads_lock:
                self.active_init_threads -= 1

            # Marque la t√¢che comme termin√©e UNIQUEMENT si elle vient de la queue
            if channel_data.get("from_queue", True):
                self.channel_init_queue.task_done()

    def _watchers_loop(self):
        """Thread de surveillance des watchers"""
        while not self.stop_watchers.is_set():
            try:
                # V√©rifier l'√©tat des cha√Ænes
                for channel_name, channel in self.channels.items():
                    if not channel.ready_for_streaming:
                        continue

                    # R√©cup√©rer le nombre de watchers actifs
                    active_watchers = self._active_watchers.get(channel_name, set())
                    watcher_count = len(active_watchers)
                    
                    # Mettre √† jour les stats
                    if hasattr(channel, "watchers_count"):
                        channel.watchers_count = watcher_count
                        
                    # Mettre √† jour le timestamp du dernier watcher si on en a
                    if watcher_count > 0:
                        channel.last_watcher_time = time.time()

                # Attendre avant la prochaine v√©rification
                time.sleep(WATCHERS_LOG_CYCLE)

            except Exception as e:
                logger.error(f"‚ùå Erreur surveillance watchers: {e}")
                time.sleep(5)  # Pause en cas d'erreur

    def _get_current_watchers(self):
        """R√©cup√®re les watchers actifs depuis le client_monitor uniquement"""
        try:
            current_watchers = {}
            
            # R√©cup√©rer les watchers depuis le client_monitor uniquement
            if hasattr(self, 'client_monitor') and hasattr(self.client_monitor, 'watchers'):
                current_time = time.time()
                for ip, data in self.client_monitor.watchers.items():
                    # Validation stricte de l'IP
                    try:
                        # V√©rifier le format de base
                        if not ip or not re.match(r'^(\d{1,3}\.){3}\d{1,3}$', ip):
                            logger.warning(f"‚ö†Ô∏è Format IP invalide ignor√©: {ip}")
                            continue
                            
                        # V√©rifier que chaque partie est un nombre valide
                        ip_parts = ip.split('.')
                        if not all(0 <= int(part) <= 255 for part in ip_parts):
                            logger.warning(f"‚ö†Ô∏è Valeurs IP hors limites ignor√©es: {ip}")
                            continue
                    except ValueError:
                        logger.warning(f"‚ö†Ô∏è IP avec valeurs non num√©riques ignor√©e: {ip}")
                        continue
                        
                    channel = data.get("current_channel")
                    last_seen = data.get("last_seen", 0)
                    
                    # Ne consid√©rer que les watchers actifs dans les 30 derni√®res secondes
                    if channel and (current_time - last_seen) < 30:
                        if channel not in current_watchers:
                            current_watchers[channel] = set()
                        current_watchers[channel].add(ip)
                        logger.debug(f"üëÅÔ∏è Watcher actif depuis client_monitor: {channel} sur {ip}")

            return current_watchers

        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration watchers: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {}

    def auto_start_ready_channels(self):
        """D√©marre automatiquement toutes les cha√Ænes pr√™tes avec un d√©lai entre chaque d√©marrage"""
        logger.info("üöÄ D√©marrage automatique des cha√Ænes pr√™tes...")
        
        # Attendre que plus de cha√Ænes soient pr√™tes
        for attempt in range(2):  # 2 tentatives maximum
            ready_channels = []
            with self.scan_lock:
                for name, is_ready in self.channel_ready_status.items():
                    if is_ready and name in self.channels:
                        channel = self.channels[name]
                        if channel.ready_for_streaming:
                            ready_channels.append(name)
                            logger.info(f"‚úÖ Cha√Æne {name} pr√™te pour le d√©marrage automatique")

            if len(ready_channels) >= len(self.channels) * 0.5:  # Au moins 50% des cha√Ænes sont pr√™tes
                break

            logger.info(f"‚è≥ Seulement {len(ready_channels)}/{len(self.channels)} cha√Ænes pr√™tes, attente suppl√©mentaire ({attempt+1}/2)...")
            time.sleep(5)  # 5 secondes entre les tentatives

        # Trier pour pr√©visibilit√©
        ready_channels.sort()
        logger.info(f"üìã Liste des cha√Ænes √† d√©marrer: {ready_channels}")

        # Limiter le CPU pour √©viter saturation
        max_parallel = 4
        groups = [ready_channels[i:i + max_parallel] for i in range(0, len(ready_channels), max_parallel)]

        for group_idx, group in enumerate(groups):
            logger.info(f"üöÄ D√©marrage du groupe {group_idx+1}/{len(groups)} ({len(group)} cha√Ænes)")

            # D√©marrer chaque cha√Æne du groupe avec un petit d√©lai entre elles
            for i, channel_name in enumerate(group):
                delay = i * 0.1  # R√©duit de 0.5s √† 0.1s entre chaque cha√Æne
                logger.info(f"[{channel_name}] ‚è±Ô∏è D√©marrage programm√© dans {delay} secondes")
                
                # V√©rifier que la cha√Æne est toujours pr√™te avant de la d√©marrer
                if channel_name in self.channels and self.channels[channel_name].ready_for_streaming:
                    threading.Timer(delay, self._start_channel, args=[channel_name]).start()
                else:
                    logger.warning(f"‚ö†Ô∏è La cha√Æne {channel_name} n'est plus pr√™te pour le d√©marrage")

            # Attendre avant le prochain groupe
            if group_idx < len(groups) - 1:
                wait_time = 1  # R√©duit de max_parallel √† 1 seconde
                logger.info(f"‚è≥ Attente de {wait_time}s avant le prochain groupe...")
                time.sleep(wait_time)

        if ready_channels:
            logger.info(f"‚úÖ {len(ready_channels)} cha√Ænes programm√©es pour d√©marrage automatique")
        else:
            logger.warning("‚ö†Ô∏è Aucune cha√Æne pr√™te √† d√©marrer")

    def _start_channel(self, channel_name):
        """D√©marre une cha√Æne sp√©cifique"""
        try:
            if channel_name in self.channels:
                channel = self.channels[channel_name]
                if channel.ready_for_streaming:
                    logger.info(f"[{channel_name}] üöÄ D√©marrage automatique...")
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] ‚úÖ D√©marrage automatique r√©ussi")
                    else:
                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage automatique")
                else:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Non pr√™te pour le streaming, d√©marrage ignor√©")
            else:
                logger.error(f"[{channel_name}] ‚ùå Cha√Æne non trouv√©e dans le dictionnaire")
        except Exception as e:
            logger.error(f"[{channel_name}] ‚ùå Erreur lors du d√©marrage automatique: {e}")
            import traceback
            logger.error(traceback.format_exc())
