# iptv_manager.py
import os
import sys
import time
import glob
import shutil
import signal
import random
import psutil
import traceback
import subprocess
from queue import Queue, Empty
from pathlib import Path
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
import threading
from file_event_handler import FileEventHandler
from ready_content_handler import ReadyContentHandler
from hls_cleaner import HLSCleaner
from client_monitor import ClientMonitor
from resource_monitor import ResourceMonitor
from iptv_channel import IPTVChannel
import signal
from ffmpeg_monitor import FFmpegMonitor
from config import (
    CONTENT_DIR,
    NGINX_ACCESS_LOG,
    SERVER_URL,
    logger,
    VIDEO_EXTENSIONS,
    CPU_THRESHOLD,
    SEGMENT_AGE_THRESHOLD,
    SUMMARY_CYCLE,
    WATCHERS_LOG_CYCLE,
    CHANNELS_STATUS_FILE,
    HLS_DIR,
)
from stats_collector import StatsCollector
from channel_status_manager import ChannelStatusManager
import json
import re
from log_utils import parse_access_log
from typing import Optional
from datetime import datetime


class IPTVManager:
    """Gestionnaire centralisÃ© des chaÃ®nes IPTV"""

    def __init__(self, content_dir: str, use_gpu: bool = False):
        # Assurons-nous que la valeur de USE_GPU est bien prise de l'environnement
        use_gpu_env = os.getenv("USE_GPU", "false").lower() == "true"
        
        # Configuration
        self.content_dir = content_dir
        self.use_gpu = use_gpu or use_gpu_env
        self.channels = {}
        self.channel_ready_status = {}
        self.log_path = NGINX_ACCESS_LOG
        
        # >>> FIX: Initialize hls_cleaner EARLY <<<
        # On initialise le nettoyeur HLS avec le bon chemin
        self.hls_cleaner = HLSCleaner(HLS_DIR)
        # Le nettoyage HLS initial sera fait dans _clean_startup
        
        # >>> STEP 1: Clean startup FIRST to reset status file
        logger.info("Initialisation du gestionnaire IPTV amÃ©liorÃ©")
        self._clean_startup()
        # <<< END STEP 1
        
        # Initialize ready_event_handler first
        try:
            self.ready_event_handler = ReadyContentHandler(self)
            logger.info("âœ… ReadyContentHandler initialized")
        except Exception as e:
            logger.error(f"âŒ Error initializing ReadyContentHandler: {e}")
            self.ready_event_handler = None
        
        # Initialize file_event_handler
        try:
            self.file_event_handler = FileEventHandler(self)
            logger.info("âœ… FileEventHandler initialized")
        except Exception as e:
            logger.error(f"âŒ Error initializing FileEventHandler: {e}")
            self.file_event_handler = None
        
        # Initialisation de last_position pour le suivi des logs
        self.last_position = 0
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                f.seek(0, 2)
                self.last_position = f.tell()
                logger.info(f"ğŸ“ Position initiale de lecture des logs: {self.last_position} bytes")

        # Tracking du temps de dÃ©marrage pour les mÃ©triques
        self.startup_time = time.time()

        # Verrou et cooldown pour les scans
        self.scan_lock = threading.RLock()
        self.scan_cooldown = 60
        self.last_scan_time = 0
        self.scan_queue = Queue()
        self.failing_channels = set()

        # Queue pour les chaÃ®nes Ã  initialiser en parallÃ¨le
        self.channel_init_queue = Queue()
        self.max_parallel_inits = 15
        self.active_init_threads = 0
        self.init_threads_lock = threading.RLock()

        # Timeout d'inactivitÃ© pour arrÃªter un stream (en secondes)
        self.channel_inactivity_timeout = 300 # 5 minutes
        self.last_inactivity_check = 0

        # >>> STEP 2: Initialize channel status manager AFTER cleaning
        self.channel_status = None  # Initialiser Ã  None
        # >>> FIX: Call init_channel_status_manager method <<<
        self.init_channel_status_manager() 
        # <<< END STEP 2

        # MODIFIÃ‰: StatsCollector et ClientMonitor seront initialisÃ©s aprÃ¨s que les chaÃ®nes soient prÃªtes
        try:
            # NOUVEAU: Obtenir les canaux valides depuis la playlist maÃ®tre comme source de vÃ©ritÃ©
            master_playlist_path = Path(HLS_DIR) / "playlist.m3u"
            valid_channels = set()
            if master_playlist_path.exists():
                with open(master_playlist_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        # Chercher les URLs des playlists des canaux
                        match = re.search(r'/hls/([^/]+)/playlist\.m3u8', line)
                        if match:
                            valid_channels.add(match.group(1))
                logger.info(f"TrouvÃ© {len(valid_channels)} canaux valides dans la playlist maÃ®tre pour le nettoyage initial des stats.")
            else:
                logger.warning(f"Playlist maÃ®tre non trouvÃ©e Ã  {master_playlist_path}. Le nettoyage des stats pourrait Ãªtre incomplet.")

            # Initialiser StatsCollector en lui passant les canaux valides pour un nettoyage immÃ©diat
            self.stats_collector = StatsCollector(manager=self, valid_channels=valid_channels)
            # Passer le callback update_watchers mÃªme avant l'initialisation complÃ¨te
            self.stats_collector.update_watchers_callback = self.update_watchers
            logger.info("ğŸ“Š StatsCollector initialisÃ© avec succÃ¨s (avec nettoyage initial basÃ© sur la playlist maÃ®tre)")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'initialisation initiale de StatsCollector: {e}")
            # CrÃ©er un objet vide pour Ã©viter les erreurs None
            from types import SimpleNamespace
            self.stats_collector = SimpleNamespace()
            self.stats_collector.update_watchers_callback = lambda *args, **kwargs: None  # Fonction vide
            
        self.client_monitor = None

        # Moniteur FFmpeg
        self.ffmpeg_monitor = FFmpegMonitor(self.channels)
        self.ffmpeg_monitor.start()

        # On initialise le nettoyeur HLS avec le bon chemin
        # HLS Cleaner is already initialized above

        # Initialisation des threads
        self.stop_scan_thread = threading.Event()
        self.stop_init_thread = threading.Event()
        self.stop_periodic_scan = threading.Event()  # Pour arrÃªter le scan pÃ©riodique
        self.periodic_scan_interval = 300  # 5 minutes entre chaque scan pÃ©riodique

        # Thread de scan unifiÃ©
        self.scan_thread = threading.Thread(
            target=self._scan_worker,
            daemon=True
        )

        # Thread d'initialisation des chaÃ®nes
        self.channel_init_thread = threading.Thread(
            target=self._process_channel_init_queue,
            daemon=True
        )

        # Thread de mise Ã  jour pÃ©riodique de la playlist maÃ®tre
        self.periodic_update_thread = threading.Thread(
            target=self._periodic_force_playlist_update,
            daemon=True,
            name="PeriodicPlaylistUpdate"
        )

        # Observer
        self.observer = Observer()
        event_handler = FileEventHandler(self)
        self.observer.schedule(event_handler, self.content_dir, recursive=True)
        logger.info(f"ğŸ‘ï¸ Observer configurÃ© pour surveiller {self.content_dir} en mode rÃ©cursif")

        # DÃ©marrage des threads dans l'ordre correct
        self.scan_thread.start()
        logger.info("ğŸ”„ Thread de scan unifiÃ© dÃ©marrÃ©")

        self.channel_init_thread.start()
        logger.info("ğŸ”„ Thread d'initialisation des chaÃ®nes dÃ©marrÃ©")

        self.periodic_update_thread.start()
        logger.info("ğŸ”„ Thread de mise Ã  jour pÃ©riodique de la playlist dÃ©marrÃ©")

        # Le thread de nettoyage a Ã©tÃ© supprimÃ© car le nettoyage est basÃ© sur les logs via ClientMonitor
        # self.cleanup_thread.start()
        # logger.info("ğŸ§¹ Thread de nettoyage des watchers dÃ©marrÃ©")

        # Force un scan initial
        logger.info("ğŸ” ForÃ§age du scan initial des chaÃ®nes...")
        self._do_scan(force=True)
        logger.info("âœ… Scan initial terminÃ©")

        # >>> STEP 3: REMOVE second _clean_startup call
        # _clean_startup called only once at the beginning now
        # self._clean_startup()
        # <<< END STEP 3

        last_scan_time = time.time()
        last_summary_time = time.time()
        last_resync_time = time.time()
        last_log_watchers_time = time.time()
        last_process_logs_time = time.time()  # Pour traiter les logs rÃ©guliÃ¨rement

    def request_scan(self, force: bool = False):
        """Demande un scan en le mettant dans la queue"""
        self.scan_queue.put(force)
        logger.debug("Scan demandÃ©" + (" (forcÃ©)" if force else ""))

    def _scan_worker(self):
        """Thread qui gÃ¨re les scans de maniÃ¨re centralisÃ©e"""
        logger.info("ğŸ” DÃ©marrage du thread de scan worker")
        while not self.stop_scan_thread.is_set():
            try:
                # Attendre une demande de scan ou le dÃ©lai pÃ©riodique
                try:
                    force = self.scan_queue.get(timeout=30)  # 30 secondes de dÃ©lai par dÃ©faut
                except Empty:  # Fixed: Using imported Empty instead of Queue.Empty
                    force = False  # Scan pÃ©riodique normal

                current_time = time.time()
                
                # VÃ©rifier le cooldown sauf si scan forcÃ©
                if not force and (current_time - self.last_scan_time) < 15:
                    logger.debug("â­ï¸ Scan ignorÃ© (cooldown)")
                    continue

                with self.scan_lock:
                    logger.info("ğŸ” DÃ©marrage du scan" + (" forcÃ©" if force else ""))
                    self._do_scan(force)
                    self.last_scan_time = time.time()

                # --- VÃ©rification pÃ©riodique des chaÃ®nes inactives ---
                if current_time - self.last_inactivity_check > 60: # VÃ©rifier toutes les 60 secondes
                    self._check_inactive_channels()
                    self.last_inactivity_check = current_time
                # -----------------------------------------------------

            except Exception as e:
                logger.error(f"âŒ Erreur dans le thread de scan: {e}")
                time.sleep(5)

    def _do_scan(self, force: bool = False):
        """Effectue le scan rÃ©el des chaÃ®nes et rÃ©concilie avec les statistiques."""
        try:
            # Compter les chaÃ®nes avant scan
            channels_before = len(self.channels)

            content_path = Path(self.content_dir)
            if not content_path.exists():
                logger.error(f"Le dossier de contenu {content_path} n'existe pas!")
                return

            # 1. Obtenir tous les rÃ©pertoires du systÃ¨me de fichiers
            channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
            found_on_disk = {d.name for d in channel_dirs}
            logger.info(f"ğŸ“‚ {len(found_on_disk)} dossiers de chaÃ®nes trouvÃ©s sur le disque.")

            # 2. Obtenir tous les canaux des statistiques et les rÃ©concilier
            with self.scan_lock:
                if self.stats_collector:
                    stats_known_channels = set(self.stats_collector.channel_stats.keys())
                    stats_known_channels.discard("global")
                else:
                    stats_known_channels = set()

                # 3. Calculer la diffÃ©rence
                removed_channels = stats_known_channels - found_on_disk
                if removed_channels:
                    logger.info(f"ğŸ—‘ï¸ ChaÃ®nes obsolÃ¨tes Ã  supprimer des stats: {removed_channels}")
                    # 4. Supprimer les canaux obsolÃ¨tes
                    for removed_name in removed_channels:
                        self.remove_channel(removed_name)

            # 5. Parcourir les rÃ©pertoires du systÃ¨me de fichiers pour ajouter/mettre Ã  jour les canaux
            for channel_dir in channel_dirs:
                channel_name = channel_dir.name
                
                with self.scan_lock:
                    if channel_name in self.channels:
                        if force:
                            logger.info(f"ğŸ”„ Scan forcÃ© : ChaÃ®ne existante {channel_name} - rafraÃ®chissement Ã©ventuel gÃ©rÃ© par la chaÃ®ne elle-mÃªme.")
                        continue
                    else:
                        self.channels[channel_name] = None
                        logger.debug(f"[{channel_name}] Ajout d'un placeholder Ã  self.channels.")

                logger.info(f"âœ… Nouvelle chaÃ®ne dÃ©tectÃ©e : {channel_name}")
                
                logger.info(f"â³ Mise en file d'attente pour initialisation de la chaÃ®ne {channel_name}")
                self.channel_init_queue.put({
                    "name": channel_name,
                    "dir": channel_dir,
                    "from_queue": True
                })

            # Compter les chaÃ®nes aprÃ¨s scan
            channels_after = len(self.channels)

            # Mettre Ã  jour la playlist maÃ®tre aprÃ¨s la rÃ©conciliation
            if channels_after != channels_before:
                logger.info(
                    f"ğŸ“Š Nombre de chaÃ®nes changÃ©: {channels_before} â†’ {channels_after}, "
                    "mise Ã  jour de la playlist"
                )
                self._update_master_playlist()
            else:
                # Mise Ã  jour normale mÃªme si le nombre n'a pas changÃ©
                self._update_master_playlist()

        except Exception as e:
            logger.error(f"âŒ Erreur lors du scan des chaÃ®nes: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """ArrÃªte proprement le gestionnaire IPTV"""
        logger.info("ğŸ›‘ ArrÃªt du gestionnaire IPTV...")
        
        # Utiliser la mÃ©thode complÃ¨te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("ğŸ›‘ Gestionnaire IPTV arrÃªtÃ© avec succÃ¨s")

    def update_watchers(self, channel_name: str, watcher_count: int, active_ips_list: list, path: str = "/hls/", source: str = 'unknown'):
        """
        Met Ã  jour le statut d'une chaÃ®ne (nombre de watchers, IPs) suite Ã  une notification
        du ClientMonitor (basÃ© sur les logs Nginx).
        Met directement Ã  jour le ChannelStatusManager.
        
        Args:
            channel_name: Nom de la chaÃ®ne.
            watcher_count: Nombre actuel de watchers pour cette chaÃ®ne.
            active_ips_list: Liste des IPs des watchers actifs.
            path: (IgnorÃ©, conservÃ© pour compatibilitÃ© potentielle)
            source: Source de la mise Ã  jour: 'nginx_log', 'nginx_log_immediate', etc.
        """
        # Ignorer la playlist maÃ®tre
        if channel_name == "master_playlist":
            return True

        # VÃ©rifier si le ChannelStatusManager est disponible
        if not hasattr(self, "channel_status") or self.channel_status is None:
            # Log une seule fois pour Ã©viter le spam
            if not getattr(self, "_logged_csm_missing", False):
                logger.warning("âš ï¸ ChannelStatusManager non disponible dans update_watchers. Impossible de mettre Ã  jour le statut.")
                self._logged_csm_missing = True
            return False
        else:
            # RÃ©initialiser le flag de log si CSM est Ã  nouveau disponible
            self._logged_csm_missing = False

        try:
            # Forcer une mise Ã  jour MÃŠME si les viewers n'ont pas changÃ©
            # C'est crucial pour maintenir les canaux actifs Ã  jour
            
            # Log diffÃ©rent selon que c'est une mise Ã  jour immÃ©diate ou pÃ©riodique
            if source == 'nginx_log_immediate':
                logger.info(f"[{channel_name}] ğŸ”„ Mise Ã  jour IMMÃ‰DIATE: {watcher_count} watchers")
            else:
                logger.debug(f"[{channel_name}] Callback update_watchers: {watcher_count} watchers (Source: {source})")
            
            # PrÃ©parer les donnÃ©es pour ChannelStatusManager
            # On suppose que si ClientMonitor notifie, la chaÃ®ne est considÃ©rÃ©e 'live'
            # ou du moins potentiellement active si des watchers sont prÃ©sents.
            channel_obj = self.channels.get(channel_name)
            is_live_status = False
            if channel_obj:
                is_live_status = (hasattr(channel_obj, 'is_ready_for_streaming') and channel_obj.is_ready_for_streaming())
            
            # Pour les canaux avec des watchers actifs, toujours les marquer comme actifs
            # mÃªme si le canal n'est pas techniquement "streaming"
            if watcher_count > 0:
                is_live_status = True
            
            status_data = {
                "is_live": is_live_status,
                "viewers": watcher_count,
                "watchers": active_ips_list,
                "last_updated": datetime.now().isoformat()
            }
            
            # Forcer la sauvegarde si le nombre de spectateurs a changÃ©.
            current_status = self.channel_status.channels.get(channel_name, {})
            previous_viewers = current_status.get("viewers", 0)
            viewers_changed = (watcher_count != previous_viewers)

            # Forcer la sauvegarde immÃ©diate si les viewers ont changÃ© ou si la source le demande
            force_immediate_save = viewers_changed or (source == 'nginx_log_immediate')

            # Mettre Ã  jour directement le ChannelStatusManager
            success = self.channel_status.update_channel(
                channel_name,
                status_data,
                force_save=force_immediate_save
            )
            
            if success:
                if source == 'nginx_log_immediate':
                    logger.info(f"[{channel_name}] âœ… Mise Ã  jour IMMÃ‰DIATE rÃ©ussie dans ChannelStatusManager")
                else:
                    logger.debug(f"[{channel_name}] âœ… Statut mis Ã  jour dans ChannelStatusManager (Viewers: {watcher_count})")
                return True
            else:
                logger.warning(f"[{channel_name}] âš ï¸ Ã‰chec de la mise Ã  jour du statut via ChannelStatusManager.")
                return False
                
        except Exception as e:
            logger.error(f"[{channel_name}] âŒ Erreur dans update_watchers: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _log_channels_summary(self):
        """GÃ©nÃ¨re et affiche un rÃ©capitulatif de l'Ã©tat des chaÃ®nes basÃ© sur ChannelStatusManager"""
        try:
            # Utiliser self.channel_status comme source de vÃ©ritÃ©
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.info("ğŸ“Š ChannelStatusManager non disponible pour le rÃ©capitulatif")
                return

            # Lire l'Ã©tat actuel des chaÃ®nes depuis ChannelStatusManager
            # AccÃ¨s direct, le manager interne gÃ¨re les verrous pour les Ã©critures
            current_statuses = self.channel_status.channels
            manager_known_channels = list(self.channels.keys()) # ChaÃ®nes connues par IPTVManager

            if not manager_known_channels:
                logger.info("ğŸ“Š Aucune chaÃ®ne gÃ©rÃ©e par IPTVManager pour le rÃ©capitulatif")
                return

            # Organiser les chaÃ®nes par Ã©tat basÃ© sur current_statuses
            live_with_viewers = []
            live_without_viewers = []
            not_live_channels = []

            for name in sorted(manager_known_channels):
                status = current_statuses.get(name, {}) # Obtenir le statut ou un dict vide
                is_live = status.get('is_live', False)
                viewers_count = status.get('viewers', 0)
                watchers_list = status.get('watchers', [])

                channel_info = {
                    "name": name,
                    "viewers": viewers_count,
                    "is_live": is_live,
                    "watchers": watchers_list
                }

                if is_live:
                    if viewers_count > 0:
                        live_with_viewers.append(channel_info)
                    else:
                        live_without_viewers.append(channel_info)
                else:
                    # Inclut les chaÃ®nes explicitement non live et celles inconnues du status manager
                    not_live_channels.append(channel_info)

            # Construire le rÃ©capitulatif
            summary_lines = ["ğŸ“Š RÃ‰CAPITULATIF DES CHAÃNES (via ChannelStatusManager):"]

            # Afficher les chaÃ®nes live avec viewers
            if live_with_viewers:
                active_parts = []
                for ch in live_with_viewers:
                    active_parts.append(f"ğŸŸ¢ {ch['name']}: {ch['viewers']} viewers")
                summary_lines.append(
                    "CHAÃNES LIVE AVEC VIEWERS: " + " | ".join(active_parts)
                )
            else:
                summary_lines.append("CHAÃNES LIVE AVEC VIEWERS: Aucune")

            # Afficher les chaÃ®nes live sans viewers
            if live_without_viewers:
                inactive_parts = []
                for ch in live_without_viewers[:10]: # Limiter pour Ã©viter logs trop longs
                    inactive_parts.append(f"{ch['name']}")
                remaining = len(live_without_viewers) - 10
                if remaining > 0:
                    inactive_parts.append(f"et {remaining} autres")
                summary_lines.append(
                    f"CHAÃNES LIVE SANS VIEWERS: {len(live_without_viewers)} ({', '.join(inactive_parts)})"
                )
            else:
                summary_lines.append("CHAÃNES LIVE SANS VIEWERS: Aucune")

            # Afficher les chaÃ®nes non-live ou inconnues
            if not_live_channels:
                stopped_names = [ch['name'] for ch in not_live_channels[:10]] # Limiter aussi
                remaining = len(not_live_channels) - 10
                if remaining > 0:
                    stopped_names.append(f"et {remaining} autres")
                summary_lines.append(f"CHAÃNES NON-LIVE / INCONNUES: {len(not_live_channels)} ({', '.join(stopped_names)})")
            else:
                summary_lines.append("CHAÃNES NON-LIVE / INCONNUES: Aucune")

            # Stats globales basÃ©es sur ChannelStatusManager
            total_viewers = sum(ch["viewers"] for ch in live_with_viewers)
            total_live_streams = len(live_with_viewers) + len(live_without_viewers)
            total_known_channels = len(manager_known_channels)
            summary_lines.append(
                f"TOTAL: {total_viewers} viewers sur {total_live_streams} streams live ({total_known_channels} chaÃ®nes gÃ©rÃ©es)"
            )

            # Afficher le rÃ©capitulatif
            logger.info("\n".join(summary_lines))

        except Exception as e:
            logger.error(f"âŒ Erreur gÃ©nÃ©ration rÃ©capitulatif: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _clean_startup(self):
        """Nettoyage initial optimisÃ©"""
        try:
            logger.info("ğŸ§¹ Nettoyage initial... (appel unique au dÃ©marrage)")

            content_path = Path(self.content_dir)
            if not content_path.exists():
                content_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"ğŸ“‚ CrÃ©ation du dossier de contenu: {content_path}")

            # Force reset of channel status file at startup
            logger.info("ğŸ”„ RÃ©initialisation du fichier de statut des chaÃ®nes...")
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)

            # Create a fresh status file with zero viewers
            with open(CHANNELS_STATUS_FILE, 'w') as f:
                json.dump({
                    'channels': {},
                    'last_updated': int(time.time()),
                    'active_viewers': 0
                }, f, indent=2)

            logger.info("âœ… Fichier de statut rÃ©initialisÃ©")

            # Nettoyage des dossiers HLS
            self.hls_cleaner.initial_cleanup()

            # Start the cleaner thread only if it's not already alive
            if hasattr(self.hls_cleaner, 'cleanup_thread') and not self.hls_cleaner.cleanup_thread.is_alive():
                self.hls_cleaner.start()
                logger.info("âœ… HLSCleaner thread started.")
            else:
                logger.info("â„¹ï¸ HLSCleaner thread already running or finished, not starting again.")

            logger.info("âœ… Nettoyage initial terminÃ©")

        except Exception as e:
            logger.error(f"âŒ Erreur lors du nettoyage initial: {e}")

    def scan_channels(self, force: bool = False, initial: bool = False):
        """
        Scanne le contenu pour dÃ©tecter les nouveaux dossiers (chaÃ®nes).
        Version amÃ©liorÃ©e avec limitation de frÃ©quence et debug pour isolation du problÃ¨me
        """
        # Limiter la frÃ©quence des scans
        current_time = time.time()
        scan_cooldown = 30  # 30s entre scans complets (sauf si force=True)

        if (
            not force
            and not initial
            and hasattr(self, "last_scan_time")
            and current_time - self.last_scan_time < scan_cooldown
        ):
            logger.debug(
                f"Scan ignorÃ©: dernier scan il y a {current_time - self.last_scan_time:.1f}s"
            )
            return

        setattr(self, "last_scan_time", current_time)

        with self.scan_lock:
            try:
                content_path = Path(self.content_dir)
                if not content_path.exists():
                    logger.error(f"Le dossier {content_path} n'existe pas!")
                    return

                # Debugging: log the directory and its existence
                logger.debug(f"ğŸ” Scanning content directory: {content_path} (exists: {content_path.exists()})")
                
                # Get all subdirectories 
                channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
                
                # Debug the found directories
                logger.debug(f"ğŸ“‚ Found {len(channel_dirs)} potential channel directories: {[d.name for d in channel_dirs]}")

                logger.info(f"ğŸ“¡ Scan des chaÃ®nes disponibles...")
                for channel_dir in channel_dirs:
                    channel_name = channel_dir.name
                    
                    # Debug: check if this directory should be a channel
                    logger.debug(f"Examining directory: {channel_name} ({channel_dir})")

                    if channel_name in self.channels:
                        # Si la chaÃ®ne existe dÃ©jÃ , on vÃ©rifie son Ã©tat
                        if force:
                            logger.info(
                                f"ğŸ”„ RafraÃ®chissement de la chaÃ®ne {channel_name}"
                            )
                            channel = self.channels[channel_name]
                            if hasattr(channel, "refresh_videos"):
                                channel.refresh_videos()
                        else:
                            logger.info(f"âœ… ChaÃ®ne existante: {channel_name}")
                        continue

                    logger.info(f"âœ… Nouvelle chaÃ®ne trouvÃ©e: {channel_name}")

                    # Ajoute la chaÃ®ne Ã  la queue d'initialisation
                    self.channel_init_queue.put(
                        {"name": channel_name, "dir": channel_dir}
                    )

                logger.info(f"ğŸ“¡ Scan terminÃ©, {len(channel_dirs)} chaÃ®nes identifiÃ©es")

            except Exception as e:
                logger.error(f"Erreur scan des chaÃ®nes: {e}")
                import traceback
                logger.error(traceback.format_exc())

    def ensure_hls_directory(self, channel_name: str = None):
        """CrÃ©e et configure les dossiers HLS avec les bonnes permissions"""
        # Dossier HLS principal
        base_hls = Path(HLS_DIR)
        if not base_hls.exists():
            logger.info("ğŸ“‚ CrÃ©ation du dossier HLS principal...")
            base_hls.mkdir(parents=True, exist_ok=True)

        # Dossier spÃ©cifique Ã  une chaÃ®ne si demandÃ©
        if channel_name:
            channel_hls = base_hls / channel_name
            if not channel_hls.exists():
                logger.info(f"ğŸ“‚ CrÃ©ation du dossier HLS pour {channel_name}")
                channel_hls.mkdir(parents=True, exist_ok=True)

    def _manage_master_playlist(self):
        """GÃ¨re la mise Ã  jour pÃ©riodique de la playlist principale avec dÃ©lai de dÃ©marrage et retries exponentiels"""
        from config import STARTUP_PLAYLIST_DELAY, PLAYLIST_UPDATE_RETRIES, RETRY_BACKOFF_BASE

        logger.info("ğŸ”„ DÃ©marrage thread de mise Ã  jour de la playlist principale")

        # S'assurer que la playlist existe avec des permissions correctes dÃ¨s le dÃ©part
        playlist_path = os.path.abspath(f"{HLS_DIR}/playlist.m3u")
        if not os.path.exists(playlist_path):
            # CrÃ©er un contenu minimal
            with open(playlist_path, "w", encoding="utf-8") as f:
                f.write("#EXTM3U\n")
            logger.info(f"âœ… Playlist initiale crÃ©Ã©e: {playlist_path}")

        # Attente initiale pour permettre l'initialisation des chaÃ®nes
        logger.info(f"ğŸ“‹ Attente de {STARTUP_PLAYLIST_DELAY}s avant premiÃ¨re mise Ã  jour playlist")
        time.sleep(STARTUP_PLAYLIST_DELAY)

        logger.info("ğŸš€ DÃ©but des mises Ã  jour de playlist avec retries")

        # Tentatives avec backoff exponentiel
        delays = [RETRY_BACKOFF_BASE * (1.5 ** i) for i in range(PLAYLIST_UPDATE_RETRIES)]
        # Exemple avec base=10: [10, 15, 22, 33, 50, 75, 113, 169, 254, 381]

        for attempt, delay in enumerate(delays, 1):
            try:
                logger.info(f"ğŸ“ Tentative de mise Ã  jour playlist {attempt}/{PLAYLIST_UPDATE_RETRIES}")
                self._update_master_playlist()

                # VÃ©rifier la complÃ©tude
                if self._validate_playlist_completeness():
                    logger.info(f"âœ… Playlist complÃ¨te aprÃ¨s {attempt} tentative(s)")
                    break
                else:
                    logger.warning(f"âš ï¸ Playlist incomplÃ¨te, retry dans {delay:.0f}s")

                if attempt < PLAYLIST_UPDATE_RETRIES:
                    time.sleep(delay)

            except Exception as e:
                logger.error(f"âŒ Erreur tentative {attempt}: {e}")
                if attempt < PLAYLIST_UPDATE_RETRIES:
                    time.sleep(delay)

        logger.info("âœ… Phase de mise Ã  jour initiale de la playlist terminÃ©e")

        # Continuer avec des mises Ã  jour pÃ©riodiques
        while True:
            try:
                self._update_master_playlist()
                time.sleep(60)  # On attend 60s avant la prochaine mise Ã  jour
            except Exception as e:
                logger.error(f"âŒ Erreur maj master playlist: {e}")
                logger.error(traceback.format_exc())
                time.sleep(60)  # On attend mÃªme en cas d'erreur

    def _periodic_force_playlist_update(self):
        """Thread qui force pÃ©riodiquement la mise Ã  jour de la playlist maÃ®tre"""
        from config import FORCE_PLAYLIST_UPDATE_INTERVAL

        logger.info(f"ğŸ”„ DÃ©marrage du thread de mise Ã  jour pÃ©riodique (interval: {FORCE_PLAYLIST_UPDATE_INTERVAL}s)")

        while not self.stop_event.is_set():
            try:
                time.sleep(FORCE_PLAYLIST_UPDATE_INTERVAL)

                if not self.stop_event.is_set():
                    logger.debug("â° Mise Ã  jour pÃ©riodique forcÃ©e de la playlist maÃ®tre")
                    self._update_master_playlist()

            except Exception as e:
                logger.error(f"âŒ Erreur dans le thread de mise Ã  jour pÃ©riodique: {e}")
                time.sleep(FORCE_PLAYLIST_UPDATE_INTERVAL)

    def _update_master_playlist(self):
        """Effectue la mise Ã  jour de la playlist principale avec logging amÃ©liorÃ©"""
        start_time = time.time()
        startup_elapsed = start_time - self.startup_time if hasattr(self, 'startup_time') else 0

        playlist_path = os.path.abspath(f"{HLS_DIR}/playlist.m3u")
        logger.info(f"ğŸ”„ DÃ©but mise Ã  jour playlist (temps depuis dÃ©marrage: {startup_elapsed:.1f}s)")

        # Utiliser le verrou de scan pour protÃ©ger l'accÃ¨s aux chaÃ®nes
        with self.scan_lock:
            try:
                # On sauvegarde d'abord le contenu actuel au cas oÃ¹
                existing_content = "#EXTM3U\n"
                if os.path.exists(playlist_path) and os.path.getsize(playlist_path) > 0:
                    try:
                        with open(playlist_path, "r", encoding="utf-8") as f:
                            existing_content = f.read()
                        logger.debug(f"âœ… Contenu actuel sauvegardÃ©: {len(existing_content)} octets")
                    except Exception as e:
                        logger.error(f"âŒ Erreur lecture playlist existante: {e}")
                
                # PrÃ©paration du nouveau contenu
                content = "#EXTM3U\n"

                # Build ready_channels based on channel objects status
                ready_channels = []
                # *** REMOVED redundant scan_lock, using self.lock now ***
                # with self.scan_lock: 
                for name, channel in sorted(self.channels.items()):
                    # Ensure channel object exists and check its ready status
                    if channel and hasattr(channel, 'is_ready_for_streaming') and channel.is_ready_for_streaming():
                        ready_channels.append((name, channel))
                        logger.debug(f"[{name}] âœ… ChaÃ®ne prÃªte pour la playlist maÃ®tre")
                    elif channel:
                        logger.debug(f"[{name}] â³ ChaÃ®ne non prÃªte pour la playlist maÃ®tre")
                    else:
                        logger.debug(f"[{name}] â³ ChaÃ®ne non initialisÃ©e, non ajoutÃ©e Ã  la playlist maÃ®tre.")

                # Ã‰criture des chaÃ®nes prÃªtes
                # No need to get SERVER_URL from os.getenv since we already imported it from config
                if ready_channels:
                    for name, _ in ready_channels:
                        content += f'#EXTINF:-1 tvg-id="{name}" tvg-name="{name}",{name}\n'
                        content += f"http://{SERVER_URL}/hls/{name}/playlist.m3u8\n"
                else:
                    # Si aucune chaÃ®ne n'est prÃªte, ajouter un commentaire
                    content += "# Aucune chaÃ®ne active pour le moment\n"
                    logger.warning("âš ï¸ Aucune chaÃ®ne active dÃ©tectÃ©e pour la playlist")
                
                # Loguer le contenu Ã  Ã©crire pour vÃ©rification
                logger.debug(f"ğŸ“ Contenu de la playlist Ã  Ã©crire:\n{content}")
                
                # Ã‰crire dans un fichier temporaire d'abord
                temp_path = f"{playlist_path}.tmp"
                with open(temp_path, "w", encoding="utf-8") as f:
                    f.write(content)
                    # *** ADDED: Ensure file is written to disk before checking size ***
                    f.flush()
                    os.fsync(f.fileno())
                    # *** END ADDED ***
                
                # VÃ©rifier que le fichier temporaire a Ã©tÃ© crÃ©Ã© correctement
                # *** ADDED: Short delay to allow filesystem sync ***
                time.sleep(0.1) 
                # *** END ADDED ***
                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
                    # Remplacer l'ancien fichier
                    os.replace(temp_path, playlist_path)
                    logger.debug(f"âœ… Playlist remplacÃ©e avec succÃ¨s")
                else:
                    logger.error(f"âŒ Fichier temporaire vide ou non crÃ©Ã©: {temp_path}")
                    # Ne pas remplacer l'ancien fichier si le temporaire est vide
                    raise Exception("Fichier temporaire vide ou non crÃ©Ã©")
                
                
                # VÃ©rification que le fichier a Ã©tÃ© correctement Ã©crit
                if os.path.exists(playlist_path):
                    size = os.path.getsize(playlist_path)
                    logger.debug(f"âœ… Playlist Ã©crite: {playlist_path}, taille: {size} octets")
                    
                    # Lire le contenu pour vÃ©rification
                    with open(playlist_path, "r", encoding="utf-8") as f:
                        read_content = f.read()
                        if read_content == content:
                            logger.debug("âœ… Contenu vÃ©rifiÃ©, identique Ã  ce qui devait Ãªtre Ã©crit")
                        else:
                            logger.error("âŒ Contenu lu diffÃ©rent du contenu qui devait Ãªtre Ã©crit")
                            logger.error(f"ğŸ“„ Contenu lu:\n{read_content}")
                            # Essayer d'Ã©crire directement
                            with open(playlist_path, "w", encoding="utf-8") as f:
                                f.write(content)
                            logger.info("ğŸ”„ Tentative d'Ã©criture directe effectuÃ©e")
                else:
                    logger.error(f"âŒ Fichier non trouvÃ© aprÃ¨s Ã©criture: {playlist_path}")
                    # RecrÃ©er avec le contenu existant
                    with open(playlist_path, "w", encoding="utf-8") as f:
                        f.write(existing_content)
                    logger.warning("ğŸ”„ Restauration du contenu prÃ©cÃ©dent")

                # Use len(self.channels) which includes all potentially initializing channels (placeholders)
                total_channels_known_by_manager = len(self.channels)
                # Count non-None channels for a more accurate 'loaded' count
                loaded_channels_count = sum(1 for ch in self.channels.values() if ch is not None)

                # Timing info
                duration = time.time() - start_time
                logger.info(
                    f"âœ… Playlist mise Ã  jour en {duration:.2f}s: {len(ready_channels)} chaÃ®nes prÃªtes sur {loaded_channels_count} chargÃ©es ({total_channels_known_by_manager} total connu par manager)"
                )
            except Exception as e:
                logger.error(f"âŒ Erreur mise Ã  jour playlist: {e}")
                logger.error(traceback.format_exc())
                
                # En cas d'erreur, vÃ©rifier si le fichier existe toujours
                if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                    # Restaurer le contenu prÃ©cÃ©dent s'il existe
                    if existing_content and len(existing_content) > 8:  # Plus que juste "#EXTM3U\n"
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write(existing_content)
                        logger.info("âœ… Contenu prÃ©cÃ©dent restaurÃ©")
                    
                    # Si pas de contenu prÃ©cÃ©dent ou erreur, crÃ©er une playlist minimale
                    if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write("#EXTM3U\n# Playlist de secours\n")
                        logger.info("âœ… Playlist minimale crÃ©Ã©e en fallback")

        # Validation de la complÃ©tude avec retry diffÃ©rÃ©
        if not self._validate_playlist_completeness():
            from config import VALIDATION_RETRY_DELAY, VALIDATION_MAX_RETRIES

            # Compter les tentatives de validation
            if not hasattr(self, '_validation_retry_count'):
                self._validation_retry_count = 0

            if self._validation_retry_count < VALIDATION_MAX_RETRIES:
                self._validation_retry_count += 1
                logger.info(
                    f"ğŸ“… Planification retry validation dans {VALIDATION_RETRY_DELAY}s "
                    f"(tentative {self._validation_retry_count}/{VALIDATION_MAX_RETRIES})"
                )

                # Planifier une mise Ã  jour diffÃ©rÃ©e
                threading.Timer(
                    VALIDATION_RETRY_DELAY,
                    self._update_master_playlist
                ).start()
            else:
                logger.warning(
                    f"âš ï¸ Nombre maximum de retries atteint ({VALIDATION_MAX_RETRIES}), "
                    "attente du prochain cycle pÃ©riodique"
                )
                self._validation_retry_count = 0
        else:
            # Playlist complÃ¨te, rÃ©initialiser le compteur
            self._validation_retry_count = 0

    def _validate_playlist_completeness(self) -> bool:
        """
        Valide que la playlist maÃ®tre contient toutes les chaÃ®nes prÃªtes.
        Retourne True si complÃ¨te, False sinon.
        """
        try:
            playlist_path = f"{HLS_DIR}/playlist.m3u"

            if not os.path.exists(playlist_path):
                logger.warning("âš ï¸ Fichier playlist n'existe pas encore")
                return False

            # Lire la playlist
            with open(playlist_path, 'r', encoding='utf-8') as f:
                playlist_content = f.read()

            # Compter les chaÃ®nes dans la playlist
            playlist_channels = set()
            for line in playlist_content.split('\n'):
                if line.startswith('#EXTINF:'):
                    # Extraire le nom de la chaÃ®ne
                    parts = line.split(',')
                    if len(parts) > 1:
                        channel_name = parts[-1].strip()
                        playlist_channels.add(channel_name)

            # Compter les chaÃ®nes prÃªtes dans le manager
            ready_channels = set()
            with self.scan_lock:
                for name, channel in self.channels.items():
                    if channel and hasattr(channel, 'is_ready_for_streaming'):
                        if channel.is_ready_for_streaming():
                            ready_channels.add(name)

            # Comparer
            missing_channels = ready_channels - playlist_channels
            extra_channels = playlist_channels - ready_channels

            if missing_channels:
                logger.warning(
                    f"âš ï¸ ChaÃ®nes prÃªtes mais absentes de la playlist ({len(missing_channels)}): "
                    f"{', '.join(sorted(missing_channels))}"
                )

            if extra_channels:
                logger.debug(
                    f"â„¹ï¸ ChaÃ®nes dans playlist mais plus prÃªtes ({len(extra_channels)}): "
                    f"{', '.join(sorted(extra_channels))}"
                )

            is_complete = len(missing_channels) == 0

            logger.info(
                f"ğŸ“Š Validation playlist: {len(playlist_channels)} dans fichier, "
                f"{len(ready_channels)} prÃªtes, complÃ¨te: {is_complete}"
            )

            return is_complete

        except Exception as e:
            logger.error(f"âŒ Erreur validation complÃ©tude playlist: {e}")
            return False

    def cleanup_manager(self):
        """Cleanup everything before shutdown"""
        logger.info("DÃ©but du nettoyage...")
        
        # Stop all threads first
        self.stop_scan_thread.set()
        self.stop_init_thread.set()

        # Vider tous les viewers du fichier de statut avant arrÃªt
        try:
            if self.channel_status is not None:
                logger.info("ğŸ§¹ Vidage de tous les viewers du fichier channel_status.json avant arrÃªt...")
                flush_success = self.channel_status.flush_all_viewers()
                if flush_success:
                    logger.info("âœ… Tous les viewers ont Ã©tÃ© vidÃ©s avec succÃ¨s du fichier de statut")
                else:
                    logger.warning("âš ï¸ Ã‰chec du vidage des viewers avant arrÃªt")
        except Exception as e:
            logger.error(f"âŒ Erreur lors du vidage des viewers: {e}")

        # Stop components that might be None
        try:
            if self.channel_status is not None:
                self.channel_status.stop()
                logger.info("âœ… Channel status manager stopped")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt du channel status manager: {e}")

        try:
            if self.stats_collector is not None:
                self.stats_collector.stop()
                logger.info("ğŸ“Š StatsCollector arrÃªtÃ©")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt du StatsCollector: {e}")

        try:
            if self.hls_cleaner is not None:
                self.hls_cleaner.stop_cleaner()
                logger.info("ğŸ§¹ HLS Cleaner arrÃªtÃ©")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt du HLS Cleaner: {e}")

        # Join threads with timeout
        threads_to_join = [
            (self.channel_init_thread, "Channel init thread"),
            (self.scan_thread, "Scan thread"),
            # (self.cleanup_thread, "Cleanup thread"),
        ]

        for thread, name in threads_to_join:
            try:
                if thread and thread.is_alive():
                    thread.join(timeout=5)
                    logger.info(f"âœ… {name} stopped")
            except Exception as e:
                logger.error(f"âŒ Erreur lors de l'arrÃªt du thread {name}: {e}")

        # Stop observers
        try:
            if hasattr(self, "observer"):
                self.observer.stop()
                self.observer.join(timeout=5)
                logger.info("âœ… Main observer stopped")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt de l'observer principal: {e}")

        try:
            if hasattr(self, "ready_observer"):
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)
                logger.info("âœ… Ready observer stopped")
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt du ready observer: {e}")
            
        # Clean up channels
        for name, channel in self.channels.items():
            try:
                if channel is not None:
                    channel._clean_processes()
                    logger.info(f"âœ… Channel {name} cleaned up")
            except Exception as e:
                logger.error(f"âŒ Erreur lors du nettoyage du canal {name}: {e}")

        logger.info("âœ… Nettoyage terminÃ©")

    def _setup_ready_observer(self):
        """Configure l'observateur pour les dossiers ready_to_stream de chaque chaÃ®ne"""
        try:
            # D'abord, arrÃªter et recrÃ©er l'observateur si nÃ©cessaire pour Ã©viter les doublons
            if hasattr(self, "ready_observer") and self.ready_observer.is_alive():
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)

            self.ready_observer = Observer()

            # Pour chaque chaÃ®ne existante
            paths_scheduled = set()  # Pour Ã©viter les doublons

            for name, channel in self.channels.items():
                # ADDED: Check if channel object is None
                if channel is None:
                    logger.debug(f"_setup_ready_observer: Skipping channel {name} as object is None.")
                    continue
                    
                ready_dir = Path(channel.video_dir) / "ready_to_stream"
                ready_dir.mkdir(
                    parents=True, exist_ok=True
                )  # S'assurer que le dossier existe

                if ready_dir.exists() and str(ready_dir) not in paths_scheduled:
                    self.ready_observer.schedule(
                        self.ready_event_handler, str(ready_dir), recursive=False
                    )
                    paths_scheduled.add(str(ready_dir))
                    logger.debug(
                        f"ğŸ‘ï¸ Surveillance ready_to_stream configurÃ©e pour {name}: {ready_dir}"
                    )

            # DÃ©marrage de l'observateur
            self.ready_observer.start()
            logger.info(
                f"ğŸš€ Observateur ready_to_stream dÃ©marrÃ© pour {len(paths_scheduled)} chemins"
            )

        except Exception as e:
            logger.error(f"âŒ Erreur configuration surveillance ready_to_stream: {e}")
            import traceback

            logger.error(traceback.format_exc())

    def _update_channel_status(self, initial_call=False):
        """Update channel status for dashboard"""
        try:
            if not self.channel_status:
                logger.warning("âš ï¸ Channel status manager not initialized")
                return False
                
            # Ensure stats directory exists and has proper permissions
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)

            
            # Prepare channel status data
            channels_dict = {}
            # Use scan_lock for iterating self.channels safely
            with self.scan_lock:
                for channel_name, channel in self.channels.items():
                    # Only include channels that have been initialized (are not None)
                    if channel and hasattr(channel, 'is_ready_for_streaming'):
                        is_ready = channel.is_ready_for_streaming()
                        is_streaming = channel.is_running() if hasattr(channel, 'is_running') else False
                        
                        # Les informations sur les viewers sont maintenant gÃ©rÃ©es par ChannelStatusManager
                        # On ne les met pas Ã  jour ici pour Ã©viter les conflits
                        status_data = {
                            "active": is_ready,
                            "streaming": is_streaming,
                        }
                        channels_dict[channel_name] = status_data
                    # else: # Log channels that are skipped during update
                        # logger.debug(f"_update_channel_status: Skipping channel '{channel_name}' (not initialized or no is_ready attr)")

            
            # If no channels are ready or available, don't wipe the status
            if not channels_dict:
                # Avoid logging this message too frequently if manager starts with no channels
                log_key = "_last_no_channels_log_time"
                now = time.time()
                if not hasattr(self, log_key) or now - getattr(self, log_key) > 60:
                     logger.info("ğŸ¤· No initialized channels found, skipping status update.")
                     setattr(self, log_key, now)
                return True # Indicate success as no update was needed

            # Update status with retry logic
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    # Call the method responsible for writing the combined status
                    success = self.channel_status.update_all_channels(channels_dict)
                    if success:
                        logger.debug(f"âœ… Channel status file updated successfully ({'initial' if initial_call else 'periodic'})")
                        return True
                    else:
                        logger.warning(f"âš ï¸ Failed to update channel status file (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"âŒ Error calling channel_status.update_all_channels (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("âŒ Failed to update channel status file after all retries")
            return False
            
        except Exception as e:
            logger.error(f"âŒ Error in _update_channel_status: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _check_channels_timeout(self):
        """VÃ©rifie pÃ©riodiquement les timeouts des chaÃ®nes sans watchers"""
        try:
            # Use list() to avoid issues if dict changes during iteration
            for channel_name, channel in list(self.channels.items()): 
                # ---> ADD CHECK FOR NONE <--- 
                if channel is not None and hasattr(channel, 'check_watchers_timeout'):
                    channel.check_watchers_timeout()
                elif channel is None:
                    logger.debug(f"_check_channels_timeout: Skipping channel {channel_name} as object is None.")
        except Exception as e:
            logger.error(f"âŒ Erreur vÃ©rification timeouts: {e}")

    def run_manager_loop(self):
        """Boucle principale du gestionnaire IPTV"""
        logger.info("ğŸ”„ DÃ©marrage de la boucle principale du gestionnaire")
        
        # DÃ©marrer les composants dans le bon ordre
        if not hasattr(self, "observer") or not self.observer.is_alive():
            self.observer.start()
            logger.info("ğŸ‘ï¸ Observateur dÃ©marrÃ©")
            
        try:
            last_scan_time = time.time()
            last_summary_time = time.time()
            last_resync_time = time.time()
            last_log_watchers_time = time.time()
            last_process_logs_time = time.time()  # Pour traiter les logs rÃ©guliÃ¨rement
            
            while True:
                current_time = time.time()
                
                # >>> NOUVEAU: Traiter les logs access.log rÃ©guliÃ¨rement
                if current_time - last_process_logs_time > 0.5 and hasattr(self, "client_monitor") and self.client_monitor is not None:
                    self.client_monitor.process_new_logs()
                    last_process_logs_time = current_time
                # <<< FIN NOUVEAU
                
                # Scan pÃ©riodique 
                if current_time - last_scan_time > SUMMARY_CYCLE:
                    self._periodic_scan()
                    last_scan_time = current_time
                    
                # Affichage pÃ©riodique du rÃ©capitulatif
                if current_time - last_summary_time > SUMMARY_CYCLE:
                    self._log_channels_summary()
                    last_summary_time = current_time
                
                # Resynchronisation gÃ©nÃ©rale de toutes les playlists
                if current_time - last_resync_time > 600:  # Toutes les 10 minutes
                    self._resync_all_playlists()
                    last_resync_time = current_time
                
                # Log pÃ©riodique des watchers
                if current_time - last_log_watchers_time > WATCHERS_LOG_CYCLE and hasattr(self, "_log_watchers_status"):
                    self._log_watchers_status()
                    last_log_watchers_time = current_time
                
                # Dormir un peu pour Ã©viter de surcharger le CPU
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            logger.info("ğŸ‘‹ Interruption clavier, arrÃªt du gestionnaire")
            self.stop()
        except Exception as e:
            logger.critical(f"âŒ ERREUR MAJEURE dans la boucle principale: {e}")
            import traceback
            logger.critical(traceback.format_exc())
            self.stop()
            
        logger.info("ğŸ›‘ Boucle principale du gestionnaire terminÃ©e")

    def _periodic_scan(self):
        """Effectue un scan pÃ©riodique des chaÃ®nes pour dÃ©tecter les changements"""
        if self.stop_periodic_scan.is_set():
            return

        try:
            logger.debug(f"ğŸ”„ Scan pÃ©riodique des chaÃ®nes en cours...")
            self.scan_channels(force=True)
            
            # NOUVEAU: Resynchronisation pÃ©riodique des playlists
            self._resync_all_playlists()
            
        except Exception as e:
            logger.error(f"âŒ Erreur scan pÃ©riodique: {e}")

    def _resync_all_playlists(self):
        """Force la resynchronisation des playlists pour toutes les chaÃ®nes"""
        try:
            resync_count = 0
            for channel_name, channel in self.channels.items():
                # VÃ©rifier si la chaÃ®ne a une mÃ©thode de crÃ©ation de playlist
                if hasattr(channel, "_create_concat_file"):
                    # On ne recrÃ©Ã© pas toutes les playlists Ã  chaque fois, on alterne
                    # 1/4 des chaÃ®nes Ã  chaque cycle pour ne pas surcharger le systÃ¨me
                    if random.randint(1, 4) == 1:  
                        logger.debug(f"[{channel_name}] ğŸ”„ Resynchronisation pÃ©riodique de la playlist")
                        
                        # CrÃ©er un thread dÃ©diÃ© pour resynchroniser et redÃ©marrer si nÃ©cessaire
                        def resync_and_restart(ch_name, ch):
                            try:
                                # 1. VÃ©rifier l'Ã©tat actuel de la playlist
                                playlist_path = Path(ch.video_dir) / "_playlist.txt"
                                old_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        old_content = f.read()
                                
                                # 2. Mettre Ã  jour la playlist
                                ch._create_concat_file()
                                
                                # 3. VÃ©rifier si la playlist a changÃ©
                                new_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        new_content = f.read()
                                
                                # 4. RedÃ©marrer seulement si le contenu a changÃ©
                                if old_content != new_content:
                                    logger.info(f"[{ch_name}] ğŸ”„ Playlist modifiÃ©e, redÃ©marrage du stream nÃ©cessaire")
                                    
                                    # Add _restart_stream method if it doesn't exist
                                    if not hasattr(ch, "_restart_stream"):
                                        logger.warning(f"[{ch_name}] âš ï¸ Adding missing _restart_stream method to channel.")
                                        # Add a basic implementation that will restart using start_stream
                                        def restart_stream_impl(diagnostic=None):
                                            """Basic implementation for channels missing _restart_stream method"""
                                            try:
                                                logger.info(f"[{ch_name}] ğŸ”„ Basic restart implementation called. Reason: {diagnostic or 'Unknown'}")
                                                # Stop current stream if it's running
                                                if hasattr(ch, "process_manager") and ch.process_manager.is_running():
                                                    ch.process_manager.stop_process()
                                                
                                                # Clean HLS segments if possible
                                                if hasattr(ch, "hls_cleaner"):
                                                    ch.hls_cleaner.cleanup_channel(ch_name)
                                                
                                                # Try to start the stream again
                                                if hasattr(ch, "start_stream"):
                                                    success = ch.start_stream()
                                                    logger.info(f"[{ch_name}] {'âœ… Stream restarted successfully' if success else 'âŒ Failed to restart stream'}")
                                                    return success
                                                else:
                                                    logger.error(f"[{ch_name}] âŒ Channel doesn't have start_stream method")
                                                    return False
                                            except Exception as e:
                                                logger.error(f"[{ch_name}] âŒ Error in basic restart implementation: {e}")
                                                return False
                                        
                                        # Add the method to the channel
                                        setattr(ch, "_restart_stream", restart_stream_impl)
                                        logger.info(f"[{ch_name}] âœ… Added basic _restart_stream method to channel")
                                    
                                    if hasattr(ch, "_restart_stream") and ch.process_manager.is_running():
                                        logger.info(f"[{ch_name}] ğŸ”„ RedÃ©marrage du stream aprÃ¨s mise Ã  jour pÃ©riodique de la playlist")
                                        ch._restart_stream()
                                else:
                                    logger.debug(f"[{ch_name}] âœ“ Playlist inchangÃ©e, pas de redÃ©marrage nÃ©cessaire")
                            except Exception as e:
                                logger.error(f"[{ch_name}] âŒ Erreur pendant la resynchronisation: {e}")
                        
                        # Lancer le thread de resynchronisation
                        threading.Thread(
                            target=resync_and_restart,
                            args=(channel_name, channel),
                            daemon=True
                        ).start()
                        resync_count += 1
                        logger.info(f"ğŸ”„ [{channel_name}] {resync_count} playlists resynchronisÃ©es")
                else:
                    logger.debug(f"[{channel_name}] â„¹ï¸ Pas de mÃ©thode de crÃ©ation de playlist, aucune resynchronisation nÃ©cessaire")
                    
            if resync_count > 0:
                logger.info(f"âœ… Resynchronisation et redÃ©marrage de {resync_count} chaÃ®nes effectuÃ©s")
                
        except Exception as e:
            logger.error(f"âŒ Erreur resynchronisation des playlists: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """ArrÃªte proprement le gestionnaire IPTV"""
        logger.info("ğŸ›‘ ArrÃªt du gestionnaire IPTV...")
        
        # Utiliser la mÃ©thode complÃ¨te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("ğŸ›‘ Gestionnaire IPTV arrÃªtÃ© avec succÃ¨s")

    def _process_channel_init_queue(self):
        """Process the queue of channels to initialize"""
        logger.info("ğŸ”„ DÃ©marrage du thread de traitement de la queue d'initialisation des chaÃ®nes")
        while not self.stop_init_thread.is_set():
            try:
                # Limite le nombre d'initialisations parallÃ¨les
                with self.init_threads_lock:
                    active_threads = self.active_init_threads
                    if active_threads >= self.max_parallel_inits:
                        logger.debug(f"[INIT_QUEUE] â³ Limite d'initialisations parallÃ¨les atteinte ({active_threads}/{self.max_parallel_inits}), attente...")
                        time.sleep(0.5)
                        continue

                # Essaie de rÃ©cupÃ©rer une chaÃ®ne de la queue
                channel_data = None
                try:
                    logger.debug("[INIT_QUEUE] â±ï¸ Attente d'un Ã©lÃ©ment dans la queue...")
                    channel_data = self.channel_init_queue.get(timeout=5)
                    channel_name = channel_data.get('name', 'unknown')
                    logger.info(f"[INIT_QUEUE] ğŸ“¥ RÃ©cupÃ©ration de {channel_name} depuis la queue")
                except Empty:
                    logger.debug("[INIT_QUEUE] ğŸ“ª Queue vide, attente...")
                    time.sleep(0.5)
                    continue # Continue to next iteration to check stop_event
                except Exception as q_err:
                    logger.error(f"[INIT_QUEUE] âŒ Erreur get() sur la queue: {q_err}")
                    time.sleep(1) # Wait a bit before retrying
                    continue

                # If we got an item from the queue
                if channel_data:
                    channel_name = channel_data.get('name', 'unknown')
                    # IncrÃ©mente le compteur de threads actifs
                    with self.init_threads_lock:
                        self.active_init_threads += 1
                        logger.debug(f"[INIT_QUEUE] â• [{channel_name}] IncrÃ©mentation du compteur de threads actifs: {self.active_init_threads}/{self.max_parallel_inits}")

                    # Lance un thread pour initialiser cette chaÃ®ne
                    logger.info(f"[INIT_QUEUE] ğŸ§µ [{channel_name}] DÃ©marrage d'un thread d'initialisation")
                    threading.Thread(
                        target=self._init_channel_async,
                        args=(channel_data,),
                        daemon=True,
                        name=f"Init-{channel_name}" # Add thread name
                    ).start()

            except Exception as e:
                logger.error(f"[INIT_QUEUE] âŒ Erreur majeure dans la boucle _process_channel_init_queue: {e}")
                logger.error(traceback.format_exc()) # Log full traceback
                time.sleep(5) # Wait longer after a major loop error

    def _init_channel_async(self, channel_data):
        """Initialise une chaÃ®ne de maniÃ¨re asynchrone"""
        channel_init_start = time.time()
        try:
            channel_name = channel_data["name"]
            channel_dir = channel_data["dir"]
            from_queue = channel_data.get("from_queue", True)  # Par dÃ©faut, on suppose que c'est de la queue

            logger.info(f"[{channel_name}] ğŸ”„ Initialisation asynchrone de la chaÃ®ne")

            # CrÃ©e l'objet chaÃ®ne
            channel = IPTVChannel(
                channel_name,
                str(channel_dir),
                hls_cleaner=self.hls_cleaner,
                use_gpu=self.use_gpu,
                stats_collector=self.stats_collector,
            )

            # Ajoute la rÃ©fÃ©rence au manager
            channel.manager = self

            # VÃ©rifie si la chaÃ®ne est prÃªte immÃ©diatement aprÃ¨s l'initialisation
            is_ready = channel.is_ready_for_streaming()

            with self.scan_lock:
                self.channels[channel_name] = channel

            if is_ready:
                logger.info(f"[{channel_name}] âœ… ChaÃ®ne prÃªte, dÃ©marrage du stream...")
                if hasattr(channel, "start_stream"):
                    if channel.start_stream():
                        logger.info(f"[{channel_name}] âœ… Stream dÃ©marrÃ© avec succÃ¨s.")
                        self._update_master_playlist()

                        # VÃ©rifier aprÃ¨s un court dÃ©lai que la chaÃ®ne est bien dans la playlist
                        def delayed_check():
                            time.sleep(10)
                            if not self._validate_playlist_completeness():
                                logger.warning(f"[{channel_name}] ChaÃ®ne manquante, nouvelle mise Ã  jour")
                                self._update_master_playlist()

                        threading.Thread(target=delayed_check, daemon=True).start()
                    else:
                        logger.error(f"[{channel_name}] âŒ Ã‰chec du dÃ©marrage du stream.")
                else:
                    logger.warning(f"[{channel_name}] âš ï¸ La mÃ©thode start_stream est manquante.")
            else:
                logger.warning(f"[{channel_name}] âš ï¸ ChaÃ®ne non prÃªte aprÃ¨s initialisation.")

            init_duration = time.time() - channel_init_start
            logger.info(f"[{channel_name}] â±ï¸ Initialisation complÃ©tÃ©e en {init_duration:.2f}s (PrÃªt: {is_ready})")

        except Exception as e:
            logger.error(f"âŒ Erreur initialisation de la chaÃ®ne {channel_data.get('name')}: {e}")
            # Make sure to add placeholder if exception happens before adding the channel object
            channel_name_for_exc = channel_data.get('name')
            if channel_name_for_exc:
                with self.scan_lock:
                    if channel_name_for_exc not in self.channels:
                        self.channels[channel_name_for_exc] = None # Placeholder on error
        finally:
            # DÃ©crÃ©mente le compteur de threads actifs
            with self.init_threads_lock:
                self.active_init_threads -= 1

            # Marque la tÃ¢che comme terminÃ©e UNIQUEMENT si elle vient de la queue
            if channel_data.get("from_queue", True):
                self.channel_init_queue.task_done()

    def init_stats_collector_and_client_monitor(self):
        """Initialise le StatsCollector et le ClientMonitor une fois que les chaÃ®nes sont prÃªtes"""
        logger.info("ğŸš€ Initialisation de StatsCollector et ClientMonitor maintenant que les chaÃ®nes sont prÃªtes...")
        
        # Initialisation du StatsCollector
        if self.stats_collector is None:
            try:
                logger.info(">>> INITIALIZING STATS COLLECTOR <<<")
                self.stats_collector = StatsCollector()
                logger.info("ğŸ“Š StatsCollector initialisÃ©")
                # Passer le callback update_watchers pour que StatsCollector puisse mettre Ã  jour les spectateurs directement
                self.stats_collector.update_watchers_callback = self.update_watchers
            except Exception as e:
                logger.error(f"âŒ Erreur initialisation StatsCollector: {e}")
                self.stats_collector = None
        
        # Initialisation du ClientMonitor
        if self.client_monitor is None:
            try:
                self.client_monitor = ClientMonitor(
                    log_path=self.log_path,
                    update_watchers_callback=self.update_watchers,
                    manager=self,
                    stats_collector=self.stats_collector
                )
                # Au lieu de dÃ©marrer le thread, on initialise juste la position
                self.client_monitor.start()
                logger.info("ğŸ‘ï¸ ClientMonitor initialisÃ© et prÃªt")
            except Exception as e:
                logger.error(f"âŒ Erreur initialisation ClientMonitor: {e}")
                self.client_monitor = None


    def _start_channel(self, channel_name):
        """DÃ©marre une chaÃ®ne spÃ©cifique"""
        try:
            if channel_name in self.channels:
                channel = self.channels[channel_name]
                if channel.ready_for_streaming:
                    logger.info(f"[{channel_name}] ğŸš€ DÃ©marrage automatique...")
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] âœ… DÃ©marrage automatique rÃ©ussi")
                    else:
                        logger.error(f"[{channel_name}] âŒ Ã‰chec du dÃ©marrage automatique")
                else:
                    logger.warning(f"[{channel_name}] âš ï¸ Non prÃªte pour le streaming, dÃ©marrage ignorÃ©")
            else:
                logger.error(f"[{channel_name}] âŒ ChaÃ®ne non trouvÃ©e dans le dictionnaire")
        except Exception as e:
            logger.error(f"[{channel_name}] âŒ Erreur lors du dÃ©marrage automatique: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def get_current_channel_status(self):
        """
        Retourne l'Ã©tat actuel de toutes les chaÃ®nes, basÃ© sur ChannelStatusManager.
        """
        try:
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.warning("âš ï¸ Tentative d'accÃ¨s au statut des chaÃ®nes mais ChannelStatusManager n'est pas prÃªt.")
                return {}

            # AccÃ¨s direct aux donnÃ©es de statut gÃ©rÃ©es par ChannelStatusManager
            # Aucune copie nÃ©cessaire ici car on ne fait que lire.
            status_data = self.channel_status.channels
            
            # CrÃ©er une copie pour Ã©viter de retourner la rÃ©fÃ©rence interne 
            # et potentiellement filtrer pour ne retourner que les chaÃ®nes connues du manager?
            # Pour l'instant, retournons tout ce que le status manager connaÃ®t.
            return status_data.copy() 
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de la rÃ©cupÃ©ration du statut actuel des chaÃ®nes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {}

    def get_channel_segment_duration(self, channel_name: str) -> Optional[float]:
        """Retrieves the configured HLS segment duration (hls_time) for a specific channel."""
        # Use scan_lock as channel dictionary might be modified during scans/inits
        with self.scan_lock:
            channel = self.channels.get(channel_name)
            if channel and hasattr(channel, 'command_builder') and hasattr(channel.command_builder, 'hls_time'):
                duration = getattr(channel.command_builder, 'hls_time', None)
                if isinstance(duration, (int, float)) and duration > 0:
                    logger.debug(f"[{channel_name}] Found segment duration: {duration}")
                    return float(duration)
                else:
                    logger.warning(f"[{channel_name}] Found invalid segment duration type/value: {duration} in command_builder")
                    return None
            elif channel:
                logger.warning(f"[{channel_name}] Channel object found but missing 'command_builder' or 'hls_time' attribute.")
                return None
            else:
                # Channel not found or is a placeholder (None)
                logger.warning(f"[{channel_name}] Channel not found or not fully initialized in IPTVManager.channels.")
                return None

    def init_channel_status_manager(self):
        """Initialize the channel status manager for dashboard"""
        try:
            # Si dÃ©jÃ  initialisÃ©, ne pas rÃ©initialiser
            if self.channel_status is not None:
                logger.info("â„¹ï¸ Channel status manager dÃ©jÃ  initialisÃ©, skip")
                return

            logger.info("ğŸš€ Initialisation du gestionnaire de statuts des chaÃ®nes")
            
            # CrÃ©er le dossier stats s'il n'existe pas
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            
            # CrÃ©er le fichier de statut s'il n'existe pas ou est vide/invalide
            should_create_file = True
            if os.path.exists(CHANNELS_STATUS_FILE):
                try:
                    if os.path.getsize(CHANNELS_STATUS_FILE) > 0:
                         with open(CHANNELS_STATUS_FILE, 'r') as f:
                             json.load(f) # Try to parse existing json
                         should_create_file = False # File exists and is valid JSON
                    # else: file exists but is empty, will overwrite
                except (json.JSONDecodeError, OSError) as e:
                     logger.warning(f"Existing status file {CHANNELS_STATUS_FILE} is invalid or unreadable ({e}). Will overwrite.")
                     # File exists but is invalid, will overwrite
                     
            if should_create_file:
                 logger.info(f"Creating/Overwriting initial status file: {CHANNELS_STATUS_FILE}")
                 with open(CHANNELS_STATUS_FILE, 'w') as f:
                     # Initial state with 0 viewers
                     json.dump({
                         'channels': {},
                         'last_updated': int(time.time()),
                         'active_viewers': 0
                     }, f, indent=2)
            
            # Initialiser le gestionnaire de statuts
            self.channel_status = ChannelStatusManager(
                status_file=CHANNELS_STATUS_FILE
            )
            
            # Faire une mise Ã  jour initiale avec retry, PASSING initial_call=True
            # Note: _update_channel_status needs TimeTracker, ensure it's initialized before calling this if needed
            # For now, we assume initialization is enough, actual update might happen later
            # max_retries = 3
            # retry_delay = 1
            # for attempt in range(max_retries):
            #     try:
            #         # Pass initial_call=True here
            #         success = self._update_channel_status(initial_call=True) # Depends on TimeTracker
            #         if success:
            #             logger.info("âœ… Channel status manager initialized for dashboard (initial status set)")
            #             return
            #         else:
            #             logger.warning(f"âš ï¸ Failed to update channel status during init (attempt {attempt + 1}/{max_retries})")
            #             if attempt < max_retries - 1:
            #                 time.sleep(retry_delay)
            #     except Exception as e:
            #         logger.error(f"âŒ Error calling _update_channel_status during init (attempt {attempt + 1}/{max_retries}): {e}")
            #         if attempt < max_retries - 1:
            #             time.sleep(retry_delay)
            # logger.error("âŒ Failed to initialize channel status manager after all retries")
            # self.channel_status = None
            logger.info("âœ… ChannelStatusManager initialisÃ©. La mise Ã  jour initiale se fera plus tard.")
            
        except Exception as e:
            logger.error(f"âŒ Error initializing channel status manager: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.channel_status = None
            
    def _check_inactive_channels(self):
        """
        VÃ©rifie les chaÃ®nes actuellement en streaming mais sans viewers (selon ChannelStatusManager)
        et les arrÃªte si elles sont inactives depuis trop longtemps.
        """
        if not hasattr(self, "channel_status") or self.channel_status is None:
            logger.debug("[_check_inactive_channels] ChannelStatusManager non disponible, skip.")
            return

        current_time = time.time()
        channels_to_stop = []

        # Utiliser le lock du ChannelStatusManager pour lire son Ã©tat
        with self.channel_status._lock:
            for channel_name, status_data in self.channel_status.channels.items():
                viewers = status_data.get("viewers", 0)
                is_live = status_data.get("is_live", False)
                last_updated_str = status_data.get("last_updated")
                
                # Ne vÃ©rifier que les chaÃ®nes considÃ©rÃ©es comme live mais sans viewers
                if is_live and viewers == 0:
                    # VÃ©rifier si la chaÃ®ne existe dans notre manager
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj and hasattr(channel_obj, 'is_running') and channel_obj.is_running():
                        # Initialiser last_active_time si ce n'est pas fait
                        if not hasattr(channel_obj, 'last_time_with_viewers'):
                            channel_obj.last_time_with_viewers = current_time
                            
                        # VÃ©rifier le dÃ©lai d'inactivitÃ©
                        inactive_duration = current_time - channel_obj.last_time_with_viewers
                        if inactive_duration > self.channel_inactivity_timeout:
                            logger.info(f"[{channel_name}] â±ï¸ Inactive depuis {inactive_duration:.0f}s (> {self.channel_inactivity_timeout}s) sans viewers. ArrÃªt demandÃ©.")
                            channels_to_stop.append(channel_name)
                        else:
                             logger.debug(f"[{channel_name}] Inactive depuis {inactive_duration:.0f}s sans viewers, mais < timeout.")
                    # else: Channel is not streaming according to its object, no need to stop
                elif viewers > 0:
                    # Mettre Ã  jour le timestamp si des viewers sont prÃ©sents
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj:
                        channel_obj.last_time_with_viewers = current_time 

        # ArrÃªter les chaÃ®nes identifiÃ©es (en dehors du lock de channel_status)
        for name in channels_to_stop:
            channel_obj = self.channels.get(name)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                 # VÃ©rifier Ã  nouveau si des viewers sont revenus entre temps?
                 # Pour l'instant, on arrÃªte si la dÃ©cision a Ã©tÃ© prise.
                 logger.info(f"[{name}] ğŸ›‘ ArrÃªt du stream pour inactivitÃ©.")
                 channel_obj.stop_stream_if_needed()
            else:
                 logger.warning(f"[{name}] Impossible d'arrÃªter le stream (objet non trouvÃ© ou mÃ©thode manquante)." )

    def remove_channel(self, channel_name: str):
        """Supprime complÃ¨tement une chaÃ®ne et nettoie ses ressources."""
        logger.info(f"ğŸ—‘ï¸ Tentative de suppression complÃ¨te de la chaÃ®ne: {channel_name}")
        with self.scan_lock:
            # 1. ArrÃªter le stream et nettoyer les processus
            channel_obj = self.channels.pop(channel_name, None)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                logger.info(f"[{channel_name}] ArrÃªt du stream pour suppression...")
                channel_obj.stop_stream_if_needed()
            
            # 2. Supprimer du ChannelStatusManager
            if self.channel_status:
                self.channel_status.remove_channel(channel_name)
                logger.info(f"[{channel_name}] SupprimÃ© de ChannelStatusManager.")

            # 3. Supprimer du StatsCollector
            if self.stats_collector:
                self.stats_collector.remove_channel(channel_name)
                logger.info(f"[{channel_name}] SupprimÃ© de StatsCollector.")

            # 4. Nettoyer les fichiers HLS
            if self.hls_cleaner:
                self.hls_cleaner.cleanup_channel(channel_name)
                logger.info(f"[{channel_name}] Fichiers HLS nettoyÃ©s.")

            # 5. Mettre Ã  jour la playlist maÃ®tre
            self._update_master_playlist()
            
            logger.info(f"âœ… Suppression de la chaÃ®ne '{channel_name}' terminÃ©e.")
