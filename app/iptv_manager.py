# iptv_manager.py
import os
import sys
import time
import glob
import shutil
import signal
import random
import psutil
import traceback
import subprocess
from queue import Queue, Empty
from pathlib import Path
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
import threading
from event_handler import ChannelEventHandler, ReadyContentHandler
from hls_cleaner import HLSCleaner
from client_monitor import ClientMonitor
from resource_monitor import ResourceMonitor
from iptv_channel import IPTVChannel
import signal
from ffmpeg_monitor import FFmpegMonitor
from config import (
    CONTENT_DIR,
    NGINX_ACCESS_LOG,
    SERVER_URL,
    TIMEOUT_NO_VIEWERS,
    logger,
    VIDEO_EXTENSIONS,
    CPU_THRESHOLD,
    SEGMENT_AGE_THRESHOLD,
    SUMMARY_CYCLE,
    WATCHERS_LOG_CYCLE,
)
from stats_collector import StatsCollector


class IPTVManager:
    """
    Gestionnaire principal du service IPTV - version am√©lior√©e avec:
    - Meilleure gestion des dossiers
    - Lancement non bloquant des cha√Ænes
    - Meilleure d√©tection et gestion des fichiers
    """

    def __init__(self, content_dir: str, use_gpu: bool = False):
        # Assurons-nous que la valeur de USE_GPU est bien prise de l'environnement
        use_gpu_env = os.getenv("USE_GPU", "false").lower() == "true"
        if use_gpu != use_gpu_env:
            logger.warning(
                f"‚ö†Ô∏è Valeur USE_GPU en param√®tre ({use_gpu}) diff√©rente de l'environnement ({use_gpu_env}), on utilise celle de l'environnement"
            )
            use_gpu = use_gpu_env

        self.use_gpu = use_gpu
        logger.info(
            f"‚úÖ Acc√©l√©ration GPU: {'ACTIV√âE' if self.use_gpu else 'D√âSACTIV√âE'}"
        )

        self.ensure_hls_directory()  # Sans argument pour le dossier principal

        self.content_dir = content_dir
        self.use_gpu = use_gpu
        self.channels = {}
        self.channel_ready_status = {}  # Pour suivre l'√©tat de pr√©paration des cha√Ænes

        # Queue pour les cha√Ænes √† initialiser en parall√®le
        self.channel_init_queue = Queue()
        self.max_parallel_inits = 3  # Nombre max d'initialisations parall√®les
        self.active_init_threads = 0
        self.init_threads_lock = threading.Lock()

        # Moniteur FFmpeg
        self.ffmpeg_monitor = FFmpegMonitor(self.channels)
        self.ffmpeg_monitor.start()

        # On initialise le nettoyeur HLS avec le bon chemin
        self.hls_cleaner = HLSCleaner("/app/hls")
        self.hls_cleaner.initial_cleanup()
        self.hls_cleaner.start()

        self.scan_lock = threading.Lock()
        self.failing_channels = set()

        logger.info("Initialisation du gestionnaire IPTV am√©lior√©")
        self._clean_startup()

        # Observer
        self.observer = Observer()
        event_handler = ChannelEventHandler(self)

        # Surveillance du dossier racine en mode r√©cursif
        self.observer.schedule(event_handler, self.content_dir, recursive=True)
        logger.info(
            f"üëÅÔ∏è Observer configur√© pour surveiller {self.content_dir} en mode r√©cursif"
        )

        # NOUVEAU: Observer pour les dossiers ready_to_stream
        self.ready_observer = Observer()
        self.ready_event_handler = ReadyContentHandler(self)

        # D√©marrage du thread d'initialisation des cha√Ænes
        self.stop_init_thread = threading.Event()
        self.channel_init_thread = threading.Thread(
            target=self._process_channel_init_queue, daemon=True
        )
        self.channel_init_thread.start()

        # Moniteur clients
        logger.info(f"üöÄ D√©marrage du client_monitor avec {NGINX_ACCESS_LOG}")
        self.client_monitor = ClientMonitor(
            NGINX_ACCESS_LOG, self.update_watchers, self
        )

        # V√©rification explicite qu'on a bien acc√®s au fichier
        if os.path.exists(NGINX_ACCESS_LOG):
            try:
                with open(NGINX_ACCESS_LOG, "r") as f:
                    # On lit juste les derni√®res lignes pour voir si √ßa fonctionne
                    f.seek(max(0, os.path.getsize(NGINX_ACCESS_LOG) - 1000))
                    last_lines = f.readlines()
                    logger.info(
                        f"‚úÖ Lecture r√©ussie du fichier de log, {len(last_lines)} derni√®res lignes trouv√©es"
                    )
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de la lecture du fichier de log: {e}")

        # D√©marrage du client_monitor une seule fois
        self.client_monitor.start()

        # Thread de surveillance du log
        self._log_monitor_thread = threading.Thread(
            target=self._check_client_monitor, daemon=True
        )
        self._log_monitor_thread.start()

        # Moniteur ressources
        self.resource_monitor = ResourceMonitor()
        self.resource_monitor.start()

        # Thread de mise √† jour de la playlist ma√Ætre
        self.master_playlist_updater = threading.Thread(
            target=self._manage_master_playlist, daemon=True
        )
        self.master_playlist_updater.start()

        # Thread qui v√©rifie les watchers
        self.watchers_thread = threading.Thread(target=self._watchers_loop, daemon=True)
        self.running = True

        # statistiques
        # Dans la m√©thode __init__ de IPTVManager
        self.stats_collector = StatsCollector()
        # V√©rifier si le StatsCollector est correctement initialis√©
        if not hasattr(self.stats_collector, "stats") or not self.stats_collector.stats:
            logger.warning("‚ö†Ô∏è R√©initialisation du StatsCollector qui √©tait invalide")
            self.stats_collector = StatsCollector()

        # Forcer une sauvegarde initiale pour v√©rifier que tout fonctionne
        self.stats_collector.save_stats()
        self.stats_collector.save_user_stats()
        logger.info("‚úÖ StatsCollector initialis√© et v√©rifi√©")

    def _check_client_monitor(self):
        """V√©rifie p√©riodiquement l'√©tat du client_monitor"""
        while True:
            try:
                logger.info("üîç V√©rification de l'√©tat du client_monitor...")
                if (
                    not hasattr(self, "client_monitor")
                    or not self.client_monitor.is_alive()
                ):
                    logger.critical("üö® client_monitor n'est plus actif!")
                    # Tentative de red√©marrage
                    logger.info("ÔøΩ Tentative de red√©marrage du client_monitor...")
                    self.client_monitor = ClientMonitor(
                        NGINX_ACCESS_LOG, self.update_watchers, self
                    )
                    self.client_monitor.start()
            except Exception as e:
                logger.error(f"‚ùå Erreur v√©rification client_monitor: {e}")
            time.sleep(60)  # V√©rification toutes les minutes

    def _stats_reporting_loop(self):
        """Thread qui g√©n√®re p√©riodiquement un rapport des statistiques"""
        stats_report_interval = int(
            os.getenv("STATS_REPORT_INTERVAL", "300")
        )  # Toutes les 5 minutes par d√©faut

        while self.running:
            try:
                time.sleep(stats_report_interval)

                if not hasattr(self, "stats_collector") or not self.stats_collector:
                    logger.warning(
                        "‚ö†Ô∏è StatsCollector non disponible, rapport impossible"
                    )
                    continue

                # G√©n√©rer le rapport
                self._generate_stats_report()

            except Exception as e:
                logger.error(f"‚ùå Erreur dans la boucle de rapport stats: {e}")
                time.sleep(60)  # Attente plus longue en cas d'erreur

    def _generate_stats_report(self):
        """G√©n√®re un rapport de statistiques bas√© sur les donn√©es du StatsCollector"""
        try:
            stats = self.stats_collector

            # R√©cup√©rer les statistiques globales
            global_stats = stats.stats.get("global", {})
            total_watchers = global_stats.get("total_watchers", 0)
            peak_watchers = global_stats.get("peak_watchers", 0)
            total_watch_time = global_stats.get("total_watch_time", 0)

            # Formater le temps de visionnage
            hours = int(total_watch_time // 3600)
            minutes = int((total_watch_time % 3600) // 60)
            seconds = int(total_watch_time % 60)
            watch_time_formatted = f"{hours}h {minutes}m {seconds}s"

            # G√©n√©rer le rapport
            report_lines = [
                "üìä RAPPORT DE STATISTIQUES",
                f"Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}",
                f"Spectateurs actifs: {total_watchers}",
                f"Pic de spectateurs: {peak_watchers}",
                f"Temps de visionnage total: {watch_time_formatted}",
            ]

            # Statistiques par cha√Æne
            channels_stats = []
            for name, channel_data in stats.stats.get("channels", {}).items():
                current_watchers = channel_data.get("current_watchers", 0)
                peak_watchers = channel_data.get("peak_watchers", 0)
                watch_time = channel_data.get("total_watch_time", 0)

                # Ne montrer que les cha√Ænes avec activit√©
                if current_watchers > 0 or peak_watchers > 0 or watch_time > 0:
                    # Formater le temps de visionnage
                    hours = int(watch_time // 3600)
                    minutes = int((watch_time % 3600) // 60)
                    watch_time_formatted = f"{hours}h {minutes}m"

                    channels_stats.append(
                        {
                            "name": name,
                            "current": current_watchers,
                            "peak": peak_watchers,
                            "watch_time": watch_time,
                            "watch_time_formatted": watch_time_formatted,
                        }
                    )

            # Trier par nombre de spectateurs actuels
            channels_stats.sort(key=lambda x: (x["current"], x["peak"]), reverse=True)

            if channels_stats:
                report_lines.append("\nSTATISTIQUES PAR CHA√éNE:")
                for ch in channels_stats:
                    report_lines.append(
                        f"- {ch['name']}: {ch['current']} actifs (pic: {ch['peak']}, visionnage: {ch['watch_time_formatted']})"
                    )

            # Statistiques par utilisateur (IP)
            user_stats = stats.user_stats.get("users", {})

            if user_stats:
                # Limiter √† 10 utilisateurs les plus actifs pour √©viter des logs trop longs
                top_users = sorted(
                    [(ip, data) for ip, data in user_stats.items()],
                    key=lambda x: x[1].get("total_watch_time", 0),
                    reverse=True,
                )[:10]

                if top_users:
                    report_lines.append("\nTOP 10 UTILISATEURS (par IP):")
                    for ip, data in top_users:
                        watch_time = data.get("total_watch_time", 0)
                        hours = int(watch_time // 3600)
                        minutes = int((watch_time % 3600) // 60)
                        watch_time_formatted = f"{hours}h {minutes}m"

                        # Si on a des cha√Ænes pour cet utilisateur
                        user_channels = len(data.get("channels", {}))
                        favorite = "aucune"

                        for ch_name, ch_data in data.get("channels", {}).items():
                            if ch_data.get("favorite", False):
                                favorite = ch_name
                                break

                        report_lines.append(
                            f"- {ip}: {watch_time_formatted} sur {user_channels} cha√Ænes (favorite: {favorite})"
                        )

            # Afficher le rapport
            logger.info("\n".join(report_lines))

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration rapport stats: {e}")

    def _process_channel_init_queue(self):
        """Traite la queue d'initialisation des cha√Ænes en parall√®le"""
        while not self.stop_init_thread.is_set():
            try:
                # Limite le nombre d'initialisations parall√®les
                with self.init_threads_lock:
                    if self.active_init_threads >= self.max_parallel_inits:
                        time.sleep(0.5)
                        continue

                # Essaie de r√©cup√©rer une cha√Æne de la queue
                try:
                    channel_data = self.channel_init_queue.get(block=False)
                except Empty:
                    time.sleep(0.5)
                    continue

                # Incr√©mente le compteur de threads actifs
                with self.init_threads_lock:
                    self.active_init_threads += 1

                # Lance un thread pour initialiser cette cha√Æne
                threading.Thread(
                    target=self._init_channel_async, args=(channel_data,), daemon=True
                ).start()

            except Exception as e:
                logger.error(f"Erreur dans le thread d'initialisation: {e}")
                time.sleep(1)

    def _init_channel_async(self, channel_data):
        """Initialise une cha√Æne de mani√®re asynchrone"""
        try:
            channel_name = channel_data["name"]
            channel_dir = channel_data["dir"]

            logger.info(f"[{channel_name}] - Initialisation asynchrone de la cha√Æne: ")

            # Cr√©e l'objet cha√Æne
            channel = IPTVChannel(
                channel_name,
                str(channel_dir),
                hls_cleaner=self.hls_cleaner,
                use_gpu=self.use_gpu,
                stats_collector=self.stats_collector,  # Ajout du stats_collector
            )

            # Ajoute la cha√Æne au dictionnaire
            with self.scan_lock:
                self.channels[channel_name] = channel
                self.channel_ready_status[channel_name] = False  # Pas encore pr√™te

            # Attente que la cha√Æne soit pr√™te (max 30 secondes)
            for _ in range(30):
                if (
                    hasattr(channel, "ready_for_streaming")
                    and channel.ready_for_streaming
                ):
                    with self.scan_lock:
                        self.channel_ready_status[channel_name] = True
                    logger.info(f"‚úÖ Cha√Æne {channel_name} pr√™te pour le streaming")
                    break
                time.sleep(1)

        except Exception as e:
            logger.error(
                f"Erreur initialisation de la cha√Æne {channel_data.get('name')}: {e}"
            )
        finally:
            # D√©cr√©mente le compteur de threads actifs
            with self.init_threads_lock:
                self.active_init_threads -= 1

            # Marque la t√¢che comme termin√©e
            self.channel_init_queue.task_done()

    def auto_start_ready_channels(self):
        """D√©marre automatiquement toutes les cha√Ænes pr√™tes avec un d√©lai entre chaque d√©marrage"""
        logger.info("üöÄ D√©marrage automatique des cha√Ænes pr√™tes...")

        # Attendre que plus de cha√Ænes soient pr√™tes
        for attempt in range(3):
            ready_channels = []
            with self.scan_lock:
                for name, is_ready in self.channel_ready_status.items():
                    if is_ready and name in self.channels:
                        channel = self.channels[name]
                        if channel.ready_for_streaming:
                            ready_channels.append(name)

            if (
                len(ready_channels) >= len(self.channels) * 0.5
            ):  # Au moins 50% des cha√Ænes sont pr√™tes
                break

            logger.info(
                f"‚è≥ Seulement {len(ready_channels)}/{len(self.channels)} cha√Ænes pr√™tes, attente suppl√©mentaire ({attempt+1}/3)..."
            )
            time.sleep(10)  # 10 secondes d'attente par tentative

        # Trier pour pr√©visibilit√©
        ready_channels.sort()

        # Limiter le CPU pour √©viter saturation
        max_parallel = 4
        groups = [
            ready_channels[i : i + max_parallel]
            for i in range(0, len(ready_channels), max_parallel)
        ]

        for group_idx, group in enumerate(groups):
            logger.info(
                f"üöÄ D√©marrage du groupe {group_idx+1}/{len(groups)} ({len(group)} cha√Ænes)"
            )

            # D√©marrer chaque cha√Æne du groupe avec un petit d√©lai entre elles
            for i, channel_name in enumerate(group):
                delay = i * 3  # 3 secondes entre chaque cha√Æne du m√™me groupe
                threading.Timer(delay, self._start_channel, args=[channel_name]).start()
                logger.info(
                    f"[{channel_name}] ‚è±Ô∏è D√©marrage programm√© dans {delay} secondes"
                )

            # Attendre avant le prochain groupe
            if group_idx < len(groups) - 1:
                time.sleep(max_parallel * 5)  # 5 secondes par cha√Æne entre les groupes

        if ready_channels:
            logger.info(
                f"‚úÖ {len(ready_channels)} cha√Ænes programm√©es pour d√©marrage automatique"
            )
        else:
            logger.warning("‚ö†Ô∏è Aucune cha√Æne pr√™te √† d√©marrer")

    def _start_channel(self, channel_name):
        """D√©marre une cha√Æne sp√©cifique"""
        try:
            if channel_name in self.channels:
                channel = self.channels[channel_name]
                if channel.ready_for_streaming:
                    logger.info(f"[{channel_name}] üöÄ D√©marrage automatique...")
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] ‚úÖ D√©marrage automatique r√©ussi")
                    else:
                        logger.error(
                            f"[{channel_name}] ‚ùå √âchec du d√©marrage automatique"
                        )
                else:
                    logger.warning(
                        f"[{channel_name}] ‚ö†Ô∏è Non pr√™te pour le streaming, d√©marrage ignor√©"
                    )
        except Exception as e:
            logger.error(
                f"[{channel_name}] ‚ùå Erreur lors du d√©marrage automatique: {e}"
            )

    def _watchers_loop(self):
        """Surveille l'activit√© des watchers et arr√™te les streams inutilis√©s"""
        last_log_time = 0
        last_health_check = 0
        last_summary_time = 0  # Nouveau compteur pour le r√©capitulatif
        log_cycle = WATCHERS_LOG_CYCLE  # Augmenter √† 60s au lieu de 10s
        summary_cycle = SUMMARY_CYCLE  # 5 minutes par d√©faut

        while True:
            try:
                current_time = time.time()
                channels_to_stop = []

                # Ajout du health check toutes les 5 minutes
                if current_time - last_health_check > 300:  # 5 minutes
                    for channel_name, channel in self.channels.items():
                        if hasattr(channel, "channel_health_check"):
                            try:
                                channel.channel_health_check()
                            except Exception as e:
                                logger.error(
                                    f"[{channel_name}] ‚ùå Erreur health check: {e}"
                                )
                    last_health_check = current_time

                # G√©n√©rer le r√©capitulatif des cha√Ænes
                if current_time - last_summary_time > summary_cycle:
                    self._log_channels_summary()
                    last_summary_time = current_time

                # Pour chaque cha√Æne, on v√©rifie l'inactivit√©
                for channel_name, channel in self.channels.items():
                    if not hasattr(channel, "last_watcher_time"):
                        continue

                    # On calcule l'inactivit√©
                    inactivity_duration = current_time - channel.last_watcher_time

                    # Si inactif depuis plus de TIMEOUT_NO_VIEWERS
                    if inactivity_duration > TIMEOUT_NO_VIEWERS:
                        if channel.process_manager.is_running():
                            logger.warning(
                                f"[{channel_name}] ‚ö†Ô∏è Stream inactif depuis {inactivity_duration:.1f}s, arr√™t programm√©"
                            )
                            channels_to_stop.append(channel)

                # Arr√™t des cha√Ænes sans watchers (avec un d√©lai pour √©viter les cascades)
                for i, channel in enumerate(channels_to_stop):
                    # Ajout d'un petit d√©lai entre les arr√™ts (0.5s entre chaque)
                    time.sleep(i * 0.5)
                    channel.stop_stream_if_needed()

                # Log p√©riodique des watchers actifs (moins fr√©quent)
                if current_time - last_log_time > log_cycle:
                    active_channels = []
                    for name, channel in sorted(self.channels.items()):
                        if (
                            hasattr(channel, "watchers_count")
                            and channel.watchers_count > 0
                        ):
                            active_channels.append(f"{name}: {channel.watchers_count}")

                    if active_channels:
                        logger.info(
                            f"üë• Cha√Ænes avec viewers: {', '.join(active_channels)}"
                        )
                    last_log_time = current_time

                time.sleep(10)  # V√©rification toutes les 10s

            except Exception as e:
                logger.error(f"‚ùå Erreur watchers_loop: {e}")
                time.sleep(10)

    def update_watchers(self, channel_name: str, count: int, request_path: str):
        """Met √† jour les watchers en fonction des requ√™tes m3u8 et ts"""
        try:
            # Si c'est la playlist principale, pas besoin de traiter
            if channel_name == "master_playlist":
                return

            # V√©rifier si la cha√Æne existe
            if channel_name not in self.channels:
                logger.warning(f"‚ùå Cha√Æne inconnue: {channel_name}")
                return

            channel = self.channels[channel_name]

            # Log pour debug
            logger.info(
                f"[{channel_name}] üîÑ Mise √† jour watchers: {count} watchers, path={request_path}"
            )

            # Toujours mettre √† jour le timestamp de derni√®re activit√©
            channel.last_watcher_time = time.time()

            # Pour les requ√™tes de segments, mettre √† jour last_segment_time
            if ".ts" in request_path:
                channel.last_segment_time = time.time()

                # Si on a un StatsCollector, mettre √† jour stats de segment
                if hasattr(self, "stats_collector") and self.stats_collector:
                    # Extraction du segment ID
                    segment_match = re.search(r"segment_(\d+)\.ts", request_path)
                    if segment_match:
                        segment_id = segment_match.group(1)
                        # On ne conna√Æt pas la taille, donc on la fixe √† une valeur par d√©faut
                        self.stats_collector.update_segment_stats(
                            channel_name, segment_id, 100000
                        )

            old_count = getattr(channel, "watchers_count", 0)

            # MAJ du compteur s'il y a changement
            channel.watchers_count = count  # Toujours mettre √† jour

            # Mise √† jour des statistiques globales si StatsCollector existe
            if hasattr(self, "stats_collector") and self.stats_collector:
                self.stats_collector.update_channel_watchers(channel_name, count)

            # V√©rification de l'√©tat de la cha√Æne apr√®s mise √† jour
            logger.debug(
                f"[{channel_name}] √âtat apr√®s MAJ: watchers_count={getattr(channel, 'watchers_count', 0)}, "
                f"stream_running={channel.process_manager.is_running()}"
            )

            # D√©marrage du stream pour toute requ√™te playlist.m3u8 si le stream n'est pas d√©j√† actif
            if ".m3u8" in request_path and not channel.process_manager.is_running():
                logger.info(
                    f"[{channel_name}] üöÄ D√©marrage du stream suite √† une requ√™te playlist.m3u8"
                )
                channel.start_stream_if_needed()
            # Si on a des watchers mais pas de stream actif, d√©marrer aussi
            elif count > 0 and not channel.process_manager.is_running():
                logger.info(
                    f"[{channel_name}] üöÄ D√©marrage du stream car {count} watchers actifs"
                )
                channel.start_stream_if_needed()

        except Exception as e:
            logger.error(f"‚ùå Erreur update_watchers: {e}")
            import traceback

            logger.error(f"Stack trace: {traceback.format_exc()}")

    def _log_channels_summary(self):
        """G√©n√®re et affiche un r√©capitulatif de l'√©tat des cha√Ænes"""
        try:
            if not self.channels:
                logger.info("üìä Aucune cha√Æne disponible pour le r√©capitulatif")
                return

            # Organiser les cha√Ænes par √©tat
            active_with_viewers = []  # Cha√Ænes actives avec viewers
            active_without_viewers = []  # Cha√Ænes actives sans viewers
            stopped_channels = []  # Cha√Ænes arr√™t√©es

            for name, channel in sorted(self.channels.items()):
                watchers_count = getattr(channel, "watchers_count", 0)
                is_streaming = (
                    channel.process_manager.is_running()
                    if hasattr(channel, "process_manager")
                    else False
                )

                channel_info = {
                    "name": name,
                    "watchers": watchers_count,
                    "streaming": is_streaming,
                    "last_activity": getattr(channel, "last_watcher_time", 0),
                }

                if is_streaming:  # Si la cha√Æne est en streaming
                    if watchers_count > 0:  # Et qu'elle a des viewers
                        active_with_viewers.append(channel_info)
                    else:  # En streaming mais sans viewers
                        active_without_viewers.append(channel_info)
                else:  # Cha√Æne arr√™t√©e
                    stopped_channels.append(channel_info)

            # Construire le r√©capitulatif
            summary_lines = ["üìä R√âCAPITULATIF DES CHA√éNES:"]

            # Afficher les cha√Ænes actives avec viewers
            if active_with_viewers:
                active_parts = []
                for ch in active_with_viewers:
                    active_parts.append(f"üü¢ {ch['name']}: {ch['watchers']} viewers")

                summary_lines.append(
                    "CHA√éNES AVEC VIEWERS: " + " | ".join(active_parts)
                )
            else:
                summary_lines.append("CHA√éNES AVEC VIEWERS: Aucune")

            # Afficher les cha√Ænes actives sans viewers
            if active_without_viewers:
                inactive_parts = []
                for ch in active_without_viewers[
                    :5
                ]:  # Limiter √† 5 pour √©viter des logs trop longs
                    inactive_parts.append(f"{ch['name']}")

                remaining = len(active_without_viewers) - 5
                if remaining > 0:
                    inactive_parts.append(f"et {remaining} autres")

                summary_lines.append(
                    f"CHA√éNES ACTIVES SANS VIEWERS: {len(active_without_viewers)} ({', '.join(inactive_parts)})"
                )

            # Nombre total de cha√Ænes arr√™t√©es
            if stopped_channels:
                summary_lines.append(f"CHA√éNES ARR√äT√âES: {len(stopped_channels)}")

            # Stats globales
            total_viewers = sum(ch["watchers"] for ch in active_with_viewers)
            total_streams = len(active_with_viewers) + len(active_without_viewers)
            summary_lines.append(
                f"TOTAL: {total_viewers} viewers sur {total_streams} streams actifs ({len(self.channels)} cha√Ænes)"
            )

            # Afficher le r√©capitulatif
            logger.info("\n".join(summary_lines))

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©capitulatif: {e}")

    def _clean_startup(self):
        """Nettoie avant de d√©marrer"""
        try:
            logger.info("üßπ Nettoyage initial...")
            patterns_to_clean = [
                ("/app/hls/**/*", "Fichiers HLS"),
                ("/app/content/**/_playlist.txt", "Playlists"),
                ("/app/content/**/*.vtt", "Fichiers VTT"),
                ("/app/content/**/temp_*", "Fichiers temporaires"),
            ]
            for pattern, desc in patterns_to_clean:
                count = 0
                for f in glob.glob(pattern, recursive=True):
                    try:
                        if os.path.isfile(f):
                            os.remove(f)
                        elif os.path.isdir(f):
                            shutil.rmtree(f)
                        count += 1
                    except Exception as e:
                        logger.error(f"Erreur nettoyage {f}: {e}")
                logger.info(f"‚ú® {count} {desc} supprim√©s")
            os.makedirs("/app/hls", exist_ok=True)
        except Exception as e:
            logger.error(f"Erreur nettoyage initial: {e}")

    def scan_channels(self, force: bool = False, initial: bool = False):
        """
        Scanne le contenu pour d√©tecter les nouveaux dossiers (cha√Ænes).
        Version am√©lior√©e avec limitation de fr√©quence
        """
        # Limiter la fr√©quence des scans
        current_time = time.time()
        scan_cooldown = 30  # 30s entre scans complets (sauf si force=True)

        if (
            not force
            and not initial
            and hasattr(self, "last_scan_time")
            and current_time - self.last_scan_time < scan_cooldown
        ):
            logger.debug(
                f"Scan ignor√©: dernier scan il y a {current_time - self.last_scan_time:.1f}s"
            )
            return

        setattr(self, "last_scan_time", current_time)

        with self.scan_lock:
            try:
                content_path = Path(self.content_dir)
                if not content_path.exists():
                    logger.error(f"Le dossier {content_path} n'existe pas!")
                    return

                channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]

                logger.info(f"üì° Scan des cha√Ænes disponibles...")
                for channel_dir in channel_dirs:
                    channel_name = channel_dir.name

                    if channel_name in self.channels:
                        # Si la cha√Æne existe d√©j√†, on v√©rifie son √©tat
                        if force:
                            logger.info(
                                f"üîÑ Rafra√Æchissement de la cha√Æne {channel_name}"
                            )
                            channel = self.channels[channel_name]
                            if hasattr(channel, "refresh_videos"):
                                channel.refresh_videos()
                        else:
                            logger.info(f"‚úÖ Cha√Æne existante: {channel_name}")
                        continue

                    logger.info(f"‚úÖ Nouvelle cha√Æne trouv√©e: {channel_name}")

                    # Ajoute la cha√Æne √† la queue d'initialisation
                    self.channel_init_queue.put(
                        {"name": channel_name, "dir": channel_dir}
                    )

                logger.info(f"üì° Scan termin√©, {len(channel_dirs)} cha√Ænes identifi√©es")

            except Exception as e:
                logger.error(f"Erreur scan des cha√Ænes: {e}")

    def ensure_hls_directory(self, channel_name: str = None):
        """Cr√©e et configure les dossiers HLS avec les bonnes permissions"""
        try:
            # Dossier HLS principal
            base_hls = Path("/app/hls")
            if not base_hls.exists():
                logger.info("üìÇ Cr√©ation du dossier HLS principal...")
                base_hls.mkdir(parents=True, exist_ok=True)
                os.chmod(base_hls, 0o777)

            # Dossier sp√©cifique √† une cha√Æne si demand√©
            if channel_name:
                channel_hls = base_hls / channel_name
                if not channel_hls.exists():
                    logger.info(f"üìÇ Cr√©ation du dossier HLS pour {channel_name}")
                    channel_hls.mkdir(parents=True, exist_ok=True)
                    os.chmod(channel_hls, 0o777)
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation dossiers HLS: {e}")

    def _manage_master_playlist(self):
        """
        G√®re la cr√©ation et mise √† jour de la playlist principale.
        Cette m√©thode tourne en boucle et reg√©n√®re la playlist toutes les 60s,
        ou peut √™tre appel√©e explicitement apr√®s un changement.
        """
        # Si c'est un appel direct (apr√®s mise √† jour d'une cha√Æne), faire une mise √† jour unique
        if threading.current_thread() != self.master_playlist_updater:
            try:
                self._update_master_playlist()
                return
            except Exception as e:
                logger.error(f"Erreur mise √† jour ponctuelle de la playlist: {e}")
                return

        # Sinon, c'est la boucle normale
        while True:
            try:
                self._update_master_playlist()
                time.sleep(60)  # On attend 60s avant la prochaine mise √† jour
            except Exception as e:
                logger.error(f"Erreur maj master playlist: {e}")
                logger.error(traceback.format_exc())
                time.sleep(60)  # On attend m√™me en cas d'erreur

    def _update_master_playlist(self):
        """Effectue la mise √† jour de la playlist principale"""
        playlist_path = os.path.abspath("/app/hls/playlist.m3u")
        logger.info(f"üîÑ Master playlist maj.: {playlist_path}")

        with open(playlist_path, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")

            # Re-v√©rifie chaque cha√Æne pour confirmer qu'elle est pr√™te
            with self.scan_lock:
                for name, channel in self.channels.items():
                    # V√©rification directe des fichiers
                    ready_dir = Path(channel.video_dir) / "ready_to_stream"
                    has_videos = (
                        list(ready_dir.glob("*.mp4")) if ready_dir.exists() else []
                    )

                    # Mise √† jour du statut si n√©cessaire
                    if has_videos and not self.channel_ready_status.get(name, False):
                        logger.info(
                            f"[{name}] üîÑ Mise √† jour auto du statut: cha√Æne pr√™te (vid√©os trouv√©es)"
                        )
                        self.channel_ready_status[name] = True
                        channel.ready_for_streaming = True
                    elif not has_videos and self.channel_ready_status.get(name, False):
                        logger.info(
                            f"[{name}] ‚ö†Ô∏è Mise √† jour auto du statut: cha√Æne non pr√™te (aucune vid√©o)"
                        )
                        self.channel_ready_status[name] = False
                        channel.ready_for_streaming = False

            # Ne r√©f√©rence que les cha√Ænes pr√™tes
            ready_channels = []
            for name, channel in sorted(self.channels.items()):
                if (
                    name in self.channel_ready_status
                    and self.channel_ready_status[name]
                ):
                    ready_channels.append((name, channel))

            # √âcriture des cha√Ænes pr√™tes
            for name, channel in ready_channels:
                f.write(f'#EXTINF:-1 tvg-id="{name}" tvg-name="{name}",{name}\n')
                f.write(f"http://{SERVER_URL}/hls/{name}/playlist.m3u8\n")

        logger.info(
            f"Playlist mise √† jour ({len(ready_channels)} cha√Ænes pr√™tes sur {len(self.channels)} totales)"
        )

    def cleanup(self):
        logger.info("D√©but du nettoyage...")

        # Arr√™t du StatsCollector
        if hasattr(self, "stats_collector"):
            self.stats_collector.stop()

        # Arr√™t du thread d'initialisation
        self.stop_init_thread.set()

        if hasattr(self, "channel_init_thread") and self.channel_init_thread.is_alive():
            self.channel_init_thread.join(timeout=5)

        if hasattr(self, "hls_cleaner"):
            self.hls_cleaner.stop()

        if hasattr(self, "observer"):
            self.observer.stop()
            self.observer.join()

        if hasattr(self, "ready_observer"):
            self.ready_observer.stop()
            self.ready_observer.join()

        for name, channel in self.channels.items():
            channel._clean_processes()

        if hasattr(self, "scan_thread_stop"):
            self.scan_thread_stop.set()

        if hasattr(self, "scan_thread") and self.scan_thread.is_alive():
            self.scan_thread.join(timeout=5)

        logger.info("Nettoyage termin√©")

    def _setup_ready_observer(self):
        """Configure l'observateur pour les dossiers ready_to_stream de chaque cha√Æne"""
        try:
            # D'abord, arr√™ter et recr√©er l'observateur si n√©cessaire pour √©viter les doublons
            if hasattr(self, "ready_observer") and self.ready_observer.is_alive():
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)

            self.ready_observer = Observer()

            # Pour chaque cha√Æne existante
            paths_scheduled = set()  # Pour √©viter les doublons

            for name, channel in self.channels.items():
                ready_dir = Path(channel.video_dir) / "ready_to_stream"
                ready_dir.mkdir(
                    parents=True, exist_ok=True
                )  # S'assurer que le dossier existe

                if ready_dir.exists() and str(ready_dir) not in paths_scheduled:
                    self.ready_observer.schedule(
                        self.ready_event_handler, str(ready_dir), recursive=False
                    )
                    paths_scheduled.add(str(ready_dir))
                    logger.debug(
                        f"üëÅÔ∏è Surveillance ready_to_stream configur√©e pour {name}: {ready_dir}"
                    )

            # D√©marrage de l'observateur
            self.ready_observer.start()
            logger.info(
                f"üöÄ Observateur ready_to_stream d√©marr√© pour {len(paths_scheduled)} chemins"
            )

        except Exception as e:
            logger.error(f"‚ùå Erreur configuration surveillance ready_to_stream: {e}")
            import traceback

            logger.error(traceback.format_exc())

    def process_new_log_lines(self):
        """Traite les nouvelles lignes ajout√©es au fichier de log nginx"""
        try:
            # V√©rification de l'existence du fichier
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log introuvable: {self.log_path}")
                return False

            # Initialisation de la position si c'est la premi√®re ex√©cution
            if not hasattr(self, "last_position"):
                # On se met √† la fin du fichier pour ne traiter que les nouvelles lignes
                with open(self.log_path, "r") as f:
                    f.seek(0, 2)  # Positionnement √† la fin
                    self.last_position = f.tell()
                return True

            file_size = os.path.getsize(self.log_path)

            # Si le fichier a √©t√© rotat√© (taille plus petite qu'avant)
            if file_size < self.last_position:
                logger.warning(f"‚ö†Ô∏è D√©tection rotation log: {self.log_path}")
                self.last_position = 0  # On repart du d√©but

            # Lecture des nouvelles lignes
            with open(self.log_path, "r") as f:
                f.seek(self.last_position)
                new_lines = f.readlines()

                # Mise √† jour de la position
                self.last_position = f.tell()

                # Traitement des nouvelles lignes
                channel_updates = {}  # {channel_name: count}
                for line in new_lines:
                    if not line.strip():
                        continue

                    # Traiter la ligne
                    ip, channel, request_type, is_valid, _ = self._parse_access_log(
                        line
                    )

                    if is_valid and channel:
                        # On met √† jour le timestamp pour ce watcher
                        current_time = time.time()
                        self.watchers[(channel, ip)] = current_time

                        # Regrouper par cha√Æne pour ne faire qu'une mise √† jour
                        if channel not in channel_updates:
                            channel_updates[channel] = set()
                        channel_updates[channel].add(ip)

                # Mise √† jour group√©e par cha√Æne
                for channel, ips in channel_updates.items():
                    count = len(ips)
                    logger.info(
                        f"[{channel}] üëÅÔ∏è MAJ watchers: {count} actifs - {list(ips)}"
                    )
                    self.update_watchers(channel, count, "/hls/")

                return True

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement nouvelles lignes: {e}")
            import traceback

            logger.error(traceback.format_exc())
            return False

    def _monitor_nginx_logs(self):
        """Surveillance des logs nginx en temps r√©el avec inotify"""
        try:
            import pyinotify  # Il faudra ajouter cette d√©pendance

            # Chemin du log
            log_path = NGINX_ACCESS_LOG

            # Configuration de l'√©v√©nement
            class LogHandler(pyinotify.ProcessEvent):
                def __init__(self, manager):
                    self.manager = manager
                    self.client_monitor = manager.client_monitor

                def process_IN_MODIFY(self, event):
                    # Le fichier a √©t√© modifi√©, traiter les nouvelles lignes
                    self.client_monitor.process_new_log_lines()

            # Initialiser le watcher
            wm = pyinotify.WatchManager()
            handler = LogHandler(self)
            notifier = pyinotify.Notifier(wm, handler)

            # Ajouter le fichier √† surveiller
            wm.add_watch(log_path, pyinotify.IN_MODIFY)

            logger.info(f"üîç Surveillance en temps r√©el des logs nginx: {log_path}")

            # Boucle de surveillance (bloquante)
            notifier.loop()

        except ImportError:
            logger.error(
                "‚ùå Module pyinotify manquant, fallback au mode de surveillance legacy"
            )
            # Fallback √† l'ancien syst√®me
            self._legacy_watchers_loop()
        except Exception as e:
            logger.error(f"‚ùå Erreur surveillance logs: {e}")
            # Fallback √† l'ancien syst√®me
            self._legacy_watchers_loop()

    def run(self):
        try:
            # D√©marrer la boucle de surveillance des watchers
            if not self.watchers_thread.is_alive():
                self.watchers_thread.start()
                logger.info("üîÑ Boucle de surveillance des watchers d√©marr√©e")

            logger.debug("üì• Scan initial des cha√Ænes...")
            self.scan_channels(initial=True)  # Marquer comme scan initial

            logger.debug("üïµÔ∏è D√©marrage de l'observer...")
            if not self.observer.is_alive():
                self.observer.start()

            # Configurer l'observateur pour ready_to_stream
            self._setup_ready_observer()

            # Attente suffisamment longue pour l'initialisation des cha√Ænes
            logger.info(
                "‚è≥ Attente de 30 secondes pour l'initialisation des cha√Ænes..."
            )
            time.sleep(30)

            # D√©marrage automatique des cha√Ænes pr√™tes
            self.auto_start_ready_channels()

            while True:
                time.sleep(1)

        except KeyboardInterrupt:
            self.cleanup()
        except Exception as e:
            logger.error(f"üî• Erreur manager : {e}")
            self.cleanup()
