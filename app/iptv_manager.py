# iptv_manager.py
import os
import sys
import time
import glob
import shutil
import signal
import random
import psutil
import traceback
import subprocess
from queue import Queue, Empty
from pathlib import Path
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
import threading
from file_event_handler import FileEventHandler
from ready_content_handler import ReadyContentHandler
from hls_cleaner import HLSCleaner
# SUPPRIM√â: from client_monitor import ClientMonitor
# ClientMonitor a √©t√© fusionn√© dans StatsCollector
from iptv_channel import IPTVChannel
import signal
from ffmpeg_monitor import FFmpegMonitor
from config import (
    CONTENT_DIR,
    NGINX_ACCESS_LOG,
    SERVER_URL,
    logger,
    VIDEO_EXTENSIONS,
    CPU_THRESHOLD,
    SEGMENT_AGE_THRESHOLD,
    SUMMARY_CYCLE,
    WATCHERS_LOG_CYCLE,
    CHANNELS_STATUS_FILE,
    HLS_DIR,
)
from stats_collector import StatsCollector
from channel_status_manager import ChannelStatusManager
import json
import re
from log_utils import parse_access_log
from typing import Optional
from datetime import datetime


class IPTVManager:
    """Gestionnaire centralis√© des cha√Ænes IPTV"""

    def __init__(self, content_dir: str, use_gpu: bool = False):
        # Assurons-nous que la valeur de USE_GPU est bien prise de l'environnement
        use_gpu_env = os.getenv("USE_GPU", "false").lower() == "true"
        
        # Configuration
        self.content_dir = content_dir
        self.use_gpu = use_gpu or use_gpu_env
        self.channels = {}
        self.channel_ready_status = {}
        self.log_path = NGINX_ACCESS_LOG
        
        # >>> FIX: Initialize hls_cleaner EARLY <<<
        # On initialise le nettoyeur HLS avec le bon chemin
        self.hls_cleaner = HLSCleaner(HLS_DIR)
        # Le nettoyage HLS initial sera fait dans _clean_startup
        
        # >>> STEP 1: Clean startup FIRST to reset status file
        logger.info("Initialisation du gestionnaire IPTV am√©lior√©")
        self._clean_startup()
        # <<< END STEP 1
        
        # Initialize ready_event_handler first
        try:
            self.ready_event_handler = ReadyContentHandler(self)
            logger.info("‚úÖ ReadyContentHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing ReadyContentHandler: {e}")
            self.ready_event_handler = None
        
        # Initialize file_event_handler
        try:
            self.file_event_handler = FileEventHandler(self)
            logger.info("‚úÖ FileEventHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing FileEventHandler: {e}")
            self.file_event_handler = None
        
        # Initialisation de last_position pour le suivi des logs
        self.last_position = 0
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                f.seek(0, 2)
                self.last_position = f.tell()
                logger.info(f"üìù Position initiale de lecture des logs: {self.last_position} bytes")

        # Tracking du temps de d√©marrage pour les m√©triques
        self.startup_time = time.time()

        # Verrou et cooldown pour les scans
        self.scan_lock = threading.RLock()
        self.scan_cooldown = 60
        self.last_scan_time = 0
        self.scan_queue = Queue()
        self.failing_channels = set()

        # Queue pour les cha√Ænes √† initialiser en parall√®le
        self.channel_init_queue = Queue()
        self.max_parallel_inits = 60  # Augment√© de 15 √† 60 pour supporter plus de cha√Ænes
        self.active_init_threads = 0
        self.init_threads_lock = threading.RLock()

        # Batch update de la playlist pour √©viter les updates r√©p√©titives
        self.playlist_update_pending = False
        self.playlist_update_lock = threading.RLock()  # RLock pour permettre la r√©-entrance
        self.last_playlist_update = 0

        # Timeout d'inactivit√© pour arr√™ter un stream (en secondes)
        self.channel_inactivity_timeout = 300 # 5 minutes
        self.last_inactivity_check = 0

        # Initialisation des √©v√©nements d'arr√™t (DOIT √™tre fait AVANT le d√©marrage des threads)
        self.stop_event = threading.Event()  # √âv√©nement principal d'arr√™t
        self.stop_scan_thread = threading.Event()
        self.stop_init_thread = threading.Event()
        self.stop_periodic_scan = threading.Event()  # Pour arr√™ter le scan p√©riodique
        self.periodic_scan_interval = 300  # 5 minutes entre chaque scan p√©riodique

        # >>> STEP 2: Initialize channel status manager AFTER cleaning
        self.channel_status = None  # Initialiser √† None
        # >>> FIX: Call init_channel_status_manager method <<<
        self.init_channel_status_manager() 
        # <<< END STEP 2

        # MODIFI√â: StatsCollector et ClientMonitor seront initialis√©s apr√®s que les cha√Ænes soient pr√™tes
        try:
            # NOUVEAU: Obtenir les canaux valides depuis la playlist ma√Ætre comme source de v√©rit√©
            master_playlist_path = Path(HLS_DIR) / "playlist.m3u"
            valid_channels = set()
            if master_playlist_path.exists():
                with open(master_playlist_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        # Chercher les URLs des playlists des canaux
                        match = re.search(r'/hls/([^/]+)/playlist\.m3u8', line)
                        if match:
                            valid_channels.add(match.group(1))
                logger.info(f"Trouv√© {len(valid_channels)} canaux valides dans la playlist ma√Ætre pour le nettoyage initial des stats.")
            else:
                logger.warning(f"Playlist ma√Ætre non trouv√©e √† {master_playlist_path}. Le nettoyage des stats pourrait √™tre incomplet.")

            # Initialiser StatsCollector en lui passant les canaux valides pour un nettoyage imm√©diat
            self.stats_collector = StatsCollector(manager=self, valid_channels=valid_channels)
            # Passer le callback update_watchers m√™me avant l'initialisation compl√®te
            self.stats_collector.update_watchers_callback = self.update_watchers
            logger.info("üìä StatsCollector initialis√© avec succ√®s (avec nettoyage initial bas√© sur la playlist ma√Ætre)")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation initiale de StatsCollector: {e}")
            # Cr√©er un objet vide pour √©viter les erreurs None
            from types import SimpleNamespace
            self.stats_collector = SimpleNamespace()
            self.stats_collector.update_watchers_callback = lambda *args, **kwargs: None  # Fonction vide

        # SUPPRIM√â: self.client_monitor (fusionn√© dans StatsCollector)

        # Moniteur FFmpeg
        self.ffmpeg_monitor = FFmpegMonitor(self.channels)
        self.ffmpeg_monitor.start()

        # On initialise le nettoyeur HLS avec le bon chemin
        # HLS Cleaner is already initialized above

        # Thread de scan unifi√©
        self.scan_thread = threading.Thread(
            target=self._scan_worker,
            daemon=True
        )

        # Thread d'initialisation des cha√Ænes
        self.channel_init_thread = threading.Thread(
            target=self._process_channel_init_queue,
            daemon=True
        )

        # Thread de mise √† jour p√©riodique de la playlist ma√Ætre
        self.periodic_update_thread = threading.Thread(
            target=self._periodic_force_playlist_update,
            daemon=True,
            name="PeriodicPlaylistUpdate"
        )

        # Observer
        self.observer = Observer()
        event_handler = FileEventHandler(self)
        self.observer.schedule(event_handler, self.content_dir, recursive=True)
        logger.info(f"üëÅÔ∏è Observer configur√© pour surveiller {self.content_dir} en mode r√©cursif")

        # D√©marrage des threads dans l'ordre correct
        self.scan_thread.start()
        logger.info("üîÑ Thread de scan unifi√© d√©marr√©")

        self.channel_init_thread.start()
        logger.info("üîÑ Thread d'initialisation des cha√Ænes d√©marr√©")

        self.periodic_update_thread.start()
        logger.info("üîÑ Thread de mise √† jour p√©riodique de la playlist d√©marr√©")

        # Le thread de nettoyage a √©t√© supprim√© car le nettoyage est bas√© sur les logs via ClientMonitor
        # self.cleanup_thread.start()
        # logger.info("üßπ Thread de nettoyage des watchers d√©marr√©")

        # Force un scan initial
        logger.info("üîç For√ßage du scan initial des cha√Ænes...")
        self._do_scan(force=True)
        logger.info("‚úÖ Scan initial termin√©")

        # >>> STEP 3: REMOVE second _clean_startup call
        # _clean_startup called only once at the beginning now
        # self._clean_startup()
        # <<< END STEP 3

        # Mise √† jour finale de la playlist apr√®s que tous les streams soient lanc√©s
        def final_playlist_update():
            try:
                logger.info("‚è≥ Attente de 30 secondes pour que tous les streams d√©marrent...")
                time.sleep(30)
                logger.info("üîÑ Mise √† jour finale de la playlist apr√®s initialisation compl√®te")
                logger.info("üîÑ Appel de _update_master_playlist()...")
                self._update_master_playlist()
                logger.info("‚úÖ Mise √† jour finale de la playlist termin√©e")
            except Exception as e:
                logger.error(f"‚ùå Erreur dans final_playlist_update: {e}")
                import traceback
                logger.error(traceback.format_exc())

        threading.Thread(target=final_playlist_update, daemon=True, name="FinalPlaylistUpdate").start()

        last_scan_time = time.time()
        last_summary_time = time.time()
        last_resync_time = time.time()
        last_log_watchers_time = time.time()
        last_process_logs_time = time.time()  # Pour traiter les logs r√©guli√®rement

    def request_scan(self, force: bool = False):
        """Demande un scan en le mettant dans la queue"""
        self.scan_queue.put(force)
        logger.debug("Scan demand√©" + (" (forc√©)" if force else ""))

    def _scan_worker(self):
        """Thread qui g√®re les scans de mani√®re centralis√©e"""
        logger.info("üîç D√©marrage du thread de scan worker")
        while not self.stop_scan_thread.is_set():
            try:
                # Attendre une demande de scan ou le d√©lai p√©riodique
                try:
                    force = self.scan_queue.get(timeout=30)  # 30 secondes de d√©lai par d√©faut
                except Empty:  # Fixed: Using imported Empty instead of Queue.Empty
                    force = False  # Scan p√©riodique normal

                current_time = time.time()
                
                # V√©rifier le cooldown sauf si scan forc√©
                if not force and (current_time - self.last_scan_time) < 15:
                    logger.debug("‚è≠Ô∏è Scan ignor√© (cooldown)")
                    continue

                with self.scan_lock:
                    logger.info("üîç D√©marrage du scan" + (" forc√©" if force else ""))
                    self._do_scan(force)
                    self.last_scan_time = time.time()

                # --- V√©rification p√©riodique des cha√Ænes inactives ---
                if current_time - self.last_inactivity_check > 60: # V√©rifier toutes les 60 secondes
                    self._check_inactive_channels()
                    self.last_inactivity_check = current_time
                # -----------------------------------------------------

            except Exception as e:
                logger.error(f"‚ùå Erreur dans le thread de scan: {e}")
                time.sleep(5)

    def _do_scan(self, force: bool = False):
        """Effectue le scan r√©el des cha√Ænes et r√©concilie avec les statistiques."""
        try:
            # Compter les cha√Ænes avant scan
            channels_before = len(self.channels)

            content_path = Path(self.content_dir)
            if not content_path.exists():
                logger.error(f"Le dossier de contenu {content_path} n'existe pas!")
                return

            # 1. Obtenir tous les r√©pertoires du syst√®me de fichiers
            channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
            found_on_disk = {d.name for d in channel_dirs}
            logger.info(f"üìÇ {len(found_on_disk)} dossiers de cha√Ænes trouv√©s sur le disque.")

            # 2. Obtenir tous les canaux des statistiques et les r√©concilier
            with self.scan_lock:
                if self.stats_collector:
                    stats_known_channels = set(self.stats_collector.channel_stats.keys())
                    stats_known_channels.discard("global")
                else:
                    stats_known_channels = set()

                # 3. Calculer la diff√©rence
                removed_channels = stats_known_channels - found_on_disk
                if removed_channels:
                    logger.info(f"üóëÔ∏è Cha√Ænes obsol√®tes √† supprimer des stats: {removed_channels}")
                    # 4. Supprimer les canaux obsol√®tes
                    for removed_name in removed_channels:
                        self.remove_channel(removed_name)

            # 5. Parcourir les r√©pertoires du syst√®me de fichiers pour ajouter/mettre √† jour les canaux
            for channel_dir in channel_dirs:
                channel_name = channel_dir.name

                # V√©rifier que le dossier ready_to_stream existe et contient des vid√©os
                ready_dir = channel_dir / "ready_to_stream"
                if not ready_dir.exists():
                    logger.warning(f"‚ö†Ô∏è Dossier ignor√© '{channel_name}': pas de dossier ready_to_stream")
                    continue

                # V√©rifier qu'il y a au moins un fichier vid√©o
                video_extensions = {'.mp4', '.mkv', '.avi', '.mov', '.flv', '.wmv', '.m4v', '.ts'}
                video_files = [f for f in ready_dir.iterdir() if f.is_file() and f.suffix.lower() in video_extensions]

                if not video_files:
                    logger.warning(f"‚ö†Ô∏è Dossier ignor√© '{channel_name}': aucune vid√©o dans ready_to_stream")
                    continue

                with self.scan_lock:
                    if channel_name in self.channels:
                        if force:
                            logger.info(f"üîÑ Scan forc√© : Cha√Æne existante {channel_name} - rafra√Æchissement √©ventuel g√©r√© par la cha√Æne elle-m√™me.")
                            channel = self.channels[channel_name]
                            if hasattr(channel, "refresh_videos"):
                                channel.refresh_videos()
                        continue
                    else:
                        self.channels[channel_name] = None
                        logger.debug(f"[{channel_name}] Ajout d'un placeholder √† self.channels.")

                logger.info(f"‚úÖ Nouvelle cha√Æne d√©tect√©e : {channel_name}")

                logger.info(f"‚è≥ Mise en file d'attente pour initialisation de la cha√Æne {channel_name}")
                self.channel_init_queue.put({
                    "name": channel_name,
                    "dir": channel_dir,
                    "from_queue": True
                })

            # Compter les cha√Ænes apr√®s scan
            channels_after = len(self.channels)

            # Mettre √† jour la playlist ma√Ætre apr√®s la r√©conciliation
            if channels_after != channels_before:
                logger.info(
                    f"üìä Nombre de cha√Ænes chang√©: {channels_before} ‚Üí {channels_after}, "
                    "mise √† jour de la playlist"
                )
                self._update_master_playlist()
            else:
                # Mise √† jour normale m√™me si le nombre n'a pas chang√©
                self._update_master_playlist()

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du scan des cha√Ænes: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire IPTV"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        
        # Utiliser la m√©thode compl√®te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("üõë Gestionnaire IPTV arr√™t√© avec succ√®s")

    def update_watchers(self, channel_name: str, watcher_count: int, active_ips_list: list, path: str = "/hls/", source: str = 'unknown'):
        """
        Met √† jour le statut d'une cha√Æne (nombre de watchers, IPs) suite √† une notification
        du ClientMonitor (bas√© sur les logs Nginx).
        Met directement √† jour le ChannelStatusManager.
        
        Args:
            channel_name: Nom de la cha√Æne.
            watcher_count: Nombre actuel de watchers pour cette cha√Æne.
            active_ips_list: Liste des IPs des watchers actifs.
            path: (Ignor√©, conserv√© pour compatibilit√© potentielle)
            source: Source de la mise √† jour: 'nginx_log', 'nginx_log_immediate', etc.
        """
        # Ignorer la playlist ma√Ætre
        if channel_name == "master_playlist":
            return True

        # V√©rifier si le ChannelStatusManager est disponible
        if not hasattr(self, "channel_status") or self.channel_status is None:
            # Log une seule fois pour √©viter le spam
            if not getattr(self, "_logged_csm_missing", False):
                logger.warning("‚ö†Ô∏è ChannelStatusManager non disponible dans update_watchers. Impossible de mettre √† jour le statut.")
                self._logged_csm_missing = True
            return False
        else:
            # R√©initialiser le flag de log si CSM est √† nouveau disponible
            self._logged_csm_missing = False

        try:
            # Forcer une mise √† jour M√äME si les viewers n'ont pas chang√©
            # C'est crucial pour maintenir les canaux actifs √† jour
            
            # Log diff√©rent selon que c'est une mise √† jour imm√©diate ou p√©riodique
            if source == 'nginx_log_immediate':
                logger.info(f"[{channel_name}] üîÑ Mise √† jour IMM√âDIATE: {watcher_count} watchers")
            else:
                logger.debug(f"[{channel_name}] Callback update_watchers: {watcher_count} watchers (Source: {source})")
            
            # Pr√©parer les donn√©es pour ChannelStatusManager
            # On suppose que si ClientMonitor notifie, la cha√Æne est consid√©r√©e 'live'
            # ou du moins potentiellement active si des watchers sont pr√©sents.
            channel_obj = self.channels.get(channel_name)
            is_live_status = False
            current_video_name = None

            if channel_obj:
                is_live_status = (hasattr(channel_obj, 'is_ready_for_streaming') and channel_obj.is_ready_for_streaming())

                # R√©cup√©rer le nom du fichier vid√©o en cours
                if hasattr(channel_obj, 'processed_videos') and hasattr(channel_obj, 'current_video_index'):
                    try:
                        if channel_obj.processed_videos and 0 <= channel_obj.current_video_index < len(channel_obj.processed_videos):
                            current_video_path = channel_obj.processed_videos[channel_obj.current_video_index]
                            # Extraire le nom du fichier sans extension
                            current_video_name = current_video_path.stem if hasattr(current_video_path, 'stem') else str(current_video_path.name).rsplit('.', 1)[0]
                    except Exception as e:
                        logger.debug(f"[{channel_name}] Erreur r√©cup√©ration nom vid√©o dans update_watchers: {e}")

            # Pour les canaux avec des watchers actifs, toujours les marquer comme actifs
            # m√™me si le canal n'est pas techniquement "streaming"
            if watcher_count > 0:
                is_live_status = True

            status_data = {
                "is_live": is_live_status,
                "viewers": watcher_count,
                "watchers": active_ips_list,
                "current_video": current_video_name,
                "last_updated": datetime.now().isoformat()
            }
            
            # Forcer la sauvegarde si le nombre de spectateurs a chang√©.
            current_status = self.channel_status.channels.get(channel_name, {})
            previous_viewers = current_status.get("viewers", 0)
            viewers_changed = (watcher_count != previous_viewers)

            # Forcer la sauvegarde imm√©diate si les viewers ont chang√© ou si la source le demande
            force_immediate_save = viewers_changed or (source == 'nginx_log_immediate')

            # Mettre √† jour directement le ChannelStatusManager
            success = self.channel_status.update_channel(
                channel_name,
                status_data,
                force_save=force_immediate_save
            )
            
            if success:
                if source == 'nginx_log_immediate':
                    logger.info(f"[{channel_name}] ‚úÖ Mise √† jour IMM√âDIATE r√©ussie dans ChannelStatusManager")
                else:
                    logger.debug(f"[{channel_name}] ‚úÖ Statut mis √† jour dans ChannelStatusManager (Viewers: {watcher_count})")
                return True
            else:
                logger.warning(f"[{channel_name}] ‚ö†Ô∏è √âchec de la mise √† jour du statut via ChannelStatusManager.")
                return False
                
        except Exception as e:
            logger.error(f"[{channel_name}] ‚ùå Erreur dans update_watchers: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _log_channels_summary(self):
        """G√©n√®re et affiche un r√©capitulatif de l'√©tat des cha√Ænes bas√© sur ChannelStatusManager"""
        try:
            # Utiliser self.channel_status comme source de v√©rit√©
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.info("üìä ChannelStatusManager non disponible pour le r√©capitulatif")
                return

            # Lire l'√©tat actuel des cha√Ænes depuis ChannelStatusManager
            # Acc√®s direct, le manager interne g√®re les verrous pour les √©critures
            current_statuses = self.channel_status.channels
            manager_known_channels = list(self.channels.keys()) # Cha√Ænes connues par IPTVManager

            if not manager_known_channels:
                logger.info("üìä Aucune cha√Æne g√©r√©e par IPTVManager pour le r√©capitulatif")
                return

            # Organiser les cha√Ænes par √©tat bas√© sur current_statuses
            live_with_viewers = []
            live_without_viewers = []
            not_live_channels = []

            for name in sorted(manager_known_channels):
                status = current_statuses.get(name, {}) # Obtenir le statut ou un dict vide
                is_live = status.get('is_live', False)
                viewers_count = status.get('viewers', 0)
                watchers_list = status.get('watchers', [])

                channel_info = {
                    "name": name,
                    "viewers": viewers_count,
                    "is_live": is_live,
                    "watchers": watchers_list
                }

                if is_live:
                    if viewers_count > 0:
                        live_with_viewers.append(channel_info)
                    else:
                        live_without_viewers.append(channel_info)
                else:
                    # Inclut les cha√Ænes explicitement non live et celles inconnues du status manager
                    not_live_channels.append(channel_info)

            # Construire le r√©capitulatif
            summary_lines = ["üìä R√âCAPITULATIF DES CHA√éNES (via ChannelStatusManager):"]

            # Afficher les cha√Ænes live avec viewers
            if live_with_viewers:
                active_parts = []
                for ch in live_with_viewers:
                    active_parts.append(f"üü¢ {ch['name']}: {ch['viewers']} viewers")
                summary_lines.append(
                    "CHA√éNES LIVE AVEC VIEWERS: " + " | ".join(active_parts)
                )
            else:
                summary_lines.append("CHA√éNES LIVE AVEC VIEWERS: Aucune")

            # Afficher les cha√Ænes live sans viewers
            if live_without_viewers:
                inactive_parts = []
                for ch in live_without_viewers[:10]: # Limiter pour √©viter logs trop longs
                    inactive_parts.append(f"{ch['name']}")
                remaining = len(live_without_viewers) - 10
                if remaining > 0:
                    inactive_parts.append(f"et {remaining} autres")
                summary_lines.append(
                    f"CHA√éNES LIVE SANS VIEWERS: {len(live_without_viewers)} ({', '.join(inactive_parts)})"
                )
            else:
                summary_lines.append("CHA√éNES LIVE SANS VIEWERS: Aucune")

            # Afficher les cha√Ænes non-live ou inconnues
            if not_live_channels:
                stopped_names = [ch['name'] for ch in not_live_channels[:10]] # Limiter aussi
                remaining = len(not_live_channels) - 10
                if remaining > 0:
                    stopped_names.append(f"et {remaining} autres")
                summary_lines.append(f"CHA√éNES NON-LIVE / INCONNUES: {len(not_live_channels)} ({', '.join(stopped_names)})")
            else:
                summary_lines.append("CHA√éNES NON-LIVE / INCONNUES: Aucune")

            # Stats globales bas√©es sur ChannelStatusManager
            total_viewers = sum(ch["viewers"] for ch in live_with_viewers)
            total_live_streams = len(live_with_viewers) + len(live_without_viewers)
            total_known_channels = len(manager_known_channels)
            summary_lines.append(
                f"TOTAL: {total_viewers} viewers sur {total_live_streams} streams live ({total_known_channels} cha√Ænes g√©r√©es)"
            )

            # Afficher le r√©capitulatif
            logger.info("\n".join(summary_lines))

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©capitulatif: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _clean_startup(self):
        """Nettoyage initial optimis√©"""
        try:
            logger.info("üßπ Nettoyage initial... (appel unique au d√©marrage)")

            content_path = Path(self.content_dir)
            if not content_path.exists():
                content_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"üìÇ Cr√©ation du dossier de contenu: {content_path}")

            # Force reset of channel status file at startup
            logger.info("üîÑ R√©initialisation du fichier de statut des cha√Ænes...")
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)

            # Create a fresh status file with zero viewers
            with open(CHANNELS_STATUS_FILE, 'w') as f:
                json.dump({
                    'channels': {},
                    'last_updated': int(time.time()),
                    'active_viewers': 0
                }, f, indent=2)

            logger.info("‚úÖ Fichier de statut r√©initialis√©")

            # Nettoyage des dossiers HLS
            self.hls_cleaner.initial_cleanup()

            # Start the cleaner thread only if it's not already alive
            if hasattr(self.hls_cleaner, 'cleanup_thread') and not self.hls_cleaner.cleanup_thread.is_alive():
                self.hls_cleaner.start()
                logger.info("‚úÖ HLSCleaner thread started.")
            else:
                logger.info("‚ÑπÔ∏è HLSCleaner thread already running or finished, not starting again.")

            logger.info("‚úÖ Nettoyage initial termin√©")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du nettoyage initial: {e}")

    def ensure_hls_directory(self, channel_name: str = None):
        """Cr√©e et configure les dossiers HLS avec les bonnes permissions"""
        # Dossier HLS principal
        base_hls = Path(HLS_DIR)
        if not base_hls.exists():
            logger.info("üìÇ Cr√©ation du dossier HLS principal...")
            base_hls.mkdir(parents=True, exist_ok=True)

        # Dossier sp√©cifique √† une cha√Æne si demand√©
        if channel_name:
            channel_hls = base_hls / channel_name
            if not channel_hls.exists():
                logger.info(f"üìÇ Cr√©ation du dossier HLS pour {channel_name}")
                channel_hls.mkdir(parents=True, exist_ok=True)

    def _periodic_force_playlist_update(self):
        """Thread qui force p√©riodiquement la mise √† jour de la playlist ma√Ætre"""
        from config import FORCE_PLAYLIST_UPDATE_INTERVAL

        logger.info(f"üîÑ D√©marrage du thread de mise √† jour p√©riodique (interval: {FORCE_PLAYLIST_UPDATE_INTERVAL}s)")

        while not self.stop_event.is_set():
            try:
                time.sleep(FORCE_PLAYLIST_UPDATE_INTERVAL)

                if not self.stop_event.is_set():
                    logger.debug("‚è∞ Mise √† jour p√©riodique forc√©e de la playlist ma√Ætre")
                    self._update_master_playlist()

                    # Mettre √† jour √©galement le statut des cha√Ænes pour le dashboard
                    try:
                        self._update_channel_status(initial_call=False)
                    except Exception as e:
                        logger.error(f"‚ùå Erreur lors de la mise √† jour p√©riodique du statut des cha√Ænes: {e}")

            except Exception as e:
                logger.error(f"‚ùå Erreur dans le thread de mise √† jour p√©riodique: {e}")
                time.sleep(FORCE_PLAYLIST_UPDATE_INTERVAL)

    def _request_playlist_update(self):
        """Demande une mise √† jour de la playlist avec batching (√©vite les updates r√©p√©titives)"""
        with self.playlist_update_lock:
            current_time = time.time()

            # Si une mise √† jour a √©t√© faite il y a moins de 3 secondes, on attend
            if current_time - self.last_playlist_update < 3:
                # Planifier une mise √† jour diff√©r√©e si pas d√©j√† planifi√©e
                if not self.playlist_update_pending:
                    self.playlist_update_pending = True

                    def delayed_update():
                        time.sleep(3)
                        with self.playlist_update_lock:
                            self.playlist_update_pending = False
                        self._update_master_playlist()

                    threading.Thread(target=delayed_update, daemon=True, name="DelayedPlaylistUpdate").start()
                    logger.debug("üìÖ Mise √† jour de playlist diff√©r√©e (batching)")
            else:
                # Faire la mise √† jour imm√©diatement
                self._update_master_playlist()

    def _update_master_playlist(self):
        """Effectue la mise √† jour de la playlist principale avec logging am√©lior√©"""
        start_time = time.time()
        startup_elapsed = start_time - self.startup_time if hasattr(self, 'startup_time') else 0

        logger.debug("üîí Tentative d'acquisition du playlist_update_lock...")
        # Mettre √† jour le timestamp de derni√®re mise √† jour
        with self.playlist_update_lock:
            logger.debug("‚úÖ playlist_update_lock acquis")
            self.last_playlist_update = start_time

        playlist_path = os.path.abspath(f"{HLS_DIR}/playlist.m3u")
        logger.debug(f"üîÑ D√©but mise √† jour playlist (temps depuis d√©marrage: {startup_elapsed:.1f}s)")

        logger.debug("üîí Tentative d'acquisition du scan_lock pour mise √† jour playlist...")
        # Utiliser le verrou de scan pour prot√©ger l'acc√®s aux cha√Ænes
        with self.scan_lock:
            logger.debug("‚úÖ scan_lock acquis, d√©but de la mise √† jour...")
            try:
                # On sauvegarde d'abord le contenu actuel au cas o√π
                existing_content = "#EXTM3U\n"
                if os.path.exists(playlist_path) and os.path.getsize(playlist_path) > 0:
                    try:
                        with open(playlist_path, "r", encoding="utf-8") as f:
                            existing_content = f.read()
                        logger.debug(f"‚úÖ Contenu actuel sauvegard√©: {len(existing_content)} octets")
                    except Exception as e:
                        logger.error(f"‚ùå Erreur lecture playlist existante: {e}")
                
                # Pr√©paration du nouveau contenu
                content = "#EXTM3U\n"

                # Build ready_channels based on channel objects status
                ready_channels = []
                # *** REMOVED redundant scan_lock, using self.lock now ***
                # with self.scan_lock: 
                for name, channel in sorted(self.channels.items()):
                    # Ensure channel object exists and check its ready status
                    if channel and hasattr(channel, 'is_ready_for_streaming') and channel.is_ready_for_streaming():
                        ready_channels.append((name, channel))
                        logger.debug(f"[{name}] ‚úÖ Cha√Æne pr√™te pour la playlist ma√Ætre")
                    elif channel:
                        # Log detailed status for debugging
                        has_method = hasattr(channel, 'is_ready_for_streaming')
                        is_ready = channel.is_ready_for_streaming() if has_method else False
                        logger.warning(f"[{name}] ‚è≥ Cha√Æne non pr√™te: has_method={has_method}, is_ready={is_ready}")
                    else:
                        logger.warning(f"[{name}] ‚è≥ Cha√Æne non initialis√©e (channel object is None)")

                # √âcriture des cha√Ænes pr√™tes
                # No need to get SERVER_URL from os.getenv since we already imported it from config
                if ready_channels:
                    for name, _ in ready_channels:
                        content += f'#EXTINF:-1 tvg-id="{name}" tvg-name="{name}",{name}\n'
                        content += f"http://{SERVER_URL}/hls/{name}/playlist.m3u8\n"
                else:
                    # Si aucune cha√Æne n'est pr√™te, ajouter un commentaire
                    content += "# Aucune cha√Æne active pour le moment\n"
                    logger.warning("‚ö†Ô∏è Aucune cha√Æne active d√©tect√©e pour la playlist")
                
                # Loguer le contenu √† √©crire pour v√©rification
                logger.debug(f"üìù Contenu de la playlist √† √©crire:\n{content}")
                
                # √âcrire dans un fichier temporaire d'abord
                temp_path = f"{playlist_path}.tmp"
                with open(temp_path, "w", encoding="utf-8") as f:
                    f.write(content)
                    # *** ADDED: Ensure file is written to disk before checking size ***
                    f.flush()
                    os.fsync(f.fileno())
                    # *** END ADDED ***
                
                # V√©rifier que le fichier temporaire a √©t√© cr√©√© correctement
                # *** ADDED: Short delay to allow filesystem sync ***
                time.sleep(0.1) 
                # *** END ADDED ***
                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
                    # Remplacer l'ancien fichier
                    os.replace(temp_path, playlist_path)
                    logger.debug(f"‚úÖ Playlist remplac√©e avec succ√®s")
                else:
                    logger.error(f"‚ùå Fichier temporaire vide ou non cr√©√©: {temp_path}")
                    # Ne pas remplacer l'ancien fichier si le temporaire est vide
                    raise Exception("Fichier temporaire vide ou non cr√©√©")
                
                
                # V√©rification que le fichier a √©t√© correctement √©crit
                if os.path.exists(playlist_path):
                    size = os.path.getsize(playlist_path)
                    logger.debug(f"‚úÖ Playlist √©crite: {playlist_path}, taille: {size} octets")
                    
                    # Lire le contenu pour v√©rification
                    with open(playlist_path, "r", encoding="utf-8") as f:
                        read_content = f.read()
                        if read_content == content:
                            logger.debug("‚úÖ Contenu v√©rifi√©, identique √† ce qui devait √™tre √©crit")
                        else:
                            logger.error("‚ùå Contenu lu diff√©rent du contenu qui devait √™tre √©crit")
                            logger.error(f"üìÑ Contenu lu:\n{read_content}")
                            # Essayer d'√©crire directement
                            with open(playlist_path, "w", encoding="utf-8") as f:
                                f.write(content)
                            logger.info("üîÑ Tentative d'√©criture directe effectu√©e")
                else:
                    logger.error(f"‚ùå Fichier non trouv√© apr√®s √©criture: {playlist_path}")
                    # Recr√©er avec le contenu existant
                    with open(playlist_path, "w", encoding="utf-8") as f:
                        f.write(existing_content)
                    logger.warning("üîÑ Restauration du contenu pr√©c√©dent")

                # Use len(self.channels) which includes all potentially initializing channels (placeholders)
                total_channels_known_by_manager = len(self.channels)
                # Count non-None channels for a more accurate 'loaded' count
                loaded_channels_count = sum(1 for ch in self.channels.values() if ch is not None)

                # Timing info
                duration = time.time() - start_time
                logger.debug(
                    f"‚úÖ Playlist mise √† jour en {duration:.2f}s: {len(ready_channels)} cha√Ænes pr√™tes sur {loaded_channels_count} charg√©es ({total_channels_known_by_manager} total connu par manager)"
                )
            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour playlist: {e}")
                logger.error(traceback.format_exc())
                
                # En cas d'erreur, v√©rifier si le fichier existe toujours
                if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                    # Restaurer le contenu pr√©c√©dent s'il existe
                    if existing_content and len(existing_content) > 8:  # Plus que juste "#EXTM3U\n"
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write(existing_content)
                        logger.info("‚úÖ Contenu pr√©c√©dent restaur√©")
                    
                    # Si pas de contenu pr√©c√©dent ou erreur, cr√©er une playlist minimale
                    if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write("#EXTM3U\n# Playlist de secours\n")
                        logger.info("‚úÖ Playlist minimale cr√©√©e en fallback")

        # Validation de la compl√©tude avec retry diff√©r√©
        if not self._validate_playlist_completeness():
            from config import VALIDATION_RETRY_DELAY, VALIDATION_MAX_RETRIES

            # Compter les tentatives de validation
            if not hasattr(self, '_validation_retry_count'):
                self._validation_retry_count = 0

            if self._validation_retry_count < VALIDATION_MAX_RETRIES:
                self._validation_retry_count += 1
                logger.info(
                    f"üìÖ Planification retry validation dans {VALIDATION_RETRY_DELAY}s "
                    f"(tentative {self._validation_retry_count}/{VALIDATION_MAX_RETRIES})"
                )

                # Planifier une mise √† jour diff√©r√©e
                threading.Timer(
                    VALIDATION_RETRY_DELAY,
                    self._update_master_playlist
                ).start()
            else:
                logger.warning(
                    f"‚ö†Ô∏è Nombre maximum de retries atteint ({VALIDATION_MAX_RETRIES}), "
                    "attente du prochain cycle p√©riodique"
                )
                self._validation_retry_count = 0
        else:
            # Playlist compl√®te, r√©initialiser le compteur
            self._validation_retry_count = 0

    def _validate_playlist_completeness(self) -> bool:
        """
        Valide que la playlist ma√Ætre contient toutes les cha√Ænes pr√™tes.
        Retourne True si compl√®te, False sinon.
        """
        try:
            playlist_path = f"{HLS_DIR}/playlist.m3u"

            if not os.path.exists(playlist_path):
                logger.warning("‚ö†Ô∏è Fichier playlist n'existe pas encore")
                return False

            # Lire la playlist
            with open(playlist_path, 'r', encoding='utf-8') as f:
                playlist_content = f.read()

            # Compter les cha√Ænes dans la playlist
            playlist_channels = set()
            for line in playlist_content.split('\n'):
                if line.startswith('#EXTINF:'):
                    # Extraire le nom de la cha√Æne
                    parts = line.split(',')
                    if len(parts) > 1:
                        channel_name = parts[-1].strip()
                        playlist_channels.add(channel_name)

            # Compter les cha√Ænes pr√™tes dans le manager
            ready_channels = set()
            with self.scan_lock:
                for name, channel in self.channels.items():
                    if channel and hasattr(channel, 'is_ready_for_streaming'):
                        if channel.is_ready_for_streaming():
                            ready_channels.add(name)

            # Comparer
            missing_channels = ready_channels - playlist_channels
            extra_channels = playlist_channels - ready_channels

            if missing_channels:
                logger.warning(
                    f"‚ö†Ô∏è Cha√Ænes pr√™tes mais absentes de la playlist ({len(missing_channels)}): "
                    f"{', '.join(sorted(missing_channels))}"
                )

            if extra_channels:
                logger.debug(
                    f"‚ÑπÔ∏è Cha√Ænes dans playlist mais plus pr√™tes ({len(extra_channels)}): "
                    f"{', '.join(sorted(extra_channels))}"
                )

            is_complete = len(missing_channels) == 0

            logger.debug(
                f"üìä Validation playlist: {len(playlist_channels)} dans fichier, "
                f"{len(ready_channels)} pr√™tes, compl√®te: {is_complete}"
            )

            return is_complete

        except Exception as e:
            logger.error(f"‚ùå Erreur validation compl√©tude playlist: {e}")
            return False

    def cleanup_manager(self):
        """Cleanup everything before shutdown"""
        logger.info("D√©but du nettoyage...")

        # Stop all threads first
        self.stop_event.set()  # Arr√™t principal
        self.stop_scan_thread.set()
        self.stop_init_thread.set()
        self.stop_periodic_scan.set()

        # Vider tous les viewers du fichier de statut avant arr√™t
        try:
            if self.channel_status is not None:
                logger.info("üßπ Vidage de tous les viewers du fichier channel_status.json avant arr√™t...")
                flush_success = self.channel_status.flush_all_viewers()
                if flush_success:
                    logger.info("‚úÖ Tous les viewers ont √©t√© vid√©s avec succ√®s du fichier de statut")
                else:
                    logger.warning("‚ö†Ô∏è √âchec du vidage des viewers avant arr√™t")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du vidage des viewers: {e}")

        # Stop components that might be None
        try:
            if self.channel_status is not None:
                self.channel_status.stop()
                logger.info("‚úÖ Channel status manager stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du channel status manager: {e}")

        try:
            if self.stats_collector is not None:
                self.stats_collector.stop()
                logger.info("üìä StatsCollector arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du StatsCollector: {e}")

        try:
            if self.hls_cleaner is not None:
                self.hls_cleaner.stop_cleaner()
                logger.info("üßπ HLS Cleaner arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du HLS Cleaner: {e}")

        # Join threads with timeout
        threads_to_join = [
            (self.channel_init_thread, "Channel init thread"),
            (self.scan_thread, "Scan thread"),
            # (self.cleanup_thread, "Cleanup thread"),
        ]

        for thread, name in threads_to_join:
            try:
                if thread and thread.is_alive():
                    thread.join(timeout=5)
                    logger.info(f"‚úÖ {name} stopped")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'arr√™t du thread {name}: {e}")

        # Stop observers
        try:
            if hasattr(self, "observer"):
                self.observer.stop()
                self.observer.join(timeout=5)
                logger.info("‚úÖ Main observer stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t de l'observer principal: {e}")

        try:
            if hasattr(self, "ready_observer"):
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)
                logger.info("‚úÖ Ready observer stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du ready observer: {e}")
            
        # Clean up channels
        for name, channel in self.channels.items():
            try:
                if channel is not None:
                    channel._clean_processes()
                    logger.info(f"‚úÖ Channel {name} cleaned up")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du nettoyage du canal {name}: {e}")

        logger.info("‚úÖ Nettoyage termin√©")

    def _setup_ready_observer(self):
        """Configure l'observateur pour les dossiers ready_to_stream de chaque cha√Æne"""
        try:
            # D'abord, arr√™ter et recr√©er l'observateur si n√©cessaire pour √©viter les doublons
            if hasattr(self, "ready_observer") and self.ready_observer.is_alive():
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)

            self.ready_observer = Observer()

            # Pour chaque cha√Æne existante
            paths_scheduled = set()  # Pour √©viter les doublons

            for name, channel in self.channels.items():
                # ADDED: Check if channel object is None
                if channel is None:
                    logger.debug(f"_setup_ready_observer: Skipping channel {name} as object is None.")
                    continue
                    
                ready_dir = Path(channel.video_dir) / "ready_to_stream"
                ready_dir.mkdir(
                    parents=True, exist_ok=True
                )  # S'assurer que le dossier existe

                if ready_dir.exists() and str(ready_dir) not in paths_scheduled:
                    self.ready_observer.schedule(
                        self.ready_event_handler, str(ready_dir), recursive=False
                    )
                    paths_scheduled.add(str(ready_dir))
                    logger.debug(
                        f"üëÅÔ∏è Surveillance ready_to_stream configur√©e pour {name}: {ready_dir}"
                    )

            # D√©marrage de l'observateur
            self.ready_observer.start()
            logger.info(
                f"üöÄ Observateur ready_to_stream d√©marr√© pour {len(paths_scheduled)} chemins"
            )

        except Exception as e:
            logger.error(f"‚ùå Erreur configuration surveillance ready_to_stream: {e}")
            import traceback

            logger.error(traceback.format_exc())

    def _update_channel_status(self, initial_call=False):
        """Update channel status for dashboard"""
        try:
            if not self.channel_status:
                logger.warning("‚ö†Ô∏è Channel status manager not initialized")
                return False

            # Ensure stats directory exists and has proper permissions
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)


            # Prepare channel status data
            channels_dict = {}

            # Premi√®re √©tape: parcourir tous les dossiers de cha√Ænes disponibles
            # pour s'assurer que toutes les cha√Ænes apparaissent dans le dashboard
            try:
                content_path = Path(self.content_dir)
                if content_path.exists():
                    for channel_dir in content_path.iterdir():
                        if channel_dir.is_dir():
                            channel_name = channel_dir.name
                            # Initialiser avec des valeurs par d√©faut pour les cha√Ænes non initialis√©es
                            channels_dict[channel_name] = {
                                "is_live": False,
                                "streaming": False,
                                "current_video": None,
                            }
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du scan des dossiers de cha√Ænes: {e}")

            # Deuxi√®me √©tape: mettre √† jour avec les informations des cha√Ænes initialis√©es
            # Use scan_lock for iterating self.channels safely
            with self.scan_lock:
                for channel_name, channel in self.channels.items():
                    # Only include channels that have been initialized (are not None)
                    if channel and hasattr(channel, 'is_ready_for_streaming'):
                        is_ready = channel.is_ready_for_streaming()
                        is_streaming = channel.is_running() if hasattr(channel, 'is_running') else False

                        # R√©cup√©rer le nom du fichier vid√©o en cours
                        current_video_name = None
                        if hasattr(channel, 'processed_videos') and hasattr(channel, 'current_video_index'):
                            try:
                                if channel.processed_videos and 0 <= channel.current_video_index < len(channel.processed_videos):
                                    current_video_path = channel.processed_videos[channel.current_video_index]
                                    # Extraire le nom du fichier sans extension
                                    current_video_name = current_video_path.stem if hasattr(current_video_path, 'stem') else str(current_video_path.name).rsplit('.', 1)[0]
                            except Exception as e:
                                logger.debug(f"[{channel_name}] Erreur r√©cup√©ration nom vid√©o: {e}")

                        # Les informations sur les viewers sont maintenant g√©r√©es par ChannelStatusManager
                        # On ne les met pas √† jour ici pour √©viter les conflits
                        status_data = {
                            "is_live": is_ready,
                            "streaming": is_streaming,
                            "current_video": current_video_name,
                        }
                        channels_dict[channel_name] = status_data
                    # else: # Log channels that are skipped during update
                        # logger.debug(f"_update_channel_status: Skipping channel '{channel_name}' (not initialized or no is_ready attr)")

            
            # If no channels are ready or available, don't wipe the status
            if not channels_dict:
                # Avoid logging this message too frequently if manager starts with no channels
                log_key = "_last_no_channels_log_time"
                now = time.time()
                if not hasattr(self, log_key) or now - getattr(self, log_key) > 60:
                     logger.info("ü§∑ No initialized channels found, skipping status update.")
                     setattr(self, log_key, now)
                return True # Indicate success as no update was needed

            # Update status with retry logic
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    # Call the method responsible for writing the combined status
                    success = self.channel_status.update_all_channels(channels_dict)
                    if success:
                        logger.debug(f"‚úÖ Channel status file updated successfully ({'initial' if initial_call else 'periodic'})")
                        return True
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status file (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error calling channel_status.update_all_channels (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to update channel status file after all retries")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error in _update_channel_status: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _check_channels_timeout(self):
        """V√©rifie p√©riodiquement les timeouts des cha√Ænes sans watchers"""
        try:
            # Use list() to avoid issues if dict changes during iteration
            for channel_name, channel in list(self.channels.items()): 
                # ---> ADD CHECK FOR NONE <--- 
                if channel is not None and hasattr(channel, 'check_watchers_timeout'):
                    channel.check_watchers_timeout()
                elif channel is None:
                    logger.debug(f"_check_channels_timeout: Skipping channel {channel_name} as object is None.")
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification timeouts: {e}")

    def run_manager_loop(self):
        """Boucle principale du gestionnaire IPTV"""
        logger.info("üîÑ D√©marrage de la boucle principale du gestionnaire")
        
        # D√©marrer les composants dans le bon ordre
        if not hasattr(self, "observer") or not self.observer.is_alive():
            self.observer.start()
            logger.info("üëÅÔ∏è Observateur d√©marr√©")
            
        try:
            last_scan_time = time.time()
            last_summary_time = time.time()
            last_resync_time = time.time()
            last_log_watchers_time = time.time()
            # SUPPRIM√â: last_process_logs_time (plus n√©cessaire)
            
            while True:
                current_time = time.time()
                
                # SUPPRIM√â: Le traitement des logs est maintenant g√©r√© automatiquement
                # par le thread de monitoring de StatsCollector (_log_monitor_loop)
                
                # Scan p√©riodique 
                if current_time - last_scan_time > SUMMARY_CYCLE:
                    self._periodic_scan()
                    last_scan_time = current_time
                    
                # Affichage p√©riodique du r√©capitulatif
                if current_time - last_summary_time > SUMMARY_CYCLE:
                    self._log_channels_summary()
                    last_summary_time = current_time
                
                # Resynchronisation g√©n√©rale de toutes les playlists
                if current_time - last_resync_time > 600:  # Toutes les 10 minutes
                    self._resync_all_playlists()
                    last_resync_time = current_time

                # Dormir un peu pour √©viter de surcharger le CPU
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            logger.info("üëã Interruption clavier, arr√™t du gestionnaire")
            self.stop()
        except Exception as e:
            logger.critical(f"‚ùå ERREUR MAJEURE dans la boucle principale: {e}")
            import traceback
            logger.critical(traceback.format_exc())
            self.stop()
            
        logger.info("üõë Boucle principale du gestionnaire termin√©e")

    def _periodic_scan(self):
        """Effectue un scan p√©riodique des cha√Ænes pour d√©tecter les changements"""
        if self.stop_periodic_scan.is_set():
            return

        try:
            logger.debug(f"üîÑ Scan p√©riodique des cha√Ænes en cours...")
            self._do_scan(force=True)
            
            # NOUVEAU: Resynchronisation p√©riodique des playlists
            self._resync_all_playlists()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur scan p√©riodique: {e}")

    def _resync_all_playlists(self):
        """Force la resynchronisation des playlists pour toutes les cha√Ænes"""
        try:
            resync_count = 0
            for channel_name, channel in self.channels.items():
                # V√©rifier si la cha√Æne a une m√©thode de cr√©ation de playlist
                if hasattr(channel, "_create_concat_file"):
                    # On ne recr√©√© pas toutes les playlists √† chaque fois, on alterne
                    # 1/4 des cha√Ænes √† chaque cycle pour ne pas surcharger le syst√®me
                    if random.randint(1, 4) == 1:  
                        logger.debug(f"[{channel_name}] üîÑ Resynchronisation p√©riodique de la playlist")
                        
                        # Cr√©er un thread d√©di√© pour resynchroniser et red√©marrer si n√©cessaire
                        def resync_and_restart(ch_name, ch):
                            try:
                                # 1. V√©rifier l'√©tat actuel de la playlist
                                playlist_path = Path(ch.video_dir) / "_playlist.txt"
                                old_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        old_content = f.read()
                                
                                # 2. Mettre √† jour la playlist
                                ch._create_concat_file()
                                
                                # 3. V√©rifier si la playlist a chang√©
                                new_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        new_content = f.read()
                                
                                # 4. Red√©marrer seulement si le contenu a chang√©
                                if old_content != new_content:
                                    logger.info(f"[{ch_name}] üîÑ Playlist modifi√©e, red√©marrage du stream n√©cessaire")
                                    
                                    # Add _restart_stream method if it doesn't exist
                                    if not hasattr(ch, "_restart_stream"):
                                        logger.warning(f"[{ch_name}] ‚ö†Ô∏è Adding missing _restart_stream method to channel.")
                                        # Add a basic implementation that will restart using start_stream
                                        def restart_stream_impl(diagnostic=None):
                                            """Basic implementation for channels missing _restart_stream method"""
                                            try:
                                                logger.info(f"[{ch_name}] üîÑ Basic restart implementation called. Reason: {diagnostic or 'Unknown'}")
                                                # Stop current stream if it's running
                                                if hasattr(ch, "process_manager") and ch.process_manager.is_running():
                                                    ch.process_manager.stop_process()
                                                
                                                # Clean HLS segments if possible
                                                if hasattr(ch, "hls_cleaner"):
                                                    ch.hls_cleaner.cleanup_channel(ch_name)
                                                
                                                # Try to start the stream again
                                                if hasattr(ch, "start_stream"):
                                                    success = ch.start_stream()
                                                    logger.info(f"[{ch_name}] {'‚úÖ Stream restarted successfully' if success else '‚ùå Failed to restart stream'}")
                                                    return success
                                                else:
                                                    logger.error(f"[{ch_name}] ‚ùå Channel doesn't have start_stream method")
                                                    return False
                                            except Exception as e:
                                                logger.error(f"[{ch_name}] ‚ùå Error in basic restart implementation: {e}")
                                                return False
                                        
                                        # Add the method to the channel
                                        setattr(ch, "_restart_stream", restart_stream_impl)
                                        logger.info(f"[{ch_name}] ‚úÖ Added basic _restart_stream method to channel")
                                    
                                    if hasattr(ch, "_restart_stream") and ch.process_manager.is_running():
                                        logger.info(f"[{ch_name}] üîÑ Red√©marrage du stream apr√®s mise √† jour p√©riodique de la playlist")
                                        ch._restart_stream()
                                else:
                                    logger.debug(f"[{ch_name}] ‚úì Playlist inchang√©e, pas de red√©marrage n√©cessaire")
                            except Exception as e:
                                logger.error(f"[{ch_name}] ‚ùå Erreur pendant la resynchronisation: {e}")
                        
                        # Lancer le thread de resynchronisation
                        threading.Thread(
                            target=resync_and_restart,
                            args=(channel_name, channel),
                            daemon=True
                        ).start()
                        resync_count += 1
                        logger.info(f"üîÑ [{channel_name}] {resync_count} playlists resynchronis√©es")
                else:
                    logger.debug(f"[{channel_name}] ‚ÑπÔ∏è Pas de m√©thode de cr√©ation de playlist, aucune resynchronisation n√©cessaire")
                    
            if resync_count > 0:
                logger.info(f"‚úÖ Resynchronisation et red√©marrage de {resync_count} cha√Ænes effectu√©s")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur resynchronisation des playlists: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire IPTV"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        
        # Utiliser la m√©thode compl√®te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("üõë Gestionnaire IPTV arr√™t√© avec succ√®s")

    def _process_channel_init_queue(self):
        """Process the queue of channels to initialize"""
        logger.info("üîÑ D√©marrage du thread de traitement de la queue d'initialisation des cha√Ænes")
        while not self.stop_init_thread.is_set():
            try:
                # Essaie de r√©cup√©rer une cha√Æne de la queue AVANT de v√©rifier la limite
                channel_data = None
                try:
                    logger.debug("[INIT_QUEUE] ‚è±Ô∏è Attente d'un √©l√©ment dans la queue...")
                    channel_data = self.channel_init_queue.get(timeout=1)
                    channel_name = channel_data.get('name', 'unknown')
                    logger.info(f"[INIT_QUEUE] üì• R√©cup√©ration de {channel_name} depuis la queue")
                except Empty:
                    # Queue vide, continuer la boucle pour v√©rifier stop_event
                    continue
                except Exception as q_err:
                    logger.error(f"[INIT_QUEUE] ‚ùå Erreur get() sur la queue: {q_err}")
                    time.sleep(1)
                    continue

                # Attendre qu'un slot se lib√®re si la limite est atteinte
                while not self.stop_init_thread.is_set():
                    with self.init_threads_lock:
                        if self.active_init_threads < self.max_parallel_inits:
                            # Slot disponible, incr√©menter et sortir de la boucle d'attente
                            self.active_init_threads += 1
                            channel_name = channel_data.get('name', 'unknown')
                            logger.debug(f"[INIT_QUEUE] ‚ûï [{channel_name}] Incr√©mentation du compteur de threads actifs: {self.active_init_threads}/{self.max_parallel_inits}")
                            break
                    # Limite atteinte, attendre un peu avant de rev√©rifier
                    logger.debug(f"[INIT_QUEUE] ‚è≥ Limite d'initialisations parall√®les atteinte ({self.active_init_threads}/{self.max_parallel_inits}), attente...")
                    time.sleep(0.1)

                # V√©rifier si on doit arr√™ter avant de lancer le thread
                if self.stop_init_thread.is_set():
                    # D√©crementer car on ne va pas lancer le thread
                    with self.init_threads_lock:
                        self.active_init_threads -= 1
                    self.channel_init_queue.task_done()
                    break

                # Lance un thread pour initialiser cette cha√Æne
                channel_name = channel_data.get('name', 'unknown')
                logger.info(f"[INIT_QUEUE] üßµ [{channel_name}] D√©marrage d'un thread d'initialisation")
                threading.Thread(
                    target=self._init_channel_async,
                    args=(channel_data,),
                    daemon=True,
                    name=f"Init-{channel_name}"
                ).start()

            except Exception as e:
                logger.error(f"[INIT_QUEUE] ‚ùå Erreur majeure dans la boucle _process_channel_init_queue: {e}")
                logger.error(traceback.format_exc())
                time.sleep(5)

    def _init_channel_async(self, channel_data):
        """Initialise une cha√Æne de mani√®re asynchrone"""
        channel_init_start = time.time()
        channel_name = channel_data.get("name", "unknown")

        try:
            channel_dir = channel_data["dir"]
            from_queue = channel_data.get("from_queue", True)

            logger.info(f"[{channel_name}] üîÑ Initialisation asynchrone de la cha√Æne")

            # Cr√©e l'objet cha√Æne (phase rapide)
            channel = IPTVChannel(
                channel_name,
                str(channel_dir),
                hls_cleaner=self.hls_cleaner,
                use_gpu=self.use_gpu,
                stats_collector=self.stats_collector,
            )

            # Ajoute la r√©f√©rence au manager
            channel.manager = self

            # V√©rifie si la cha√Æne est pr√™te imm√©diatement apr√®s l'initialisation
            is_ready = channel.is_ready_for_streaming()

            with self.scan_lock:
                self.channels[channel_name] = channel

            init_duration = time.time() - channel_init_start
            logger.info(f"[{channel_name}] ‚è±Ô∏è Initialisation compl√©t√©e en {init_duration:.2f}s (Pr√™t: {is_ready})")

            # IMPORTANT: D√©cr√©menter IMM√âDIATEMENT le compteur pour lib√©rer le slot
            # Le d√©marrage du stream se fera en arri√®re-plan
            with self.init_threads_lock:
                self.active_init_threads -= 1
                logger.debug(f"[{channel_name}] Slot d'initialisation lib√©r√©: {self.active_init_threads}/{self.max_parallel_inits}")

            # Marquer la t√¢che comme termin√©e
            if from_queue:
                self.channel_init_queue.task_done()

            # D√©marrer le stream en arri√®re-plan (sans bloquer)
            if is_ready and hasattr(channel, "start_stream"):
                def start_stream_background():
                    try:
                        logger.info(f"[{channel_name}] ‚úÖ Cha√Æne pr√™te, d√©marrage du stream en arri√®re-plan...")
                        if channel.start_stream():
                            logger.info(f"[{channel_name}] ‚úÖ Stream d√©marr√© avec succ√®s.")
                            # Demander une mise √† jour de playlist (batched)
                            self._request_playlist_update()
                        else:
                            logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage du stream.")
                    except Exception as e:
                        logger.error(f"[{channel_name}] ‚ùå Erreur d√©marrage stream en arri√®re-plan: {e}")

                threading.Thread(target=start_stream_background, daemon=True, name=f"Start-{channel_name}").start()
            elif not is_ready:
                logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne non pr√™te apr√®s initialisation.")

        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation de la cha√Æne {channel_name}: {e}")
            logger.error(traceback.format_exc())

            # Ajouter un placeholder en cas d'erreur
            with self.scan_lock:
                if channel_name not in self.channels:
                    self.channels[channel_name] = None

            # IMPORTANT: D√©crementer m√™me en cas d'erreur
            with self.init_threads_lock:
                self.active_init_threads -= 1

            # Marquer comme termin√©e m√™me en cas d'erreur
            if channel_data.get("from_queue", True):
                self.channel_init_queue.task_done()

    # M√âTHODE SUPPRIM√âE: init_stats_collector_and_client_monitor()
    # StatsCollector est maintenant initialis√© dans __init__ et g√®re tout le monitoring
    # ClientMonitor a √©t√© fusionn√© dans StatsCollector


    def _start_channel(self, channel_name):
        """D√©marre une cha√Æne sp√©cifique"""
        try:
            if channel_name in self.channels:
                channel = self.channels[channel_name]
                if channel.ready_for_streaming:
                    logger.info(f"[{channel_name}] üöÄ D√©marrage automatique...")
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] ‚úÖ D√©marrage automatique r√©ussi")
                    else:
                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage automatique")
                else:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Non pr√™te pour le streaming, d√©marrage ignor√©")
            else:
                logger.error(f"[{channel_name}] ‚ùå Cha√Æne non trouv√©e dans le dictionnaire")
        except Exception as e:
            logger.error(f"[{channel_name}] ‚ùå Erreur lors du d√©marrage automatique: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def get_current_channel_status(self):
        """
        Retourne l'√©tat actuel de toutes les cha√Ænes, bas√© sur ChannelStatusManager.
        """
        try:
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.warning("‚ö†Ô∏è Tentative d'acc√®s au statut des cha√Ænes mais ChannelStatusManager n'est pas pr√™t.")
                return {}

            # Acc√®s direct aux donn√©es de statut g√©r√©es par ChannelStatusManager
            # Aucune copie n√©cessaire ici car on ne fait que lire.
            status_data = self.channel_status.channels
            
            # Cr√©er une copie pour √©viter de retourner la r√©f√©rence interne 
            # et potentiellement filtrer pour ne retourner que les cha√Ænes connues du manager?
            # Pour l'instant, retournons tout ce que le status manager conna√Æt.
            return status_data.copy() 
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du statut actuel des cha√Ænes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {}

    def get_channel_segment_duration(self, channel_name: str) -> Optional[float]:
        """Retrieves the configured HLS segment duration (hls_time) for a specific channel."""
        # Use scan_lock as channel dictionary might be modified during scans/inits
        with self.scan_lock:
            channel = self.channels.get(channel_name)
            if channel and hasattr(channel, 'command_builder') and hasattr(channel.command_builder, 'hls_time'):
                duration = getattr(channel.command_builder, 'hls_time', None)
                if isinstance(duration, (int, float)) and duration > 0:
                    logger.debug(f"[{channel_name}] Found segment duration: {duration}")
                    return float(duration)
                else:
                    logger.warning(f"[{channel_name}] Found invalid segment duration type/value: {duration} in command_builder")
                    return None
            elif channel:
                logger.warning(f"[{channel_name}] Channel object found but missing 'command_builder' or 'hls_time' attribute.")
                return None
            else:
                # Channel not found or is a placeholder (None)
                logger.warning(f"[{channel_name}] Channel not found or not fully initialized in IPTVManager.channels.")
                return None

    def init_channel_status_manager(self):
        """Initialize the channel status manager for dashboard"""
        try:
            # Si d√©j√† initialis√©, ne pas r√©initialiser
            if self.channel_status is not None:
                logger.info("‚ÑπÔ∏è Channel status manager d√©j√† initialis√©, skip")
                return

            logger.info("üöÄ Initialisation du gestionnaire de statuts des cha√Ænes")
            
            # Cr√©er le dossier stats s'il n'existe pas
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            
            # Cr√©er le fichier de statut s'il n'existe pas ou est vide/invalide
            should_create_file = True
            if os.path.exists(CHANNELS_STATUS_FILE):
                try:
                    if os.path.getsize(CHANNELS_STATUS_FILE) > 0:
                         with open(CHANNELS_STATUS_FILE, 'r') as f:
                             json.load(f) # Try to parse existing json
                         should_create_file = False # File exists and is valid JSON
                    # else: file exists but is empty, will overwrite
                except (json.JSONDecodeError, OSError) as e:
                     logger.warning(f"Existing status file {CHANNELS_STATUS_FILE} is invalid or unreadable ({e}). Will overwrite.")
                     # File exists but is invalid, will overwrite
                     
            if should_create_file:
                 logger.info(f"Creating/Overwriting initial status file: {CHANNELS_STATUS_FILE}")
                 with open(CHANNELS_STATUS_FILE, 'w') as f:
                     # Initial state with 0 viewers
                     json.dump({
                         'channels': {},
                         'last_updated': int(time.time()),
                         'active_viewers': 0
                     }, f, indent=2)
            
            # Initialiser le gestionnaire de statuts
            self.channel_status = ChannelStatusManager(
                status_file=CHANNELS_STATUS_FILE
            )
            
            # Faire une mise √† jour initiale pour inclure toutes les cha√Ænes disponibles
            logger.info("üîÑ Mise √† jour initiale du statut des cha√Ænes...")
            try:
                success = self._update_channel_status(initial_call=True)
                if success:
                    logger.info("‚úÖ Channel status manager initialized for dashboard (initial status set)")
                else:
                    logger.warning("‚ö†Ô∏è Failed to update channel status during init")
            except Exception as e:
                logger.error(f"‚ùå Error calling _update_channel_status during init: {e}")

            logger.info("‚úÖ ChannelStatusManager initialis√©.")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing channel status manager: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.channel_status = None
            
    def _check_inactive_channels(self):
        """
        V√©rifie les cha√Ænes actuellement en streaming mais sans viewers (selon ChannelStatusManager)
        et les arr√™te si elles sont inactives depuis trop longtemps.
        """
        if not hasattr(self, "channel_status") or self.channel_status is None:
            logger.debug("[_check_inactive_channels] ChannelStatusManager non disponible, skip.")
            return

        current_time = time.time()
        channels_to_stop = []

        # Utiliser le lock du ChannelStatusManager pour lire son √©tat
        with self.channel_status._lock:
            for channel_name, status_data in self.channel_status.channels.items():
                viewers = status_data.get("viewers", 0)
                is_live = status_data.get("is_live", False)
                last_updated_str = status_data.get("last_updated")
                
                # Ne v√©rifier que les cha√Ænes consid√©r√©es comme live mais sans viewers
                if is_live and viewers == 0:
                    # V√©rifier si la cha√Æne existe dans notre manager
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj and hasattr(channel_obj, 'is_running') and channel_obj.is_running():
                        # Initialiser last_active_time si ce n'est pas fait
                        if not hasattr(channel_obj, 'last_time_with_viewers'):
                            channel_obj.last_time_with_viewers = current_time
                            
                        # V√©rifier le d√©lai d'inactivit√©
                        inactive_duration = current_time - channel_obj.last_time_with_viewers
                        if inactive_duration > self.channel_inactivity_timeout:
                            logger.info(f"[{channel_name}] ‚è±Ô∏è Inactive depuis {inactive_duration:.0f}s (> {self.channel_inactivity_timeout}s) sans viewers. Arr√™t demand√©.")
                            channels_to_stop.append(channel_name)
                        else:
                             logger.debug(f"[{channel_name}] Inactive depuis {inactive_duration:.0f}s sans viewers, mais < timeout.")
                    # else: Channel is not streaming according to its object, no need to stop
                elif viewers > 0:
                    # Mettre √† jour le timestamp si des viewers sont pr√©sents
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj:
                        channel_obj.last_time_with_viewers = current_time 

        # Arr√™ter les cha√Ænes identifi√©es (en dehors du lock de channel_status)
        for name in channels_to_stop:
            channel_obj = self.channels.get(name)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                 # V√©rifier √† nouveau si des viewers sont revenus entre temps?
                 # Pour l'instant, on arr√™te si la d√©cision a √©t√© prise.
                 logger.info(f"[{name}] üõë Arr√™t du stream pour inactivit√©.")
                 channel_obj.stop_stream_if_needed()
            else:
                 logger.warning(f"[{name}] Impossible d'arr√™ter le stream (objet non trouv√© ou m√©thode manquante)." )

    def remove_channel(self, channel_name: str):
        """Supprime compl√®tement une cha√Æne et nettoie ses ressources."""
        logger.info(f"üóëÔ∏è Tentative de suppression compl√®te de la cha√Æne: {channel_name}")
        with self.scan_lock:
            # 1. Arr√™ter le stream et nettoyer les processus
            channel_obj = self.channels.pop(channel_name, None)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                logger.info(f"[{channel_name}] Arr√™t du stream pour suppression...")
                channel_obj.stop_stream_if_needed()
            
            # 2. Supprimer du ChannelStatusManager
            if self.channel_status:
                self.channel_status.remove_channel(channel_name)
                logger.info(f"[{channel_name}] Supprim√© de ChannelStatusManager.")

            # 3. Supprimer du StatsCollector
            if self.stats_collector:
                self.stats_collector.remove_channel(channel_name)
                logger.info(f"[{channel_name}] Supprim√© de StatsCollector.")

            # 4. Nettoyer les fichiers HLS
            if self.hls_cleaner:
                self.hls_cleaner.cleanup_channel(channel_name)
                logger.info(f"[{channel_name}] Fichiers HLS nettoy√©s.")

            # 5. Mettre √† jour la playlist ma√Ætre
            self._update_master_playlist()
            
            logger.info(f"‚úÖ Suppression de la cha√Æne '{channel_name}' termin√©e.")
