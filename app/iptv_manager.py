# iptv_manager.py
import os
import sys
import time
import glob
import shutil
import signal
import random
import psutil
import traceback
import subprocess
from queue import Queue, Empty
from pathlib import Path
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
import threading
from file_event_handler import FileEventHandler
from ready_content_handler import ReadyContentHandler
from hls_cleaner import HLSCleaner
from client_monitor import ClientMonitor
from resource_monitor import ResourceMonitor
from iptv_channel import IPTVChannel
import signal
from ffmpeg_monitor import FFmpegMonitor
from config import (
    CONTENT_DIR,
    NGINX_ACCESS_LOG,
    SERVER_URL,
    logger,
    VIDEO_EXTENSIONS,
    CPU_THRESHOLD,
    SEGMENT_AGE_THRESHOLD,
    SUMMARY_CYCLE,
    WATCHERS_LOG_CYCLE,
    CHANNELS_STATUS_FILE,
    HLS_DIR,
)
from stats_collector import StatsCollector
from channel_status_manager import ChannelStatusManager
import json
import re
from log_utils import parse_access_log
from typing import Optional
from datetime import datetime
from base_file_event_handler import BaseFileEventHandler


COMMAND_DIR = "/app/commands"


class IPTVManager:
    """Gestionnaire centralis√© des cha√Ænes IPTV"""

    def __init__(self, content_dir: str, use_gpu: bool = False):
        # Assurons-nous que la valeur de USE_GPU est bien prise de l'environnement
        use_gpu_env = os.getenv("USE_GPU", "false").lower() == "true"
        
        # Configuration
        self.content_dir = content_dir
        self.use_gpu = use_gpu or use_gpu_env
        self.channels = {}
        self.channel_ready_status = {}
        self.log_path = NGINX_ACCESS_LOG
        
        # >>> FIX: Initialize hls_cleaner EARLY <<<
        # On initialise le nettoyeur HLS avec le bon chemin
        self.hls_cleaner = HLSCleaner(HLS_DIR)
        # Le nettoyage HLS initial sera fait dans _clean_startup
        
        # >>> STEP 1: Clean startup FIRST to reset status file
        logger.info("Initialisation du gestionnaire IPTV am√©lior√©")
        self._clean_startup()
        # <<< END STEP 1
        
        # Initialize ready_event_handler first
        try:
            self.ready_event_handler = ReadyContentHandler(self)
            logger.info("‚úÖ ReadyContentHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing ReadyContentHandler: {e}")
            self.ready_event_handler = None
        
        # Initialize file_event_handler
        try:
            self.file_event_handler = FileEventHandler(self)
            logger.info("‚úÖ FileEventHandler initialized")
        except Exception as e:
            logger.error(f"‚ùå Error initializing FileEventHandler: {e}")
            self.file_event_handler = None
        
        # Initialisation de last_position pour le suivi des logs
        self.last_position = 0
        if os.path.exists(self.log_path):
            with open(self.log_path, "r") as f:
                f.seek(0, 2)
                self.last_position = f.tell()
                logger.info(f"üìù Position initiale de lecture des logs: {self.last_position} bytes")
        

        
        # Verrou et cooldown pour les scans
        self.scan_lock = threading.RLock()
        self.scan_cooldown = 60
        self.last_scan_time = 0
        self.scan_queue = Queue()
        self.failing_channels = set()
        self.restarting_channels = set()

        # Queue pour les cha√Ænes √† initialiser en parall√®le
        self.channel_init_queue = Queue()
        self.max_parallel_inits = 15
        self.active_init_threads = 0
        self.init_threads_lock = threading.RLock()

        # Timeout d'inactivit√© pour arr√™ter un stream (en secondes)
        self.channel_inactivity_timeout = 300 # 5 minutes
        self.last_inactivity_check = 0

        # >>> STEP 2: Initialize channel status manager AFTER cleaning
        self.channel_status = None  # Initialiser √† None
        # >>> FIX: Call init_channel_status_manager method <<<
        self.init_channel_status_manager() 
        # <<< END STEP 2

        # MODIFI√â: StatsCollector et ClientMonitor seront initialis√©s apr√®s que les cha√Ænes soient pr√™tes
        try:
            # NOUVEAU: Obtenir les canaux valides depuis la playlist ma√Ætre comme source de v√©rit√©
            master_playlist_path = Path(HLS_DIR) / "playlist.m3u"
            valid_channels = set()
            if master_playlist_path.exists():
                with open(master_playlist_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        # Chercher les URLs des playlists des canaux
                        match = re.search(r'/hls/([^/]+)/playlist\.m3u8', line)
                        if match:
                            valid_channels.add(match.group(1))
                logger.info(f"Trouv√© {len(valid_channels)} canaux valides dans la playlist ma√Ætre pour le nettoyage initial des stats.")
            else:
                logger.warning(f"Playlist ma√Ætre non trouv√©e √† {master_playlist_path}. Le nettoyage des stats pourrait √™tre incomplet.")

            # Initialiser StatsCollector en lui passant les canaux valides pour un nettoyage imm√©diat
            self.stats_collector = StatsCollector(manager=self, valid_channels=valid_channels)
            # Passer le callback update_watchers m√™me avant l'initialisation compl√®te
            self.stats_collector.update_watchers_callback = self.update_watchers
            logger.info("üìä StatsCollector initialis√© avec succ√®s (avec nettoyage initial bas√© sur la playlist ma√Ætre)")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation initiale de StatsCollector: {e}")
            # Cr√©er un objet vide pour √©viter les erreurs None
            from types import SimpleNamespace
            self.stats_collector = SimpleNamespace()
            self.stats_collector.update_watchers_callback = lambda *args, **kwargs: None  # Fonction vide
            
        self.client_monitor = None

        # Moniteur FFmpeg
        self.ffmpeg_monitor = FFmpegMonitor(self.channels)
        self.ffmpeg_monitor.start()

        # On initialise le nettoyeur HLS avec le bon chemin
        # HLS Cleaner is already initialized above

        # Initialisation des threads
        self.stop_scan_thread = threading.Event()
        self.stop_init_thread = threading.Event()
        self.stop_periodic_scan = threading.Event()  # Pour arr√™ter le scan p√©riodique
        self.periodic_scan_interval = 300  # 5 minutes entre chaque scan p√©riodique

        # Thread de scan unifi√©
        self.scan_thread = threading.Thread(
            target=self._scan_worker,
            daemon=True
        )

        # Thread d'initialisation des cha√Ænes
        self.channel_init_thread = threading.Thread(
            target=self._process_channel_init_queue,
            daemon=True
        )

        # Observer
        self.observer = Observer()
        event_handler = FileEventHandler(self)
        self.observer.schedule(event_handler, self.content_dir, recursive=True)
        logger.info(f"üëÅÔ∏è Observer configur√© pour surveiller {self.content_dir} en mode r√©cursif")

        # Command actions
        self.command_actions = {
            '.restart': self.restart_channel,
        }
        Path(COMMAND_DIR).mkdir(parents=True, exist_ok=True)
        logger.info(f"Directory des commandes configur√© sur {COMMAND_DIR}")

        # D√©marrage des threads dans l'ordre correct
        self.scan_thread.start()
        logger.info("üîÑ Thread de scan unifi√© d√©marr√©")

        self.channel_init_thread.start()
        logger.info("üîÑ Thread d'initialisation des cha√Ænes d√©marr√©")

        # Le thread de nettoyage a √©t√© supprim√© car le nettoyage est bas√© sur les logs via ClientMonitor
        # self.cleanup_thread.start()
        # logger.info("üßπ Thread de nettoyage des watchers d√©marr√©")

        # Force un scan initial
        logger.info("üîç For√ßage du scan initial des cha√Ænes...")
        self._do_scan(force=True)
        logger.info("‚úÖ Scan initial termin√©")

        # >>> STEP 3: REMOVE second _clean_startup call
        # _clean_startup called only once at the beginning now
        # self._clean_startup()
        # <<< END STEP 3

        last_scan_time = time.time()
        last_summary_time = time.time()
        last_resync_time = time.time()
        last_log_watchers_time = time.time()
        last_process_logs_time = time.time()  # Pour traiter les logs r√©guli√®rement

    def request_scan(self, force: bool = False):
        """Demande un scan en le mettant dans la queue"""
        self.scan_queue.put(force)
        logger.debug("Scan demand√©" + (" (forc√©)" if force else ""))

    def _scan_worker(self):
        """Thread qui g√®re les scans de mani√®re centralis√©e"""
        logger.info("üîç D√©marrage du thread de scan worker")
        while not self.stop_scan_thread.is_set():
            try:
                # Attendre une demande de scan ou le d√©lai p√©riodique
                try:
                    force = self.scan_queue.get(timeout=30)  # 30 secondes de d√©lai par d√©faut
                except Empty:  # Fixed: Using imported Empty instead of Queue.Empty
                    force = False  # Scan p√©riodique normal

                current_time = time.time()
                
                # V√©rifier le cooldown sauf si scan forc√©
                if not force and (current_time - self.last_scan_time) < 15:
                    logger.debug("‚è≠Ô∏è Scan ignor√© (cooldown)")
                    continue

                with self.scan_lock:
                    logger.info("üîç D√©marrage du scan" + (" forc√©" if force else ""))
                    self._do_scan(force)
                    self.last_scan_time = time.time()

                # --- V√©rification p√©riodique des cha√Ænes inactives ---
                if current_time - self.last_inactivity_check > 60: # V√©rifier toutes les 60 secondes
                    self._check_inactive_channels()
                    self.last_inactivity_check = current_time
                # -----------------------------------------------------

            except Exception as e:
                logger.error(f"‚ùå Erreur dans le thread de scan: {e}")
                time.sleep(5)

    def _do_scan(self, force: bool = False):
        """Effectue le scan r√©el des cha√Ænes et r√©concilie avec les statistiques."""
        try:
            content_path = Path(self.content_dir)
            if not content_path.exists():
                logger.error(f"Le dossier de contenu {content_path} n'existe pas!")
                return

            # 1. Obtenir tous les r√©pertoires du syst√®me de fichiers
            channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
            found_on_disk = {d.name for d in channel_dirs}
            logger.info(f"üìÇ {len(found_on_disk)} dossiers de cha√Ænes trouv√©s sur le disque.")

            # 2. Obtenir tous les canaux des statistiques et les r√©concilier
            with self.scan_lock:
                if self.stats_collector:
                    stats_known_channels = set(self.stats_collector.channel_stats.keys())
                    stats_known_channels.discard("global")
                else:
                    stats_known_channels = set()

                # 3. Calculer la diff√©rence
                removed_channels = stats_known_channels - found_on_disk
                if removed_channels:
                    logger.info(f"üóëÔ∏è Cha√Ænes obsol√®tes √† supprimer des stats: {removed_channels}")
                    # 4. Supprimer les canaux obsol√®tes
                    for removed_name in removed_channels:
                        self.remove_channel(removed_name)

            # 5. Parcourir les r√©pertoires du syst√®me de fichiers pour ajouter/mettre √† jour les canaux
            for channel_dir in channel_dirs:
                channel_name = channel_dir.name
                
                with self.scan_lock:
                    if channel_name in self.channels:
                        if force:
                            logger.info(f"üîÑ Scan forc√© : Cha√Æne existante {channel_name} - rafra√Æchissement √©ventuel g√©r√© par la cha√Æne elle-m√™me.")
                        continue
                    else:
                        self.channels[channel_name] = None
                        logger.debug(f"[{channel_name}] Ajout d'un placeholder √† self.channels.")

                logger.info(f"‚úÖ Nouvelle cha√Æne d√©tect√©e : {channel_name}")
                
                logger.info(f"‚è≥ Mise en file d'attente pour initialisation de la cha√Æne {channel_name}")
                self.channel_init_queue.put({
                    "name": channel_name,
                    "dir": channel_dir,
                    "from_queue": True
                })

            # Mettre √† jour la playlist ma√Ætre apr√®s la r√©conciliation
            self._update_master_playlist()

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du scan des cha√Ænes: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire IPTV"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        
        # Utiliser la m√©thode compl√®te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("üõë Gestionnaire IPTV arr√™t√© avec succ√®s")

    def update_watchers(self, channel_name: str, watcher_count: int, active_ips_list: list, path: str = "/hls/", source: str = 'unknown'):
        """
        Met √† jour le statut d'une cha√Æne (nombre de watchers, IPs) suite √† une notification
        du ClientMonitor (bas√© sur les logs Nginx).
        Met directement √† jour le ChannelStatusManager.
        
        Args:
            channel_name: Nom de la cha√Æne.
            watcher_count: Nombre actuel de watchers pour cette cha√Æne.
            active_ips_list: Liste des IPs des watchers actifs.
            path: (Ignor√©, conserv√© pour compatibilit√© potentielle)
            source: Source de la mise √† jour: 'nginx_log', 'nginx_log_immediate', etc.
        """
        # Ignorer la playlist ma√Ætre
        if channel_name == "master_playlist":
            return True

        # V√©rifier si le ChannelStatusManager est disponible
        if not hasattr(self, "channel_status") or self.channel_status is None:
            # Log une seule fois pour √©viter le spam
            if not getattr(self, "_logged_csm_missing", False):
                logger.warning("‚ö†Ô∏è ChannelStatusManager non disponible dans update_watchers. Impossible de mettre √† jour le statut.")
                self._logged_csm_missing = True
            return False
        else:
            # R√©initialiser le flag de log si CSM est √† nouveau disponible
            self._logged_csm_missing = False

        try:
            # Forcer une mise √† jour M√äME si les viewers n'ont pas chang√©
            # C'est crucial pour maintenir les canaux actifs √† jour
            
            # Log diff√©rent selon que c'est une mise √† jour imm√©diate ou p√©riodique
            if source == 'nginx_log_immediate':
                logger.info(f"[{channel_name}] üîÑ Mise √† jour IMM√âDIATE: {watcher_count} watchers")
            else:
                logger.debug(f"[{channel_name}] Callback update_watchers: {watcher_count} watchers (Source: {source})")
            
            # Pr√©parer les donn√©es pour ChannelStatusManager
            # On suppose que si ClientMonitor notifie, la cha√Æne est consid√©r√©e 'live'
            # ou du moins potentiellement active si des watchers sont pr√©sents.
            channel_obj = self.channels.get(channel_name)
            is_live_status = False
            if channel_obj:
                is_live_status = (hasattr(channel_obj, 'is_ready_for_streaming') and channel_obj.is_ready_for_streaming())
            
            # Pour les canaux avec des watchers actifs, toujours les marquer comme actifs
            # m√™me si le canal n'est pas techniquement "streaming"
            if watcher_count > 0:
                is_live_status = True
            
            status_data = {
                "is_live": is_live_status,
                "viewers": watcher_count,
                "watchers": active_ips_list,
                "last_updated": datetime.now().isoformat()
            }
            
            # Forcer la sauvegarde si le nombre de spectateurs a chang√©.
            current_status = self.channel_status.channels.get(channel_name, {})
            previous_viewers = current_status.get("viewers", 0)
            viewers_changed = (watcher_count != previous_viewers)

            # Forcer la sauvegarde imm√©diate si les viewers ont chang√© ou si la source le demande
            force_immediate_save = viewers_changed or (source == 'nginx_log_immediate')

            # Mettre √† jour directement le ChannelStatusManager
            success = self.channel_status.update_channel(
                channel_name,
                status_data,
                force_save=force_immediate_save
            )
            
            if success:
                if source == 'nginx_log_immediate':
                    logger.info(f"[{channel_name}] ‚úÖ Mise √† jour IMM√âDIATE r√©ussie dans ChannelStatusManager")
                else:
                    logger.debug(f"[{channel_name}] ‚úÖ Statut mis √† jour dans ChannelStatusManager (Viewers: {watcher_count})")
                return True
            else:
                logger.warning(f"[{channel_name}] ‚ö†Ô∏è √âchec de la mise √† jour du statut via ChannelStatusManager.")
                return False
                
        except Exception as e:
            logger.error(f"[{channel_name}] ‚ùå Erreur dans update_watchers: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _log_channels_summary(self):
        """G√©n√®re et affiche un r√©capitulatif de l'√©tat des cha√Ænes bas√© sur ChannelStatusManager"""
        try:
            # Utiliser self.channel_status comme source de v√©rit√©
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.info("üìä ChannelStatusManager non disponible pour le r√©capitulatif")
                return

            # Lire l'√©tat actuel des cha√Ænes depuis ChannelStatusManager
            # Acc√®s direct, le manager interne g√®re les verrous pour les √©critures
            current_statuses = self.channel_status.channels
            manager_known_channels = list(self.channels.keys()) # Cha√Ænes connues par IPTVManager

            if not manager_known_channels:
                logger.info("üìä Aucune cha√Æne g√©r√©e par IPTVManager pour le r√©capitulatif")
                return

            # Organiser les cha√Ænes par √©tat bas√© sur current_statuses
            live_with_viewers = []
            live_without_viewers = []
            not_live_channels = []

            for name in sorted(manager_known_channels):
                status = current_statuses.get(name, {}) # Obtenir le statut ou un dict vide
                is_live = status.get('is_live', False)
                viewers_count = status.get('viewers', 0)
                watchers_list = status.get('watchers', [])

                channel_info = {
                    "name": name,
                    "viewers": viewers_count,
                    "is_live": is_live,
                    "watchers": watchers_list
                }

                if is_live:
                    if viewers_count > 0:
                        live_with_viewers.append(channel_info)
                    else:
                        live_without_viewers.append(channel_info)
                else:
                    # Inclut les cha√Ænes explicitement non live et celles inconnues du status manager
                    not_live_channels.append(channel_info)

            # Construire le r√©capitulatif
            summary_lines = ["üìä R√âCAPITULATIF DES CHA√éNES (via ChannelStatusManager):"]

            # Afficher les cha√Ænes live avec viewers
            if live_with_viewers:
                active_parts = []
                for ch in live_with_viewers:
                    active_parts.append(f"üü¢ {ch['name']}: {ch['viewers']} viewers")
                summary_lines.append(
                    "CHA√éNES LIVE AVEC VIEWERS: " + " | ".join(active_parts)
                )
            else:
                summary_lines.append("CHA√éNES LIVE AVEC VIEWERS: Aucune")

            # Afficher les cha√Ænes live sans viewers
            if live_without_viewers:
                inactive_parts = []
                for ch in live_without_viewers[:10]: # Limiter pour √©viter logs trop longs
                    inactive_parts.append(f"{ch['name']}")
                remaining = len(live_without_viewers) - 10
                if remaining > 0:
                    inactive_parts.append(f"et {remaining} autres")
                summary_lines.append(
                    f"CHA√éNES LIVE SANS VIEWERS: {len(live_without_viewers)} ({', '.join(inactive_parts)})"
                )
            else:
                summary_lines.append("CHA√éNES LIVE SANS VIEWERS: Aucune")

            # Afficher les cha√Ænes non-live ou inconnues
            if not_live_channels:
                stopped_names = [ch['name'] for ch in not_live_channels[:10]] # Limiter aussi
                remaining = len(not_live_channels) - 10
                if remaining > 0:
                    stopped_names.append(f"et {remaining} autres")
                summary_lines.append(f"CHA√éNES NON-LIVE / INCONNUES: {len(not_live_channels)} ({', '.join(stopped_names)})")
            else:
                summary_lines.append("CHA√éNES NON-LIVE / INCONNUES: Aucune")

            # Stats globales bas√©es sur ChannelStatusManager
            total_viewers = sum(ch["viewers"] for ch in live_with_viewers)
            total_live_streams = len(live_with_viewers) + len(live_without_viewers)
            total_known_channels = len(manager_known_channels)
            summary_lines.append(
                f"TOTAL: {total_viewers} viewers sur {total_live_streams} streams live ({total_known_channels} cha√Ænes g√©r√©es)"
            )

            # Afficher le r√©capitulatif
            logger.info("\n".join(summary_lines))

        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©capitulatif: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _clean_startup(self):
        """Nettoyage initial optimis√©"""
        try:
            logger.info("üßπ Nettoyage initial... (appel unique au d√©marrage)")

            content_path = Path(self.content_dir)
            if not content_path.exists():
                content_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"üìÇ Cr√©ation du dossier de contenu: {content_path}")

            # Force reset of channel status file at startup
            logger.info("üîÑ R√©initialisation du fichier de statut des cha√Ænes...")
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)

            # Create a fresh status file with zero viewers
            with open(CHANNELS_STATUS_FILE, 'w') as f:
                json.dump({
                    'channels': {},
                    'last_updated': int(time.time()),
                    'active_viewers': 0
                }, f, indent=2)

            logger.info("‚úÖ Fichier de statut r√©initialis√©")

            # Nettoyage des dossiers HLS
            self.hls_cleaner.initial_cleanup()

            # Start the cleaner thread only if it's not already alive
            if hasattr(self.hls_cleaner, 'cleanup_thread') and not self.hls_cleaner.cleanup_thread.is_alive():
                self.hls_cleaner.start()
                logger.info("‚úÖ HLSCleaner thread started.")
            else:
                logger.info("‚ÑπÔ∏è HLSCleaner thread already running or finished, not starting again.")

            logger.info("‚úÖ Nettoyage initial termin√©")

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du nettoyage initial: {e}")

    def scan_channels(self, force: bool = False, initial: bool = False):
        """
        Scanne le contenu pour d√©tecter les nouveaux dossiers (cha√Ænes).
        Version am√©lior√©e avec limitation de fr√©quence et debug pour isolation du probl√®me
        """
        # Limiter la fr√©quence des scans
        current_time = time.time()
        scan_cooldown = 30  # 30s entre scans complets (sauf si force=True)

        if (
            not force
            and not initial
            and hasattr(self, "last_scan_time")
            and current_time - self.last_scan_time < scan_cooldown
        ):
            logger.debug(
                f"Scan ignor√©: dernier scan il y a {current_time - self.last_scan_time:.1f}s"
            )
            return

        setattr(self, "last_scan_time", current_time)

        with self.scan_lock:
            try:
                content_path = Path(self.content_dir)
                if not content_path.exists():
                    logger.error(f"Le dossier {content_path} n'existe pas!")
                    return

                # Debugging: log the directory and its existence
                logger.debug(f"üîç Scanning content directory: {content_path} (exists: {content_path.exists()})")
                
                # Get all subdirectories 
                channel_dirs = [d for d in content_path.iterdir() if d.is_dir()]
                
                # Debug the found directories
                logger.debug(f"üìÇ Found {len(channel_dirs)} potential channel directories: {[d.name for d in channel_dirs]}")

                logger.info(f"üì° Scan des cha√Ænes disponibles...")
                for channel_dir in channel_dirs:
                    channel_name = channel_dir.name
                    
                    # Debug: check if this directory should be a channel
                    logger.debug(f"Examining directory: {channel_name} ({channel_dir})")

                    if channel_name in self.channels:
                        # Si la cha√Æne existe d√©j√†, on v√©rifie son √©tat
                        if force:
                            logger.info(
                                f"üîÑ Rafra√Æchissement de la cha√Æne {channel_name}"
                            )
                            channel = self.channels[channel_name]
                            if hasattr(channel, "refresh_videos"):
                                channel.refresh_videos()
                        else:
                            logger.info(f"‚úÖ Cha√Æne existante: {channel_name}")
                        continue

                    logger.info(f"‚úÖ Nouvelle cha√Æne trouv√©e: {channel_name}")

                    # Ajoute la cha√Æne √† la queue d'initialisation
                    self.channel_init_queue.put(
                        {"name": channel_name, "dir": channel_dir}
                    )

                logger.info(f"üì° Scan termin√©, {len(channel_dirs)} cha√Ænes identifi√©es")

            except Exception as e:
                logger.error(f"Erreur scan des cha√Ænes: {e}")
                import traceback
                logger.error(traceback.format_exc())

    def ensure_hls_directory(self, channel_name: str = None):
        """Cr√©e et configure les dossiers HLS avec les bonnes permissions"""
        # Dossier HLS principal
        base_hls = Path(HLS_DIR)
        if not base_hls.exists():
            logger.info("üìÇ Cr√©ation du dossier HLS principal...")
            base_hls.mkdir(parents=True, exist_ok=True)

        # Dossier sp√©cifique √† une cha√Æne si demand√©
        if channel_name:
            channel_hls = base_hls / channel_name
            if not channel_hls.exists():
                logger.info(f"üìÇ Cr√©ation du dossier HLS pour {channel_name}")
                channel_hls.mkdir(parents=True, exist_ok=True)

    def _manage_master_playlist(self):
        """G√®re la mise √† jour p√©riodique de la playlist principale"""
        logger.info("üîÑ D√©marrage thread de mise √† jour de la playlist principale")
        
        # S'assurer que la playlist existe avec des permissions correctes d√®s le d√©part
        playlist_path = os.path.abspath(f"{HLS_DIR}/playlist.m3u")
        if not os.path.exists(playlist_path):
            # Cr√©er un contenu minimal
            with open(playlist_path, "w", encoding="utf-8") as f:
                f.write("#EXTM3U\n")
            logger.info(f"‚úÖ Playlist initiale cr√©√©e: {playlist_path}")
        
        # Mise √† jour imm√©diate au d√©marrage
        try:
            self._update_master_playlist()
            logger.info("‚úÖ Premi√®re mise √† jour de la playlist effectu√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur premi√®re mise √† jour playlist: {e}")
        
        # Mises √† jour fr√©quentes au d√©marrage
        for _ in range(3):
            try:
                # Attendre un peu entre les mises √† jour
                time.sleep(10)
                self._update_master_playlist()
                logger.info("‚úÖ Mise √† jour de d√©marrage de la playlist effectu√©e")
            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour playlist de d√©marrage: {e}")
        
        # Continuer avec des mises √† jour p√©riodiques
        while True:
            try:
                self._update_master_playlist()
                time.sleep(60)  # On attend 60s avant la prochaine mise √† jour
            except Exception as e:
                logger.error(f"‚ùå Erreur maj master playlist: {e}")
                logger.error(traceback.format_exc())
                time.sleep(60)  # On attend m√™me en cas d'erreur

    def _update_master_playlist(self):
        """Effectue la mise √† jour de la playlist principale"""
        playlist_path = os.path.abspath(f"{HLS_DIR}/playlist.m3u")
        logger.debug(f"üîÑ Master playlist maj.: {playlist_path}")
        
        # Utiliser le verrou de scan pour prot√©ger l'acc√®s aux cha√Ænes
        with self.scan_lock:
            try:
                # On sauvegarde d'abord le contenu actuel au cas o√π
                existing_content = "#EXTM3U\n"
                if os.path.exists(playlist_path) and os.path.getsize(playlist_path) > 0:
                    try:
                        with open(playlist_path, "r", encoding="utf-8") as f:
                            existing_content = f.read()
                        logger.debug(f"‚úÖ Contenu actuel sauvegard√©: {len(existing_content)} octets")
                    except Exception as e:
                        logger.error(f"‚ùå Erreur lecture playlist existante: {e}")
                
                # Pr√©paration du nouveau contenu
                content = "#EXTM3U\n"

                # Build ready_channels based on channel objects status
                ready_channels = []
                # *** REMOVED redundant scan_lock, using self.lock now ***
                # with self.scan_lock: 
                for name, channel in sorted(self.channels.items()):
                    # Ensure channel object exists and check its ready status
                    if channel and hasattr(channel, 'is_ready_for_streaming') and channel.is_ready_for_streaming():
                        ready_channels.append((name, channel))
                        logger.debug(f"[{name}] ‚úÖ Cha√Æne pr√™te pour la playlist ma√Ætre")
                    elif channel:
                        logger.debug(f"[{name}] ‚è≥ Cha√Æne non pr√™te pour la playlist ma√Ætre")
                    else:
                        logger.debug(f"[{name}] ‚è≥ Cha√Æne non initialis√©e, non ajout√©e √† la playlist ma√Ætre.")

                # √âcriture des cha√Ænes pr√™tes
                # No need to get SERVER_URL from os.getenv since we already imported it from config
                if ready_channels:
                    for name, _ in ready_channels:
                        content += f'#EXTINF:-1 tvg-id="{name}" tvg-name="{name}",{name}\n'
                        content += f"http://{SERVER_URL}/hls/{name}/playlist.m3u8\n"
                else:
                    # Si aucune cha√Æne n'est pr√™te, ajouter un commentaire
                    content += "# Aucune cha√Æne active pour le moment\n"
                    logger.warning("‚ö†Ô∏è Aucune cha√Æne active d√©tect√©e pour la playlist")
                
                # Loguer le contenu √† √©crire pour v√©rification
                logger.debug(f"üìù Contenu de la playlist √† √©crire:\n{content}")
                
                # √âcrire dans un fichier temporaire d'abord
                temp_path = f"{playlist_path}.tmp"
                with open(temp_path, "w", encoding="utf-8") as f:
                    f.write(content)
                    # *** ADDED: Ensure file is written to disk before checking size ***
                    f.flush()
                    os.fsync(f.fileno())
                    # *** END ADDED ***
                
                # V√©rifier que le fichier temporaire a √©t√© cr√©√© correctement
                # *** ADDED: Short delay to allow filesystem sync ***
                time.sleep(0.1) 
                # *** END ADDED ***
                if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
                    # Remplacer l'ancien fichier
                    os.replace(temp_path, playlist_path)
                    logger.debug(f"‚úÖ Playlist remplac√©e avec succ√®s")
                else:
                    logger.error(f"‚ùå Fichier temporaire vide ou non cr√©√©: {temp_path}")
                    # Ne pas remplacer l'ancien fichier si le temporaire est vide
                    raise Exception("Fichier temporaire vide ou non cr√©√©")
                
                
                # V√©rification que le fichier a √©t√© correctement √©crit
                if os.path.exists(playlist_path):
                    size = os.path.getsize(playlist_path)
                    logger.debug(f"‚úÖ Playlist √©crite: {playlist_path}, taille: {size} octets")
                    
                    # Lire le contenu pour v√©rification
                    with open(playlist_path, "r", encoding="utf-8") as f:
                        read_content = f.read()
                        if read_content == content:
                            logger.debug("‚úÖ Contenu v√©rifi√©, identique √† ce qui devait √™tre √©crit")
                        else:
                            logger.error("‚ùå Contenu lu diff√©rent du contenu qui devait √™tre √©crit")
                            logger.error(f"üìÑ Contenu lu:\n{read_content}")
                            # Essayer d'√©crire directement
                            with open(playlist_path, "w", encoding="utf-8") as f:
                                f.write(content)
                            logger.info("üîÑ Tentative d'√©criture directe effectu√©e")
                else:
                    logger.error(f"‚ùå Fichier non trouv√© apr√®s √©criture: {playlist_path}")
                    # Recr√©er avec le contenu existant
                    with open(playlist_path, "w", encoding="utf-8") as f:
                        f.write(existing_content)
                    logger.warning("üîÑ Restauration du contenu pr√©c√©dent")

                # Use len(self.channels) which includes all potentially initializing channels (placeholders)
                total_channels_known_by_manager = len(self.channels)
                # Count non-None channels for a more accurate 'loaded' count
                loaded_channels_count = sum(1 for ch in self.channels.values() if ch is not None)
                logger.info(
                    f"‚úÖ Playlist mise √† jour avec {len(ready_channels)} cha√Ænes pr√™tes sur {loaded_channels_count} charg√©es ({total_channels_known_by_manager} total connu par manager)"
                )
            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour playlist: {e}")
                logger.error(traceback.format_exc())
                
                # En cas d'erreur, v√©rifier si le fichier existe toujours
                if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                    # Restaurer le contenu pr√©c√©dent s'il existe
                    if existing_content and len(existing_content) > 8:  # Plus que juste "#EXTM3U\n"
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write(existing_content)
                        logger.info("‚úÖ Contenu pr√©c√©dent restaur√©")
                    
                    # Si pas de contenu pr√©c√©dent ou erreur, cr√©er une playlist minimale
                    if not os.path.exists(playlist_path) or os.path.getsize(playlist_path) == 0:
                        with open(playlist_path, "w", encoding="utf-8") as f:
                            f.write("#EXTM3U\n# Playlist de secours\n")
                        logger.info("‚úÖ Playlist minimale cr√©√©e en fallback")
            
            # Removed the redundant stream start logic from here

    def cleanup_manager(self):
        """Cleanup everything before shutdown"""
        logger.info("D√©but du nettoyage...")
        
        # Stop all threads first
        self.stop_scan_thread.set()
        self.stop_init_thread.set()
 
        # Vider tous les viewers du fichier de statut avant arr√™t
        try:
            if self.channel_status is not None:
                logger.info("üßπ Vidage de tous les viewers du fichier channel_status.json avant arr√™t...")
                flush_success = self.channel_status.flush_all_viewers()
                if flush_success:
                    logger.info("‚úÖ Tous les viewers ont √©t√© vid√©s avec succ√®s du fichier de statut")
                else:
                    logger.warning("‚ö†Ô∏è √âchec du vidage des viewers avant arr√™t")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du vidage des viewers: {e}")

        # Stop components that might be None
        try:
            if self.channel_status is not None:
                self.channel_status.stop()
                logger.info("‚úÖ Channel status manager stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du channel status manager: {e}")

        try:
            if self.stats_collector is not None:
                self.stats_collector.stop()
                logger.info("üìä StatsCollector arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du StatsCollector: {e}")

        try:
            if self.hls_cleaner is not None:
                self.hls_cleaner.stop_cleaner()
                logger.info("üßπ HLS Cleaner arr√™t√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du HLS Cleaner: {e}")

        # Join threads with timeout
        threads_to_join = [
            (self.channel_init_thread, "Channel init thread"),
            (self.scan_thread, "Scan thread"),
            # (self.cleanup_thread, "Cleanup thread"),
        ]

        for thread, name in threads_to_join:
            try:
                if thread and thread.is_alive():
                    thread.join(timeout=5)
                    logger.info(f"‚úÖ {name} stopped")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors de l'arr√™t du thread {name}: {e}")

        # Stop observers
        try:
            if hasattr(self, "observer"):
                self.observer.stop()
                self.observer.join(timeout=5)
                logger.info("‚úÖ Main observer stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t de l'observer principal: {e}")

        try:
            if hasattr(self, "ready_observer"):
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)
                logger.info("‚úÖ Ready observer stopped")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'arr√™t du ready observer: {e}")
            
        # Clean up channels
        for name, channel in list(self.channels.items()):
            try:
                if channel is not None:
                    channel._clean_processes()
                    logger.info(f"‚úÖ Channel {name} cleaned up")
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du nettoyage du canal {name}: {e}")

        logger.info("‚úÖ Nettoyage termin√©")

    def _setup_ready_observer(self):
        """Configure l'observateur pour les dossiers ready_to_stream de chaque cha√Æne"""
        try:
            # D'abord, arr√™ter et recr√©er l'observateur si n√©cessaire pour √©viter les doublons
            if hasattr(self, "ready_observer") and self.ready_observer.is_alive():
                self.ready_observer.stop()
                self.ready_observer.join(timeout=5)

            self.ready_observer = Observer()

            # Pour chaque cha√Æne existante
            paths_scheduled = set()  # Pour √©viter les doublons

            for name, channel in self.channels.items():
                # ADDED: Check if channel object is None
                if channel is None:
                    logger.debug(f"_setup_ready_observer: Skipping channel {name} as object is None.")
                    continue
                    
                ready_dir = Path(channel.video_dir) / "ready_to_stream"
                ready_dir.mkdir(
                    parents=True, exist_ok=True
                )  # S'assurer que le dossier existe

                if ready_dir.exists() and str(ready_dir) not in paths_scheduled:
                    self.ready_observer.schedule(
                        self.ready_event_handler, str(ready_dir), recursive=False
                    )
                    paths_scheduled.add(str(ready_dir))
                    logger.debug(
                        f"üëÅÔ∏è Surveillance ready_to_stream configur√©e pour {name}: {ready_dir}"
                    )

            # D√©marrage de l'observateur
            self.ready_observer.start()
            logger.info(
                f"üöÄ Observateur ready_to_stream d√©marr√© pour {len(paths_scheduled)} chemins"
            )

        except Exception as e:
            logger.error(f"‚ùå Erreur configuration surveillance ready_to_stream: {e}")
            import traceback

            logger.error(traceback.format_exc())

    def _update_channel_status(self, initial_call=False):
        """Update channel status for dashboard"""
        try:
            if not self.channel_status:
                logger.warning("‚ö†Ô∏è Channel status manager not initialized")
                return False
                
            # Ensure stats directory exists and has proper permissions
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)

            
            # Prepare channel status data
            channels_dict = {}
            # Use scan_lock for iterating self.channels safely
            with self.scan_lock:
                for channel_name, channel in self.channels.items():
                    # Only include channels that have been initialized (are not None)
                    if channel and hasattr(channel, 'is_ready_for_streaming'):
                        is_ready = channel.is_ready_for_streaming()
                        is_streaming = channel.is_running() if hasattr(channel, 'is_running') else False
                        
                        # Les informations sur les viewers sont maintenant g√©r√©es par ChannelStatusManager
                        # On ne les met pas √† jour ici pour √©viter les conflits
                        status_data = {
                            "active": is_ready,
                            "streaming": is_streaming,
                        }
                        channels_dict[channel_name] = status_data
                    # else: # Log channels that are skipped during update
                        # logger.debug(f"_update_channel_status: Skipping channel '{channel_name}' (not initialized or no is_ready attr)")

            
            # If no channels are ready or available, don't wipe the status
            if not channels_dict:
                # Avoid logging this message too frequently if manager starts with no channels
                log_key = "_last_no_channels_log_time"
                now = time.time()
                if not hasattr(self, log_key) or now - getattr(self, log_key) > 60:
                     logger.info("ü§∑ No initialized channels found, skipping status update.")
                     setattr(self, log_key, now)
                return True # Indicate success as no update was needed

            # Update status with retry logic
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    # Call the method responsible for writing the combined status
                    success = self.channel_status.update_all_channels(channels_dict)
                    if success:
                        logger.debug(f"‚úÖ Channel status file updated successfully ({'initial' if initial_call else 'periodic'})")
                        return True
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status file (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error calling channel_status.update_all_channels (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to update channel status file after all retries")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error in _update_channel_status: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _check_channels_timeout(self):
        """V√©rifie p√©riodiquement les timeouts des cha√Ænes sans watchers"""
        try:
            # Use list() to avoid issues if dict changes during iteration
            for channel_name, channel in list(self.channels.items()): 
                # ---> ADD CHECK FOR NONE <--- 
                if channel is not None and hasattr(channel, 'check_watchers_timeout'):
                    channel.check_watchers_timeout()
                elif channel is None:
                    logger.debug(f"_check_channels_timeout: Skipping channel {channel_name} as object is None.")
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification timeouts: {e}")

    def _run_periodic_tasks(self):
        """Ex√©cute toutes les t√¢ches p√©riodiques."""
        last_times = {
            "scan": 0,
            "summary": 0,
            "resync": 0,
            "log_watchers": 0,
            "process_logs": 0,
            "commands": 0,
        }
        
        while not self.stop_scan_thread.is_set():
            now = time.time()

            # V√©rifier les commandes (toutes les 2 secondes)
            if now - last_times["commands"] > 2:
                self._check_for_commands()
                last_times["commands"] = now

            # Traiter les logs Nginx (fr√©quemment)
            if now - last_times["process_logs"] > 0.5 and hasattr(self, "client_monitor") and self.client_monitor:
                self.client_monitor.process_new_logs()
                last_times["process_logs"] = now

            # Scan p√©riodique
            if now - last_times["scan"] > self.periodic_scan_interval:
                self._periodic_scan()
                last_times["scan"] = now

            # Affichage du r√©capitulatif
            if now - last_times["summary"] > SUMMARY_CYCLE:
                self._log_channels_summary()
                last_times["summary"] = now
            
            # Resynchronisation des playlists
            if now - last_times["resync"] > 600:
                self._resync_all_playlists()
                last_times["resync"] = now

            # Log des watchers
            if now - last_times["log_watchers"] > WATCHERS_LOG_CYCLE and hasattr(self, "_log_watchers_status"):
                self._log_watchers_status()
                last_times["log_watchers"] = now

            time.sleep(0.1)

    def run_manager_loop(self):
        """Boucle principale du gestionnaire IPTV."""
        logger.info("üîÑ D√©marrage de la boucle principale du gestionnaire")
        
        if not hasattr(self, "observer") or not self.observer.is_alive():
            self.observer.start()
            logger.info("üëÅÔ∏è Observateur de contenu d√©marr√©")

        # D√©marrer le thread pour les t√¢ches p√©riodiques
        self.periodic_task_thread = threading.Thread(target=self._run_periodic_tasks, daemon=True)
        self.periodic_task_thread.start()
        logger.info("üîÑ Thread des t√¢ches p√©riodiques d√©marr√©")

        try:
            # La boucle principale peut maintenant √™tre utilis√©e pour d'autres logiques si n√©cessaire,
            # ou simplement pour maintenir le processus en vie.
            while not self.stop_scan_thread.is_set():
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("üëã Interruption clavier, arr√™t du gestionnaire")
            self.stop()
        except Exception as e:
            logger.critical(f"‚ùå ERREUR MAJEURE dans la boucle principale: {e}")
            import traceback
            logger.critical(traceback.format_exc())
            self.stop()
            
        logger.info("üõë Boucle principale du gestionnaire termin√©e")

    def _periodic_scan(self):
        """Effectue un scan p√©riodique des cha√Ænes pour d√©tecter les changements"""
        if self.stop_periodic_scan.is_set():
            return

        try:
            logger.debug(f"üîÑ Scan p√©riodique des cha√Ænes en cours...")
            self.scan_channels(force=True)
            
            # NOUVEAU: Resynchronisation p√©riodique des playlists
            self._resync_all_playlists()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur scan p√©riodique: {e}")

    def _resync_all_playlists(self):
        """Force la resynchronisation des playlists pour toutes les cha√Ænes"""
        try:
            resync_count = 0
            for channel_name, channel in list(self.channels.items()):
                # V√©rifier si la cha√Æne a une m√©thode de cr√©ation de playlist
                if hasattr(channel, "_create_concat_file"):
                    # On ne recr√©√© pas toutes les playlists √† chaque fois, on alterne
                    # 1/4 des cha√Ænes √† chaque cycle pour ne pas surcharger le syst√®me
                    if random.randint(1, 4) == 1:  
                        logger.debug(f"[{channel_name}] üîÑ Resynchronisation p√©riodique de la playlist")
                        
                        # Cr√©er un thread d√©di√© pour resynchroniser et red√©marrer si n√©cessaire
                        def resync_and_restart(ch_name, ch):
                            try:
                                # 1. V√©rifier l'√©tat actuel de la playlist
                                playlist_path = Path(ch.video_dir) / "_playlist.txt"
                                old_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        old_content = f.read()
                                
                                # 2. Mettre √† jour la playlist
                                ch._create_concat_file()
                                
                                # 3. V√©rifier si la playlist a chang√©
                                new_content = ""
                                if playlist_path.exists():
                                    with open(playlist_path, "r", encoding="utf-8") as f:
                                        new_content = f.read()
                                
                                # 4. Red√©marrer seulement si le contenu a chang√©
                                if old_content != new_content:
                                    logger.info(f"[{ch_name}] üîÑ Playlist modifi√©e, red√©marrage du stream n√©cessaire")
                                    
                                    # Add _restart_stream method if it doesn't exist
                                    if not hasattr(ch, "_restart_stream"):
                                        logger.warning(f"[{ch_name}] ‚ö†Ô∏è Adding missing _restart_stream method to channel.")
                                        # Add a basic implementation that will restart using start_stream
                                        def restart_stream_impl(diagnostic=None):
                                            """Basic implementation for channels missing _restart_stream method"""
                                            try:
                                                logger.info(f"[{ch_name}] üîÑ Basic restart implementation called. Reason: {diagnostic or 'Unknown'}")
                                                # Stop current stream if it's running
                                                if hasattr(ch, "process_manager") and ch.process_manager.is_running():
                                                    ch.process_manager.stop_process()
                                                
                                                # Clean HLS segments if possible
                                                if hasattr(ch, "hls_cleaner"):
                                                    ch.hls_cleaner.cleanup_channel(ch_name)
                                                
                                                # Try to start the stream again
                                                if hasattr(ch, "start_stream"):
                                                    success = ch.start_stream()
                                                    logger.info(f"[{ch_name}] {'‚úÖ Stream restarted successfully' if success else '‚ùå Failed to restart stream'}")
                                                    return success
                                                else:
                                                    logger.error(f"[{ch_name}] ‚ùå Channel doesn't have start_stream method")
                                                    return False
                                            except Exception as e:
                                                logger.error(f"[{ch_name}] ‚ùå Error in basic restart implementation: {e}")
                                                return False
                                        
                                        # Add the method to the channel
                                        setattr(ch, "_restart_stream", restart_stream_impl)
                                        logger.info(f"[{ch_name}] ‚úÖ Added basic _restart_stream method to channel")
                                    
                                    if hasattr(ch, "_restart_stream") and ch.process_manager.is_running():
                                        logger.info(f"[{ch_name}] üîÑ Red√©marrage du stream apr√®s mise √† jour p√©riodique de la playlist")
                                        ch._restart_stream()
                                else:
                                    logger.debug(f"[{ch_name}] ‚úì Playlist inchang√©e, pas de red√©marrage n√©cessaire")
                            except Exception as e:
                                logger.error(f"[{ch_name}] ‚ùå Erreur pendant la resynchronisation: {e}")
                        
                        # Lancer le thread de resynchronisation
                        threading.Thread(
                            target=resync_and_restart,
                            args=(channel_name, channel),
                            daemon=True
                        ).start()
                        resync_count += 1
                        logger.info(f"üîÑ [{channel_name}] {resync_count} playlists resynchronis√©es")
                else:
                    logger.debug(f"[{channel_name}] ‚ÑπÔ∏è Pas de m√©thode de cr√©ation de playlist, aucune resynchronisation n√©cessaire")
                    
            if resync_count > 0:
                logger.info(f"‚úÖ Resynchronisation et red√©marrage de {resync_count} cha√Ænes effectu√©s")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur resynchronisation des playlists: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def stop(self):
        """Arr√™te proprement le gestionnaire IPTV"""
        logger.info("üõë Arr√™t du gestionnaire IPTV...")
        
        # Utiliser la m√©thode compl√®te de nettoyage pour aussi vider les viewers
        self.cleanup_manager()
        
        logger.info("üõë Gestionnaire IPTV arr√™t√© avec succ√®s")

    def _process_channel_init_queue(self):
        """Process the queue of channels to initialize"""
        logger.info("üîÑ D√©marrage du thread de traitement de la queue d'initialisation des cha√Ænes")
        while not self.stop_init_thread.is_set():
            try:
                # Limite le nombre d'initialisations parall√®les
                with self.init_threads_lock:
                    active_threads = self.active_init_threads
                    if active_threads >= self.max_parallel_inits:
                        logger.debug(f"[INIT_QUEUE] ‚è≥ Limite d'initialisations parall√®les atteinte ({active_threads}/{self.max_parallel_inits}), attente...")
                        time.sleep(0.5)
                        continue

                # Essaie de r√©cup√©rer une cha√Æne de la queue
                channel_data = None
                try:
                    logger.debug("[INIT_QUEUE] ‚è±Ô∏è Attente d'un √©l√©ment dans la queue...")
                    channel_data = self.channel_init_queue.get(timeout=5)
                    channel_name = channel_data.get('name', 'unknown')
                    logger.info(f"[INIT_QUEUE] üì• R√©cup√©ration de {channel_name} depuis la queue")
                except Empty:
                    logger.debug("[INIT_QUEUE] üì™ Queue vide, attente...")
                    time.sleep(0.5)
                    continue # Continue to next iteration to check stop_event
                except Exception as q_err:
                    logger.error(f"[INIT_QUEUE] ‚ùå Erreur get() sur la queue: {q_err}")
                    time.sleep(1) # Wait a bit before retrying
                    continue

                # If we got an item from the queue
                if channel_data:
                    channel_name = channel_data.get('name', 'unknown')
                    # Incr√©mente le compteur de threads actifs
                    with self.init_threads_lock:
                        self.active_init_threads += 1
                        logger.debug(f"[INIT_QUEUE] ‚ûï [{channel_name}] Incr√©mentation du compteur de threads actifs: {self.active_init_threads}/{self.max_parallel_inits}")

                    # Lance un thread pour initialiser cette cha√Æne
                    logger.info(f"[INIT_QUEUE] üßµ [{channel_name}] D√©marrage d'un thread d'initialisation")
                    threading.Thread(
                        target=self._init_channel_async,
                        args=(channel_data,),
                        daemon=True,
                        name=f"Init-{channel_name}" # Add thread name
                    ).start()

            except Exception as e:
                logger.error(f"[INIT_QUEUE] ‚ùå Erreur majeure dans la boucle _process_channel_init_queue: {e}")
                logger.error(traceback.format_exc()) # Log full traceback
                time.sleep(5) # Wait longer after a major loop error

    def _init_channel_async(self, channel_data):
        """Initialise une cha√Æne de mani√®re asynchrone"""
        try:
            channel_name = channel_data["name"]
            channel_dir = channel_data["dir"]
            from_queue = channel_data.get("from_queue", True)  # Par d√©faut, on suppose que c'est de la queue

            logger.info(f"[{channel_name}] üîÑ Initialisation asynchrone de la cha√Æne")

            # Cr√©e l'objet cha√Æne
            channel = IPTVChannel(
                channel_name,
                str(channel_dir),
                hls_cleaner=self.hls_cleaner,
                use_gpu=self.use_gpu,
                stats_collector=self.stats_collector,
            )

            # Ajoute la r√©f√©rence au manager
            channel.manager = self

            # V√©rifie si la cha√Æne est pr√™te imm√©diatement apr√®s l'initialisation
            is_ready = channel.is_ready_for_streaming()
            
            with self.scan_lock:
                self.channels[channel_name] = channel

            if is_ready:
                logger.info(f"[{channel_name}] ‚úÖ Cha√Æne pr√™te, d√©marrage du stream...")
                if hasattr(channel, "start_stream"):
                    if channel.start_stream():
                        logger.info(f"[{channel_name}] ‚úÖ Stream d√©marr√© avec succ√®s.")
                        self._update_master_playlist()
                    else:
                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage du stream.")
                else:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è La m√©thode start_stream est manquante.")
            else:
                logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne non pr√™te apr√®s initialisation.")

            logger.info(f"[{channel_name}] ‚úÖ Traitement d'initialisation termin√© (Pr√™t: {is_ready})")

        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation de la cha√Æne {channel_data.get('name')}: {e}")
            # Make sure to add placeholder if exception happens before adding the channel object
            channel_name_for_exc = channel_data.get('name')
            if channel_name_for_exc:
                with self.scan_lock:
                    if channel_name_for_exc not in self.channels:
                        self.channels[channel_name_for_exc] = None # Placeholder on error
        finally:
            # D√©cr√©mente le compteur de threads actifs
            with self.init_threads_lock:
                self.active_init_threads -= 1

            # Marque la t√¢che comme termin√©e UNIQUEMENT si elle vient de la queue
            if channel_data.get("from_queue", True):
                self.channel_init_queue.task_done()

    def init_stats_collector_and_client_monitor(self):
        """Initialise le StatsCollector et le ClientMonitor une fois que les cha√Ænes sont pr√™tes"""
        logger.info("üöÄ Initialisation de StatsCollector et ClientMonitor maintenant que les cha√Ænes sont pr√™tes...")
        
        # Initialisation du StatsCollector
        if self.stats_collector is None:
            try:
                logger.info(">>> INITIALIZING STATS COLLECTOR <<<")
                self.stats_collector = StatsCollector()
                logger.info("üìä StatsCollector initialis√©")
                # Passer le callback update_watchers pour que StatsCollector puisse mettre √† jour les spectateurs directement
                self.stats_collector.update_watchers_callback = self.update_watchers
            except Exception as e:
                logger.error(f"‚ùå Erreur initialisation StatsCollector: {e}")
                self.stats_collector = None
        
        # Initialisation du ClientMonitor
        if self.client_monitor is None:
            try:
                self.client_monitor = ClientMonitor(
                    log_path=self.log_path,
                    update_watchers_callback=self.update_watchers,
                    manager=self,
                    stats_collector=self.stats_collector
                )
                # Au lieu de d√©marrer le thread, on initialise juste la position
                self.client_monitor.start()
                logger.info("üëÅÔ∏è ClientMonitor initialis√© et pr√™t")
            except Exception as e:
                logger.error(f"‚ùå Erreur initialisation ClientMonitor: {e}")
                self.client_monitor = None


    def _start_channel(self, channel_name):
        """D√©marre une cha√Æne sp√©cifique"""
        try:
            if channel_name in self.channels:
                channel = self.channels[channel_name]
                if channel.ready_for_streaming:
                    logger.info(f"[{channel_name}] üöÄ D√©marrage automatique...")
                    success = channel.start_stream()
                    if success:
                        logger.info(f"[{channel_name}] ‚úÖ D√©marrage automatique r√©ussi")
                    else:
                        logger.error(f"[{channel_name}] ‚ùå √âchec du d√©marrage automatique")
                else:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Non pr√™te pour le streaming, d√©marrage ignor√©")
            else:
                logger.error(f"[{channel_name}] ‚ùå Cha√Æne non trouv√©e dans le dictionnaire")
        except Exception as e:
            logger.error(f"[{channel_name}] ‚ùå Erreur lors du d√©marrage automatique: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def get_current_channel_status(self):
        """
        Retourne l'√©tat actuel de toutes les cha√Ænes, bas√© sur ChannelStatusManager.
        """
        try:
            if not hasattr(self, 'channel_status') or not self.channel_status:
                logger.warning("‚ö†Ô∏è Tentative d'acc√®s au statut des cha√Ænes mais ChannelStatusManager n'est pas pr√™t.")
                return {}

            # Acc√®s direct aux donn√©es de statut g√©r√©es par ChannelStatusManager
            # Aucune copie n√©cessaire ici car on ne fait que lire.
            status_data = self.channel_status.channels
            
            # Cr√©er une copie pour √©viter de retourner la r√©f√©rence interne 
            # et potentiellement filtrer pour ne retourner que les cha√Ænes connues du manager?
            # Pour l'instant, retournons tout ce que le status manager conna√Æt.
            return status_data.copy() 
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration du statut actuel des cha√Ænes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {}

    def get_channel_segment_duration(self, channel_name: str) -> Optional[float]:
        """Retrieves the configured HLS segment duration (hls_time) for a specific channel."""
        # Use scan_lock as channel dictionary might be modified during scans/inits
        with self.scan_lock:
            channel = self.channels.get(channel_name)
            if channel and hasattr(channel, 'command_builder') and hasattr(channel.command_builder, 'hls_time'):
                duration = getattr(channel.command_builder, 'hls_time', None)
                if isinstance(duration, (int, float)) and duration > 0:
                    logger.debug(f"[{channel_name}] Found segment duration: {duration}")
                    return float(duration)
                else:
                    logger.warning(f"[{channel_name}] Found invalid segment duration type/value: {duration} in command_builder")
                    return None
            elif channel:
                logger.warning(f"[{channel_name}] Channel object found but missing 'command_builder' or 'hls_time' attribute.")
                return None
            else:
                # Channel not found or is a placeholder (None)
                logger.warning(f"[{channel_name}] Channel not found or not fully initialized in IPTVManager.channels.")
                return None

    def init_channel_status_manager(self):
        """Initialize the channel status manager for dashboard"""
        try:
            # Si d√©j√† initialis√©, ne pas r√©initialiser
            if self.channel_status is not None:
                logger.info("‚ÑπÔ∏è Channel status manager d√©j√† initialis√©, skip")
                return

            logger.info("üöÄ Initialisation du gestionnaire de statuts des cha√Ænes")
            
            # Cr√©er le dossier stats s'il n'existe pas
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            
            # Cr√©er le fichier de statut s'il n'existe pas ou est vide/invalide
            should_create_file = True
            if os.path.exists(CHANNELS_STATUS_FILE):
                try:
                    if os.path.getsize(CHANNELS_STATUS_FILE) > 0:
                         with open(CHANNELS_STATUS_FILE, 'r') as f:
                             json.load(f) # Try to parse existing json
                         should_create_file = False # File exists and is valid JSON
                    # else: file exists but is empty, will overwrite
                except (json.JSONDecodeError, OSError) as e:
                     logger.warning(f"Existing status file {CHANNELS_STATUS_FILE} is invalid or unreadable ({e}). Will overwrite.")
                     # File exists but is invalid, will overwrite
                     
            if should_create_file:
                 logger.info(f"Creating/Overwriting initial status file: {CHANNELS_STATUS_FILE}")
                 with open(CHANNELS_STATUS_FILE, 'w') as f:
                     # Initial state with 0 viewers
                     json.dump({
                         'channels': {},
                         'last_updated': int(time.time()),
                         'active_viewers': 0
                     }, f, indent=2)
            
            # Initialiser le gestionnaire de statuts
            self.channel_status = ChannelStatusManager(
                status_file=CHANNELS_STATUS_FILE
            )
            
            # Faire une mise √† jour initiale avec retry, PASSING initial_call=True
            # Note: _update_channel_status needs TimeTracker, ensure it's initialized before calling this if needed
            # For now, we assume initialization is enough, actual update might happen later
            # max_retries = 3
            # retry_delay = 1
            # for attempt in range(max_retries):
            #     try:
            #         # Pass initial_call=True here
            #         success = self._update_channel_status(initial_call=True) # Depends on TimeTracker
            #         if success:
            #             logger.info("‚úÖ Channel status manager initialized for dashboard (initial status set)")
            #             return
            #         else:
            #             logger.warning(f"‚ö†Ô∏è Failed to update channel status during init (attempt {attempt + 1}/{max_retries})")
            #             if attempt < max_retries - 1:
            #                 time.sleep(retry_delay)
            #     except Exception as e:
            #         logger.error(f"‚ùå Error calling _update_channel_status during init (attempt {attempt + 1}/{max_retries}): {e}")
            #         if attempt < max_retries - 1:
            #             time.sleep(retry_delay)
            # logger.error("‚ùå Failed to initialize channel status manager after all retries")
            # self.channel_status = None
            logger.info("‚úÖ ChannelStatusManager initialis√©. La mise √† jour initiale se fera plus tard.")
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing channel status manager: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.channel_status = None
            
    def _check_inactive_channels(self):
        """
        V√©rifie les cha√Ænes actuellement en streaming mais sans viewers (selon ChannelStatusManager)
        et les arr√™te si elles sont inactives depuis trop longtemps.
        """
        if not hasattr(self, "channel_status") or self.channel_status is None:
            logger.debug("[_check_inactive_channels] ChannelStatusManager non disponible, skip.")
            return

        current_time = time.time()
        channels_to_stop = []

        # Utiliser le lock du ChannelStatusManager pour lire son √©tat
        with self.channel_status._lock:
            for channel_name, status_data in self.channel_status.channels.items():
                viewers = status_data.get("viewers", 0)
                is_live = status_data.get("is_live", False)
                last_updated_str = status_data.get("last_updated")
                
                # Ne v√©rifier que les cha√Ænes consid√©r√©es comme live mais sans viewers
                if is_live and viewers == 0:
                    # V√©rifier si la cha√Æne existe dans notre manager
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj and hasattr(channel_obj, 'is_running') and channel_obj.is_running():
                        # Initialiser last_active_time si ce n'est pas fait
                        if not hasattr(channel_obj, 'last_time_with_viewers'):
                            channel_obj.last_time_with_viewers = current_time
                            
                        # V√©rifier le d√©lai d'inactivit√©
                        inactive_duration = current_time - channel_obj.last_time_with_viewers
                        if inactive_duration > self.channel_inactivity_timeout:
                            logger.info(f"[{channel_name}] ‚è±Ô∏è Inactive depuis {inactive_duration:.0f}s (> {self.channel_inactivity_timeout}s) sans viewers. Arr√™t demand√©.")
                            channels_to_stop.append(channel_name)
                        else:
                             logger.debug(f"[{channel_name}] Inactive depuis {inactive_duration:.0f}s sans viewers, mais < timeout.")
                    # else: Channel is not streaming according to its object, no need to stop
                elif viewers > 0:
                    # Mettre √† jour le timestamp si des viewers sont pr√©sents
                    channel_obj = self.channels.get(channel_name)
                    if channel_obj:
                        channel_obj.last_time_with_viewers = current_time 

        # Arr√™ter les cha√Ænes identifi√©es (en dehors du lock de channel_status)
        for name in channels_to_stop:
            channel_obj = self.channels.get(name)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                 # V√©rifier √† nouveau si des viewers sont revenus entre temps?
                 # Pour l'instant, on arr√™te si la d√©cision a √©t√© prise.
                 logger.info(f"[{name}] üõë Arr√™t du stream pour inactivit√©.")
                 channel_obj.stop_stream_if_needed()
            else:
                 logger.warning(f"[{name}] Impossible d'arr√™ter le stream (objet non trouv√© ou m√©thode manquante)." )

    def remove_channel(self, channel_name: str):
        """Supprime compl√®tement une cha√Æne et nettoie ses ressources."""
        logger.info(f"üóëÔ∏è Tentative de suppression compl√®te de la cha√Æne: {channel_name}")
        with self.scan_lock:
            # 1. Arr√™ter le stream et nettoyer les processus
            channel_obj = self.channels.pop(channel_name, None)
            if channel_obj and hasattr(channel_obj, 'stop_stream_if_needed'):
                logger.info(f"[{channel_name}] Arr√™t du stream pour suppression...")
                channel_obj.stop_stream_if_needed()
            
            # 2. Supprimer du ChannelStatusManager
            if self.channel_status:
                self.channel_status.remove_channel(channel_name)
                logger.info(f"[{channel_name}] Supprim√© de ChannelStatusManager.")

            # 3. Supprimer du StatsCollector
            if self.stats_collector:
                self.stats_collector.remove_channel(channel_name)
                logger.info(f"[{channel_name}] Supprim√© de StatsCollector.")

            # 4. Nettoyer les fichiers HLS
            if self.hls_cleaner:
                self.hls_cleaner.cleanup_channel(channel_name)
                logger.info(f"[{channel_name}] Fichiers HLS nettoy√©s.")

            # 5. Mettre √† jour la playlist ma√Ætre
            self._update_master_playlist()
            
            logger.info(f"‚úÖ Suppression de la cha√Æne '{channel_name}' termin√©e.")

    def _check_for_commands(self):
        """Scans the command directory for new commands."""
        try:
            command_dir = Path(COMMAND_DIR)
            if not command_dir.exists():
                return

            for command_file in command_dir.glob("*.restart"):
                if command_file.is_file():
                    channel_name = command_file.stem
                    if channel_name in self.channels:
                        logger.info(f"ACTION: Commande '{command_file.suffix}' re√ßue pour la cha√Æne '{channel_name}' via scan")
                        self.restart_channel(channel_name)
                        try:
                            os.remove(command_file)
                            logger.info(f"Fichier de commande '{command_file}' supprim√©.")
                        except OSError as e:
                            logger.error(f"Erreur lors de la suppression du fichier de commande '{command_file}': {e}")
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification des commandes: {e}")

    def restart_channel(self, channel_name: str):
        """Red√©marre une cha√Æne sp√©cifique en utilisant sa m√©thode interne."""
        with self.scan_lock:
            channel = self.channels.get(channel_name)
            if channel and hasattr(channel, '_restart_stream'):
                logger.info(f"[{channel_name}] üîÑ Red√©marrage initi√© par le manager.")
                self.restarting_channels.add(channel_name)
                # Ex√©cuter le red√©marrage dans un thread s√©par√© pour ne pas bloquer
                threading.Thread(
                    target=self._restart_channel_thread,
                    args=(channel, channel_name),
                    daemon=True
                ).start()
            elif channel:
                logger.error(f"[{channel_name}] ‚ùå La m√©thode _restart_stream est introuvable.")
            else:
                logger.error(f"[{channel_name}] ‚ùå Cha√Æne introuvable pour le red√©marrage.")

    def _restart_channel_thread(self, channel, channel_name):
        """Thread worker for restarting a channel."""
        try:
            channel._restart_stream("manual_manager_restart")
        finally:
            # Attendre un peu pour que les op√©rations sur les fichiers se terminent
            time.sleep(5)
            self.restarting_channels.discard(channel_name)
            logger.info(f"[{channel_name}] ‚úÖ Red√©marrage termin√©.")
