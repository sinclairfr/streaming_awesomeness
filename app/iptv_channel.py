# iptv_channel.py
import os
import time
import threading
import random
from pathlib import Path
from typing import Optional, List
import shutil
from video_processor import VideoProcessor
from hls_cleaner import HLSCleaner
from ffmpeg_logger import FFmpegLogger
from ffmpeg_command_builder import FFmpegCommandBuilder
from ffmpeg_process_manager import FFmpegProcessManager
from playback_position_manager import PlaybackPositionManager
import subprocess
from config import (
    logger,
    CRASH_THRESHOLD,
    HLS_DIR,
)
from video_processor import get_accurate_duration
import datetime
from error_handler import ErrorHandler
from time_tracker import TimeTracker
import psutil
import traceback


class IPTVChannel:
    """G√®re une cha√Æne IPTV, son streaming et sa surveillance"""
    
    # Initialisation des variables de classe (statiques)
    # _playlist_creation_timestamps = {} # Removed - No longer needed for single file playback

    def __init__(
        self,
        name: str,
        video_dir: str,
        hls_cleaner: HLSCleaner,
        use_gpu: bool = False,
        stats_collector=None,
    ):
        """Initialise une cha√Æne IPTV"""
        self.name = name
        self.video_dir = video_dir
        self.hls_cleaner = hls_cleaner
        self.use_gpu = use_gpu

        # Configuration du logger
        self.logger = FFmpegLogger(name)

        # Stats collector optionnel
        self.stats_collector = stats_collector
        
        # Gestion centralis√©e du temps de visionnage
        self.time_tracker = TimeTracker(stats_collector) if stats_collector else None

        # Gestion des erreurs et des arr√™ts d'urgence
        self.error_handler = ErrorHandler(
            channel_name=self.name,
            max_restarts=5,
            restart_cooldown=60
        )
        
        # Chemin du fichier de log
        self.crash_log_path = Path(f"/app/logs/crashes_{self.name}.log")
        self.crash_log_path.parent.mkdir(exist_ok=True)

        self.lock = threading.Lock()
        self.ready_for_streaming = False
        self.total_duration = 0
        self.processed_videos = [] # List to hold video file Paths
        self.current_video_index = 0 # Index for the current video

        # Initialiser les composants dans le bon ordre
        self.position_manager = PlaybackPositionManager(name)
        self.command_builder = FFmpegCommandBuilder(name, use_gpu=use_gpu)
        self.process_manager = FFmpegProcessManager(
            self.name, self.logger
        )

        # Ajouter cette cha√Æne au registre global
        if hasattr(FFmpegProcessManager, "all_channels"):
            FFmpegProcessManager.all_channels[name] = self

        # Configuration des callbacks
        self.process_manager.on_process_died = self._handle_process_died
        self.process_manager.on_position_update = self._handle_position_update
        self.process_manager.on_segment_created = self._handle_segment_created

        # Autres composants
        self.processor = VideoProcessor(self.video_dir)

        # Variables de surveillance
        self.watchers_count = 0
        self.last_watcher_time = time.time()
        self.last_segment_time = time.time()

        # √âtat du scan initial
        self.initial_scan_complete = False
        self.scan_lock = threading.Lock()

        # Initial scan to populate processed_videos
        logger.info(f"[{self.name}] üîÑ Pr√©paration initiale de la cha√Æne")
        if not self._scan_videos(): # Scan and check if successful
            logger.error(f"[{self.name}] ‚ùå Scan initial √©chou√©, impossible d'initialiser")
            return # Prevent further initialization if scan fails
        
        # No longer need concat file creation here
        # self._create_concat_file()

        # No longer need total duration calculation here, maybe later per-file
        # total_duration = self._calculate_total_duration()
        # self.position_manager.set_total_duration(total_duration)
        # self.process_manager.set_total_duration(total_duration)

        self.initial_scan_complete = True
        self.ready_for_streaming = len(self.processed_videos) > 0

        logger.info(
            f"[{self.name}] ‚úÖ Initialisation compl√®te. Cha√Æne pr√™te: {self.ready_for_streaming} avec {len(self.processed_videos)} vid√©os."
        )

    def _handle_position_update(self, position):
        """Re√ßoit les mises √† jour de position du ProcessManager"""
        try:
            # D√©tecter les sauts de position
            if hasattr(self, "last_logged_position"):
                if abs(position - self.last_logged_position) > 30:
                    logger.info(f"[{self.name}] üìä Saut d√©tect√©: {self.last_logged_position:.2f}s ‚Üí {position:.2f}s")
                    
                    # V√©rifier si on a des erreurs de DTS
                    if position < self.last_logged_position:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è DTS non-monotone d√©tect√©")
                        self.last_dts_error_time = time.time()
                        
                        # Si on a trop d'erreurs DTS, on force un red√©marrage
                        if hasattr(self, "dts_error_count"):
                            self.dts_error_count += 1
                            if self.dts_error_count >= 3:
                                logger.error(f"[{self.name}] ‚ùå Trop d'erreurs DTS, red√©marrage forc√©")
                                self.process_manager.restart_process()
                                self.dts_error_count = 0
                        else:
                            self.dts_error_count = 1
            
            # Mettre √† jour la position
            self.last_logged_position = position
            
            # V√©rifier si on a calcul√© la dur√©e du fichier actuel
            if not hasattr(self, "current_file_duration") and position > 0:
                # Estimer la dur√©e en fonction de la position (approximation)
                duration = get_accurate_duration(self.current_video_file) if hasattr(self, "current_video_file") else 0
                if duration > 0:
                    self.current_file_duration = duration
                    logger.info(f"[{self.name}] ‚ÑπÔ∏è Dur√©e du fichier actuel: {duration:.2f}s")
            
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur dans _handle_position_update: {e}")

    def _scan_videos_async(self):
        """Scanne les vid√©os en t√¢che de fond pour les mises √† jour ult√©rieures"""
        # √âviter les ex√©cutions multiples concurrentes
        if hasattr(self, "_scan_in_progress") and self._scan_in_progress:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Scan d√©j√† en cours, ignor√©")
            return

        # V√©rifier si un scan a √©t√© fait r√©cemment
        current_time = time.time()
        if hasattr(self, "_last_scan_time") and (current_time - self._last_scan_time) < 60:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Dernier scan trop r√©cent, ignor√©")
            return

        self._scan_in_progress = True
        try:
            with self.scan_lock:
                logger.info(f"[{self.name}] üîç Scan de mise √† jour des vid√©os en cours...")
                old_videos = set(self.processed_videos)
                self._scan_videos()

                # Ne continuer que si des changements ont √©t√© d√©tect√©s
                new_videos = set(self.processed_videos)
                if old_videos == new_videos:
                    logger.debug(f"[{self.name}] ‚ÑπÔ∏è Aucun changement d√©tect√© dans les vid√©os")
                    return

                # Mise √† jour de la dur√©e totale - Removed as total duration isn't used for single file playback
                # total_duration = self._calculate_total_duration()
                # self.position_manager.set_total_duration(total_duration) # Removed
                # self.process_manager.set_total_duration(total_duration) # Removed

                # Mise √† jour de la playlist - Removed as concat file isn't used
                # self._create_concat_file()

                logger.info(f"[{self.name}] ‚úÖ Scan de mise √† jour termin√©. Cha√Æne pr√™te: {self.ready_for_streaming}")
                self._last_scan_time = current_time

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur scan de mise √† jour: {e}")
        finally:
            self._scan_in_progress = False

    def _segment_monitor_loop(self):
        """Boucle de surveillance des segments pour v√©rifier la sant√© du stream"""
        try:
            # Ajouter un d√©lai initial pour laisser le temps √† FFmpeg de d√©marrer
            if not hasattr(self, "segment_monitor_started"):
                self.segment_monitor_started = time.time()
                logger.info(f"[{self.name}] üîç Surveillance du stream d√©marr√©e")
                time.sleep(5)
                if not hasattr(self, "_startup_time"):
                    self._startup_time = time.time() - 5
            
            # Initialiser le timestamp du dernier health check
            if not hasattr(self, "last_health_check"):
                self.last_health_check = time.time()
            
            # La boucle s'ex√©cute tant que le processus est en cours
            while self.process_manager.is_running():
                # V√©rification p√©riodique de la sant√© du stream
                if time.time() - self.last_health_check >= 30:
                    self.process_manager.check_stream_health()
                    self.last_health_check = time.time()
                
                # Pause entre les v√©rifications
                time.sleep(1)

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur dans la boucle de surveillance: {e}")

    def _handle_segment_created(self, segment_path, size):
        """G√®re la cr√©ation d'un nouveau segment HLS"""
        if self.logger:
            self.logger.log_segment(segment_path, size)

        # MAJ des stats de segments
        if hasattr(self, "stats_collector") and self.stats_collector:
            # Extraction de l'ID du segment depuis le nom
            segment_id = Path(segment_path).stem.split("_")[-1]
            self.stats_collector.update_segment_stats(self.name, segment_id, size)
        
        # Mise √† jour du timestamp du dernier segment
        self.last_segment_time = time.time()
        logger.debug(f"[{self.name}] ‚è±Ô∏è Segment cr√©√©: {Path(segment_path).name}")

    def _handle_process_died(self, exit_code, stderr=None):
        """G√®re la mort du processus FFmpeg et d√©cide des actions √† prendre"""
        try:
            # Log the exit code and stderr for debugging
            logger.info(f"[{self.name}] ‚ÑπÔ∏è Processus FFmpeg termin√© avec code: {exit_code}")
            if stderr:
                logger.info(f"[{self.name}] ‚ÑπÔ∏è FFmpeg stderr (premi√®res lignes):\n{stderr[:500]}")

            # --- Handle Successful Completion (Advance to Random Next Video) ---
            if exit_code == 0:
                logger.info(f"[{self.name}] ‚úÖ Fichier vid√©o termin√© avec succ√®s.")
                next_video_index = 0 # Default index
                num_videos = 0

                with self.lock:
                    if not self.processed_videos: # Should not happen if started, but check
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide apr√®s fin de lecture.")
                        return # Cannot proceed

                    num_videos = len(self.processed_videos)
                    old_index = self.current_video_index

                    if num_videos > 1:
                        # Pick a new random index, different from the old one
                        next_video_index = random.randrange(num_videos)
                        while next_video_index == old_index:
                            logger.debug(f"[{self.name}] üîÄ Vid√©o suivante identique ({next_video_index}), re-tirage...")
                            next_video_index = random.randrange(num_videos)
                        logger.info(f"[{self.name}] üîÄ S√©lection al√©atoire de la prochaine vid√©o: Index {next_video_index}")
                    elif num_videos == 1:
                        # Only one video, index must be 0
                        next_video_index = 0
                        logger.info(f"[{self.name}] ‚ÑπÔ∏è Une seule vid√©o disponible, lecture en boucle.")
                    else: # Should be caught above, but safety check
                         logger.error(f"[{self.name}] ‚ùå Incoh√©rence: 0 vid√©o mais blocage non d√©clench√© plus t√¥t.")
                         return

                    self.current_video_index = next_video_index

                # Schedule the start of the next video slightly delayed
                # Use the updated index for logging
                logger.info(f"[{self.name}] ‚è±Ô∏è Planification du d√©marrage du prochain fichier ({self.current_video_index + 1}/{num_videos}) dans 1 seconde...")
                threading.Timer(1.0, self.start_stream).start()
                return # Don't proceed to error handling
            # --- End Successful Completion Handling ---
            
            # --- Existing Error Handling (for crashes/non-zero exit codes) ---
            logger.warning(f"[{self.name}] ‚ö†Ô∏è Processus FFmpeg termin√© anormalement (code: {exit_code}).")
            
            # Analyser l'erreur pour d√©tecter le type
            error_type = "unknown_error"
            diagnosis = ""
            
            if exit_code < 0:
                # Signal n√©gatif, indique une terminaison par signal
                error_type = f"signal_{abs(exit_code)}"
                logger.warning(f"[{self.name}] Processus termin√© par signal {abs(exit_code)}")
                
            elif stderr and "error" in stderr.lower():
                # Extraction du type d'erreur √† partir du message
                if "no such file" in stderr.lower():
                    error_type = "missing_file"
                elif "invalid data" in stderr.lower():
                    error_type = "invalid_data"
                elif "dts" in stderr.lower():
                    error_type = "dts_error"
                elif "timeout" in stderr.lower():
                    error_type = "timeout"
                
                # Enregistrer le message d'erreur complet pour plus de contexte
                logger.warning(f"[{self.name}] üìù Message d'erreur FFmpeg: {stderr[:200]}...")
            
            # Traiter les erreurs de diagnostic enrichi (format dictionnaire)
            if stderr and stderr.startswith("{'type':"):
                try:
                    # Tenter de r√©cup√©rer le diagnostic structur√©
                    import ast
                    error_info = ast.literal_eval(stderr)
                    
                    if isinstance(error_info, dict) and 'diagnosis' in error_info:
                        diagnosis = error_info['diagnosis']
                        error_type = "health_check_detailed"
                        
                        # Logs d√©taill√©s du diagnostic
                        elapsed = error_info.get('elapsed', 0)
                        cpu_usage = error_info.get('cpu_usage', 0)
                        segments_count = error_info.get('segments_count', 0)
                        avg_segment_size = error_info.get('average_segment_size', 0)
                        
                        logger.warning(f"[{self.name}] üìä DIAGNOSTIC D√âTAILL√â: {diagnosis}")
                        logger.warning(f"[{self.name}] ‚è±Ô∏è {elapsed:.1f}s sans activit√© | CPU: {cpu_usage:.1f}% | Segments: {segments_count} | Taille moy: {avg_segment_size/1024:.1f}KB")
                except:
                    # Si √©chec du parsing, utiliser le message standard
                    error_type = "health_check_failed"
                    logger.warning(f"[{self.name}] Diagnostic non structur√©: {stderr[:100]}...")
            
            # Approche sp√©cifique pour les probl√®mes de sant√©
            if exit_code == -2:  # Code sp√©cial pour probl√®me de sant√©
                # On incr√©mente progressivement un compteur d'avertissements
                # au lieu de red√©marrer imm√©diatement
                if not hasattr(self, "_health_warnings"):
                    self._health_warnings = 0
                    self._health_check_details = []
                
                # Collecter des d√©tails sur le probl√®me de sant√©
                current_time = time.time()
                elapsed_since_last_segment = current_time - getattr(self.process_manager, "last_segment_time", current_time)
                duration_threshold = getattr(self, "current_file_duration", 0) or 300  # Dur√©e par d√©faut de 5 minutes
                
                health_details = {
                    "timestamp": current_time,
                    "elapsed_since_segment": elapsed_since_last_segment,
                    "file_duration": duration_threshold,
                    "diagnosis": diagnosis or "Probl√®me de sant√© non sp√©cifi√©",
                    "stderr": stderr[:100] if stderr else "Aucune erreur sp√©cifique"
                }
                
                self._health_warnings += 1
                self._health_check_details.append(health_details)
                
                # Log d√©taill√© du probl√®me de sant√©
                logger.warning(f"[{self.name}] ‚ö†Ô∏è Probl√®me de sant√© d√©tect√© - Avertissement {min(self._health_warnings, 3)}/3")
                
                if diagnosis:
                    logger.warning(f"[{self.name}] üîç Cause probable: {diagnosis}")
                else:
                    logger.warning(f"[{self.name}] ‚è±Ô∏è Temps √©coul√© depuis dernier segment: {elapsed_since_last_segment:.1f}s")
                
                # On red√©marre seulement apr√®s plusieurs avertissements
                if self._health_warnings >= 3:
                    logger.warning(f"[{self.name}] ‚ùó Red√©marrage apr√®s {self._health_warnings} avertissements de sant√©")
                    details_log = "\n".join([f"  - {i+1}: {details['elapsed_since_segment']:.1f}s sans segment, diagnostic: {details['diagnosis']}" 
                                            for i, details in enumerate(self._health_check_details)])
                    logger.warning(f"[{self.name}] üìä Historique des probl√®mes de sant√©:\n{details_log}")
                    
                    self._health_warnings = 0
                    self._health_check_details = []
                    self._restart_stream(diagnostic=diagnosis)
                else:
                    logger.info(f"[{self.name}] üîç Avertissement de sant√© {min(self._health_warnings, 3)}/3, surveillance continue")
            else:
                # Utiliser l'error handler seulement si ce n'est pas une fin normale (exit_code != 0)
                if self.error_handler.add_error(error_type):
                    logger.warning(f"[{self.name}] ‚ùó Red√©marrage n√©cessaire apr√®s erreur: {error_type}")
                    # Log des erreurs accumul√©es
                    error_counts = [f"{err_type}: {data['count']}" for err_type, data in self.error_handler.errors.items() if data['count'] > 0]
                    logger.warning(f"[{self.name}] üìä Erreurs accumul√©es: {', '.join(error_counts)}")
                    
                    # On ajoute un petit d√©lai al√©atoire pour √©viter les red√©marrages simultan√©s
                    # IMPORTANT: _restart_stream will call start_stream, which will use the *current* (failed) video index
                    time.sleep(random.uniform(0.5, 3.0))
                    self._restart_stream(diagnostic=error_type)
                elif self.error_handler.has_critical_errors():
                    logger.error(f"[{self.name}] ‚ùå Erreurs critiques d√©tect√©es, arr√™t du stream")
                    # Attendre un peu avant d'arr√™ter pour √©viter les actions trop rapproch√©es
                    time.sleep(2)
                    self.stop_stream_if_needed()
                
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors de la gestion du processus: {e}")
            logger.error(traceback.format_exc())

    def _restart_stream(self, diagnostic=None) -> bool:
        """Red√©marre le stream. Si le red√©marrage est manuel, il relance la m√™me vid√©o. Sinon, il choisit un NOUVEAU fichier VID√âO al√©atoire."""
        try:
            restart_reason = diagnostic or "Raison inconnue"
            is_manual_restart = (diagnostic == "manual_manager_restart")
            
            if is_manual_restart:
                logger.info(f"[{self.name}] üîÑ Tentative de red√©marrage MANUEL du stream.")
            else:
                logger.info(f"[{self.name}] üîÑ Tentative de red√©marrage du stream - Raison: {restart_reason}")

            # Arr√™ter proprement les processus FFmpeg
            if self.process_manager.is_running():
                logger.info(f"[{self.name}] üõë Arr√™t du processus en cours avant red√©marrage...")
                self.process_manager.stop_process(timeout=10)

            # Nettoyer le dossier HLS
            self.hls_cleaner.cleanup_channel(self.name)

            # Attendre un peu avant de red√©marrer
            time.sleep(random.uniform(1.5, 3.0))
            
            # --- Logique de s√©lection de vid√©o ---
            # --- Logique de s√©lection de vid√©o ---
            with self.lock:
                if not self.processed_videos:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide, impossible de red√©marrer.")
                    return False

                if not is_manual_restart:
                    # Comportement en cas de probl√®me: s√©lectionner un nouveau fichier al√©atoire
                    num_videos = len(self.processed_videos)
                    if num_videos > 1:
                        old_index = self.current_video_index
                        next_video_index = random.randrange(num_videos)
                        while next_video_index == old_index:
                            next_video_index = random.randrange(num_videos)
                        self.current_video_index = next_video_index
                        logger.info(f"[{self.name}] üîÄ S√©lection d'un nouveau fichier al√©atoire (cause: erreur): Index {next_video_index}")
                    else:
                        self.current_video_index = 0
                else:
                    # Pour un red√©marrage manuel, on garde le m√™me index
                    logger.info(f"[{self.name}] ‚ÑπÔ∏è Conservation du fichier vid√©o actuel (Index {self.current_video_index}) pour le red√©marrage manuel.")


            # Red√©marrer le stream
            success = self.start_stream()
            if success:
                if is_manual_restart:
                    logger.info(f"[{self.name}] ‚úÖ Stream red√©marr√© manuellement avec succ√®s.")
                else:
                    logger.info(f"[{self.name}] ‚úÖ Stream red√©marr√© avec succ√®s sur un nouveau fichier.")
            else:
                if is_manual_restart:
                    logger.error(f"[{self.name}] ‚ùå √âchec du red√©marrage manuel.")
                else:
                    logger.error(f"[{self.name}] ‚ùå √âchec du red√©marrage sur un nouveau fichier.")
            
            return success
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur majeure lors du red√©marrage: {e}", exc_info=True)
            return False

    def stop_stream_if_needed(self):
        """Arr√™te le stream si n√©cessaire"""
        try:
            # Utiliser le process manager pour arr√™ter proprement les processus FFmpeg
            self.process_manager.stop_process()

            # Nettoyer le dossier HLS avec le HLSCleaner
            self.hls_cleaner.cleanup_channel(self.name)

            logger.info(f"[{self.name}] ‚úÖ Stream arr√™t√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur arr√™t stream: {e}")
            return False

    def start_stream(self) -> bool:
        """D√©marre le stream pour le fichier vid√©o actuel de cette cha√Æne"""
        try:
            with self.lock: # Lock to prevent race conditions with index/list
                # V√©rifier que la cha√Æne est pr√™te et a des vid√©os
                if not self.ready_for_streaming or not self.processed_videos:
                    logger.error(f"[{self.name}] ‚ùå La cha√Æne n'est pas pr√™te ou n'a pas de vid√©os.")
                    return False

                # V√©rifier la validit√© de l'index
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Index vid√©o invalide ({self.current_video_index}), r√©initialisation √† 0.")
                    self.current_video_index = 0
                    if not self.processed_videos: # Double check after reset
                         logger.error(f"[{self.name}] ‚ùå Aucune vid√©o √† lire apr√®s r√©initialisation de l'index.")
                         return False
                
                # Ensure permissions on all content files before starting
                self._ensure_permissions()
                         
                # S√©lectionner le fichier vid√©o actuel
                video_file = self.processed_videos[self.current_video_index]
                logger.info(f"[{self.name}] üé• Processing file ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")
                
                # Check if file still exists and is accessible
                if not video_file.exists() or not os.access(video_file, os.R_OK):
                    logger.error(f"[{self.name}] ‚ùå Fichier vid√©o inaccessible: {video_file}. Tentative de rescan...")
                    self._scan_videos() # Try to refresh the list
                    # Check index validity again after rescan
                    if not (0 <= self.current_video_index < len(self.processed_videos)):
                         self.current_video_index = 0 # Reset if still bad
                    if not self.processed_videos: 
                        logger.error(f"[{self.name}] ‚ùå Aucune vid√©o valide trouv√©e apr√®s rescan.")
                        return False
                    # Try to get the file again
                    video_file = self.processed_videos[self.current_video_index]
                    if not video_file.exists() or not os.access(video_file, os.R_OK):
                        logger.error(f"[{self.name}] ‚ùå Fichier toujours inaccessible apr√®s rescan: {video_file}. Abandon.")
                        return False # Give up if still inaccessible
                    logger.info(f"[{self.name}] üé• Reprise avec fichier ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")


                # Cr√©er le dossier HLS
                hls_dir = Path(f"{HLS_DIR}/{self.name}")
                hls_dir.mkdir(parents=True, exist_ok=True)

                # Nettoyer les anciens segments AVANT de d√©marrer un nouveau fichier
                self.hls_cleaner.cleanup_channel(self.name)

                # Check if it's an MKV file
                has_mkv = ('.mkv' in video_file.name.lower())

                # Construire la commande FFmpeg pour le fichier unique
                command = self.command_builder.build_command(
                    input_file=str(video_file), # Pass the single video file path
                    output_dir=str(hls_dir),
                    progress_file=f"/app/logs/ffmpeg/{self.name}_progress.log",
                    has_mkv=has_mkv, # Pass the MKV check result for this specific file
                    # is_playlist=False # Default or remove parameter
                )

                if not command:
                    logger.error(f"[{self.name}] ‚ùå Impossible de construire la commande FFmpeg pour {video_file.name}")
                    
                    # Tentative avec le prochain fichier de la playlist
                    if len(self.processed_videos) > 1:
                        logger.warning(f"[{self.name}] üîÑ Tentative avec le prochain fichier dans la playlist...")
                        old_index = self.current_video_index
                        
                        # Select a new random index different from the current one
                        next_video_index = random.randrange(len(self.processed_videos))
                        while next_video_index == old_index:
                            next_video_index = random.randrange(len(self.processed_videos))
                            
                        logger.info(f"[{self.name}] üîÄ Passage au fichier suivant: {old_index} ‚Üí {next_video_index}")
                        self.current_video_index = next_video_index
                        
                        # Lancer un nouveau thread pour red√©marrer le stream avec le nouvel index
                        threading.Timer(1.0, self.start_stream).start()
                        return False
                    
                    return False

                logger.debug(f"[{self.name}] ‚öôÔ∏è Commande FFmpeg: {' '.join(command)}")

                # D√©marrer le processus FFmpeg
                success = self.process_manager.start_process(command, str(hls_dir))

                if success:
                    logger.info(f"[{self.name}] ‚úÖ Processus FFmpeg d√©marr√© avec succ√®s pour {video_file.name}")
                    self.error_handler.reset() # Reset errors on successful start
                else:
                    logger.error(f"[{self.name}] ‚ùå √âchec du d√©marrage du processus FFmpeg pour {video_file.name}")
                    
                    # Tentative avec le prochain fichier de la playlist en cas d'√©chec du d√©marrage
                    if len(self.processed_videos) > 1:
                        logger.warning(f"[{self.name}] üîÑ √âchec du d√©marrage, tentative avec le prochain fichier...")
                        old_index = self.current_video_index
                        
                        # Select a new random index different from the current one
                        next_video_index = random.randrange(len(self.processed_videos))
                        while next_video_index == old_index:
                            next_video_index = random.randrange(len(self.processed_videos))
                            
                        logger.info(f"[{self.name}] üîÄ Passage au fichier suivant apr√®s √©chec: {old_index} ‚Üí {next_video_index}")
                        self.current_video_index = next_video_index
                        
                        # Lancer un nouveau thread pour red√©marrer le stream avec le nouvel index
                        threading.Timer(1.0, self.start_stream).start()

                return success # Return success status outside the lock

        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors de la d√©marrage du stream: {e}")
            logger.error(traceback.format_exc())
            return False

    def _scan_videos(self) -> bool:
        """Scanne le dossier ready_to_stream, valide les fichiers, les m√©lange et met √† jour self.processed_videos. Renvoie True si r√©ussi et au moins une vid√©o trouv√©e, False sinon."""
        try:
            with self.lock: # Use lock as we modify shared state
                ready_to_stream_dir = Path(self.video_dir) / "ready_to_stream"
                if not ready_to_stream_dir.exists():
                    logger.error(f"[{self.name}] ‚ùå Dossier ready_to_stream introuvable: {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False

                # Scanner le dossier ready_to_stream (removed sorted())
                video_files = list(ready_to_stream_dir.glob("*.mp4"))

                if not video_files:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Aucun fichier MP4 dans {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False
                    
                logger.info(f"[{self.name}] üîç {len(video_files)} fichiers trouv√©s dans ready_to_stream")

                # V√©rifier que tous les fichiers sont valides
                valid_files = []
                for video in video_files:
                    if video.exists() and os.access(video, os.R_OK):
                        # Optional: Add duration check if needed
                        # try:
                        #     duration = get_accurate_duration(video)
                        #     if duration and duration > 0:
                        #         valid_files.append(video)
                        #     else:
                        #         logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (dur√©e invalide)")
                        # except Exception as e:
                        #     logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (erreur validation: {e})")
                        valid_files.append(video) # Simpler validation for now
                    else:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (non accessible)")

                if not valid_files:
                    logger.error(f"[{self.name}] ‚ùå Aucun fichier MP4 valide trouv√© apr√®s v√©rification")
                    self.processed_videos = []
                    return False

                # *** Shuffle the valid files ***
                random.shuffle(valid_files)
                logger.info(f"[{self.name}] üîÄ Liste de vid√©os m√©lang√©e.")

                logger.info(f"[{self.name}] ‚úÖ {len(valid_files)} vid√©os valides trouv√©es.")
                self.processed_videos = valid_files # Update the list
                # Reset index if it's now out of bounds OR if the list changed significantly
                # (safer to reset to 0 on any successful scan with videos)
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                     logger.info(f"[{self.name}] üîÑ R√©initialisation de l'index vid√©o √† 0 apr√®s scan.")
                     self.current_video_index = 0
                elif len(self.processed_videos) > 0 and self.current_video_index >= len(self.processed_videos):
                    # Handle case where list shrank and index is now invalid
                    logger.info(f"[{self.name}] üîÑ Liste de vid√©os r√©duite, r√©initialisation de l'index vid√©o √† 0.")
                    self.current_video_index = 0


                return True # Success

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur _scan_videos: {e}")
            logger.error(traceback.format_exc())
            self.processed_videos = []
            return False # Failure 

    def is_running(self) -> bool:
        """V√©rifie si la cha√Æne est actuellement en streaming"""
        return self.process_manager.is_running()

    def is_ready_for_streaming(self) -> bool:
        """V√©rifie si la cha√Æne est pr√™te √† √™tre ajout√©e √† la playlist principale."""
        return self.ready_for_streaming and self.initial_scan_complete and len(self.processed_videos) > 0

    def _clean_processes(self):
        """Nettoie tous les processus FFmpeg associ√©s √† cette cha√Æne."""
        try:
            if self.process_manager:
                self.process_manager.stop_process()
            logger.info(f"[{self.name}] Processus FFmpeg nettoy√©s.")
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors du nettoyage des processus: {e}")

    def _ensure_permissions(self):
        """S'assure que tous les fichiers et dossiers de la cha√Æne ont les bonnes permissions."""
        # Cette fonction est conserv√©e pour la structure mais les appels chmod sont d√©sactiv√©s.
        if not hasattr(self, 'video_extensions'):
            self.video_extensions = (".mp4", ".avi", ".mkv", ".mov", ".m4v")
        return True
            
    def refresh_videos(self):
        """
        Rafra√Æchit la liste des vid√©os et red√©marre le stream si n√©cessaire.
        Cette m√©thode est appel√©e quand des fichiers sont ajout√©s/supprim√©s dans ready_to_stream.
        """
        logger.info(f"[{self.name}] üîÑ Rafra√Æchissement des vid√©os suite √† un changement")
        
        # Sauvegarder la liste actuelle pour d√©tecter les changements
        old_videos = set()
        if hasattr(self, "processed_videos") and self.processed_videos:
            old_videos = set(str(v) for v in self.processed_videos)
        
        # Scanner les vid√©os
        with self.lock:  # Verrouiller pour modifier l'√©tat partag√©
            scan_success = self._scan_videos()
            if not scan_success:
                logger.warning(f"[{self.name}] ‚ö†Ô∏è √âchec du scan lors du rafra√Æchissement des vid√©os")
                # Si √©chec du scan et qu'on √©tait en cours de lecture, il faut arr√™ter
                if self.is_running() and not self.processed_videos:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Plus de vid√©os disponibles, arr√™t du stream")
                    self.process_manager.stop_process()
                return False
        
        # V√©rifier si la liste des vid√©os a chang√©
        new_videos = set(str(v) for v in self.processed_videos)
        if old_videos == new_videos:
            logger.info(f"[{self.name}] ‚ÑπÔ∏è Aucun changement d√©tect√© dans la liste des vid√©os")
            return True
            
        # La liste a chang√©, v√©rifier si le stream est en cours
        if self.is_running():
            # Si on lit actuellement un fichier qui a √©t√© supprim√©
            if self.current_video_index < len(self.processed_videos):
                current_file = str(self.processed_videos[self.current_video_index])
                # V√©rifier si le fichier actuel existe toujours
                if current_file not in old_videos or not Path(current_file).exists():
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Le fichier actuel a √©t√© supprim√© ou modifi√©, red√©marrage n√©cessaire")
                    # Red√©marrer le stream avec un nouveau fichier
                    return self._restart_stream(diagnostic="file_deleted")
            else:
                # Index invalide, n√©cessite un red√©marrage
                logger.warning(f"[{self.name}] ‚ö†Ô∏è Index vid√©o ({self.current_video_index}) invalide apr√®s changement de liste")
                return self._restart_stream(diagnostic="index_invalid")
        
        # Le stream n'est pas en cours, ou le fichier actuel existe toujours
        logger.info(f"[{self.name}] ‚úÖ Liste de vid√©os mise √† jour: {len(self.processed_videos)} fichiers")
        return True

