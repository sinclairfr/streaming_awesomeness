# iptv_channel.py
import os
import time
import threading
import random
from pathlib import Path
from typing import Optional, List
import shutil
from video_processor import VideoProcessor
from hls_cleaner import HLSCleaner
from ffmpeg_logger import FFmpegLogger
from ffmpeg_command_builder import FFmpegCommandBuilder
from ffmpeg_process_manager import FFmpegProcessManager
from playback_position_manager import PlaybackPositionManager
import subprocess
from config import (
    logger,
    CRASH_THRESHOLD,
)
from video_processor import verify_file_ready, get_accurate_duration
import datetime
from error_handler import ErrorHandler
from time_tracker import TimeTracker
import psutil
import traceback


class IPTVChannel:
    """G√®re une cha√Æne IPTV, son streaming et sa surveillance"""
    
    # Initialisation des variables de classe (statiques)
    # _playlist_creation_timestamps = {} # Removed - No longer needed for single file playback

    def __init__(
        self,
        name: str,
        video_dir: str,
        hls_cleaner: HLSCleaner,
        use_gpu: bool = False,
        stats_collector=None,
    ):
        """Initialise une cha√Æne IPTV"""
        self.name = name
        self.video_dir = video_dir
        self.hls_cleaner = hls_cleaner
        self.use_gpu = use_gpu

        # Configuration du logger
        self.logger = FFmpegLogger(name)

        # Stats collector optionnel
        self.stats_collector = stats_collector
        
        # Gestion centralis√©e du temps de visionnage
        self.time_tracker = TimeTracker(stats_collector) if stats_collector else None

        # Gestion des erreurs et des arr√™ts d'urgence
        self.error_handler = ErrorHandler(
            channel_name=self.name,
            max_restarts=5,
            restart_cooldown=60
        )
        
        # Chemin du fichier de log
        self.crash_log_path = Path(f"/app/logs/crashes_{self.name}.log")
        self.crash_log_path.parent.mkdir(exist_ok=True)

        self.lock = threading.Lock()
        self.ready_for_streaming = False
        self.total_duration = 0
        self.processed_videos = [] # List to hold video file Paths
        self.current_video_index = 0 # Index for the current video

        # Initialiser les composants dans le bon ordre
        self.position_manager = PlaybackPositionManager(name)
        self.command_builder = FFmpegCommandBuilder(name, use_gpu=use_gpu)
        self.process_manager = FFmpegProcessManager(
            self.name, self.logger
        )

        # Ajouter cette cha√Æne au registre global
        if hasattr(FFmpegProcessManager, "all_channels"):
            FFmpegProcessManager.all_channels[name] = self

        # Configuration des callbacks
        self.process_manager.on_process_died = self._handle_process_died
        self.process_manager.on_position_update = self._handle_position_update
        self.process_manager.on_segment_created = self._handle_segment_created

        # Autres composants
        self.processor = VideoProcessor(self.video_dir)

        # Variables de surveillance
        self.watchers_count = 0
        self.last_watcher_time = time.time()
        self.last_segment_time = time.time()

        # √âtat du scan initial
        self.initial_scan_complete = False
        self.scan_lock = threading.Lock()

        # Initial scan to populate processed_videos
        logger.info(f"[{self.name}] üîÑ Pr√©paration initiale de la cha√Æne")
        if not self._scan_videos(): # Scan and check if successful
            logger.error(f"[{self.name}] ‚ùå Scan initial √©chou√©, impossible d'initialiser")
            return # Prevent further initialization if scan fails
        
        # No longer need concat file creation here
        # self._create_concat_file()

        # No longer need total duration calculation here, maybe later per-file
        # total_duration = self._calculate_total_duration()
        # self.position_manager.set_total_duration(total_duration)
        # self.process_manager.set_total_duration(total_duration)

        self.initial_scan_complete = True
        self.ready_for_streaming = len(self.processed_videos) > 0

        logger.info(
            f"[{self.name}] ‚úÖ Initialisation compl√®te. Cha√Æne pr√™te: {self.ready_for_streaming} avec {len(self.processed_videos)} vid√©os."
        )

    def _handle_position_update(self, position):
        """Re√ßoit les mises √† jour de position du ProcessManager"""
        try:
            # D√©tecter les sauts de position
            if hasattr(self, "last_logged_position"):
                if abs(position - self.last_logged_position) > 30:
                    logger.info(f"[{self.name}] üìä Saut d√©tect√©: {self.last_logged_position:.2f}s ‚Üí {position:.2f}s")
                    
                    # V√©rifier si on a des erreurs de DTS
                    if position < self.last_logged_position:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è DTS non-monotone d√©tect√©")
                        self.last_dts_error_time = time.time()
                        
                        # Si on a trop d'erreurs DTS, on force un red√©marrage
                        if hasattr(self, "dts_error_count"):
                            self.dts_error_count += 1
                            if self.dts_error_count >= 3:
                                logger.error(f"[{self.name}] ‚ùå Trop d'erreurs DTS, red√©marrage forc√©")
                                self.process_manager.restart_process()
                                self.dts_error_count = 0
                        else:
                            self.dts_error_count = 1
            
            # Mettre √† jour la position
            self.last_logged_position = position
            
            # V√©rifier si on a calcul√© la dur√©e du fichier actuel
            if not hasattr(self, "current_file_duration") and position > 0:
                # Estimer la dur√©e en fonction de la position (approximation)
                duration = get_accurate_duration(self.current_video_file) if hasattr(self, "current_video_file") else 0
                if duration > 0:
                    self.current_file_duration = duration
                    logger.info(f"[{self.name}] ‚ÑπÔ∏è Dur√©e du fichier actuel: {duration:.2f}s")
            
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur dans _handle_position_update: {e}")

    def _scan_videos_async(self):
        """Scanne les vid√©os en t√¢che de fond pour les mises √† jour ult√©rieures"""
        # √âviter les ex√©cutions multiples concurrentes
        if hasattr(self, "_scan_in_progress") and self._scan_in_progress:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Scan d√©j√† en cours, ignor√©")
            return

        # V√©rifier si un scan a √©t√© fait r√©cemment
        current_time = time.time()
        if hasattr(self, "_last_scan_time") and (current_time - self._last_scan_time) < 60:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Dernier scan trop r√©cent, ignor√©")
            return

        self._scan_in_progress = True
        try:
            with self.scan_lock:
                logger.info(f"[{self.name}] üîç Scan de mise √† jour des vid√©os en cours...")
                old_videos = set(self.processed_videos)
                self._scan_videos()

                # Ne continuer que si des changements ont √©t√© d√©tect√©s
                new_videos = set(self.processed_videos)
                if old_videos == new_videos:
                    logger.debug(f"[{self.name}] ‚ÑπÔ∏è Aucun changement d√©tect√© dans les vid√©os")
                    return

                # Mise √† jour de la dur√©e totale - Removed as total duration isn't used for single file playback
                # total_duration = self._calculate_total_duration()
                # self.position_manager.set_total_duration(total_duration) # Removed
                # self.process_manager.set_total_duration(total_duration) # Removed

                # Mise √† jour de la playlist - Removed as concat file isn't used
                # self._create_concat_file()

                logger.info(f"[{self.name}] ‚úÖ Scan de mise √† jour termin√©. Cha√Æne pr√™te: {self.ready_for_streaming}")
                self._last_scan_time = current_time

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur scan de mise √† jour: {e}")
        finally:
            self._scan_in_progress = False

    def _segment_monitor_loop(self):
        """Boucle de surveillance des segments pour v√©rifier la sant√© du stream"""
        try:
            # Ajouter un d√©lai initial pour laisser le temps √† FFmpeg de d√©marrer
            if not hasattr(self, "segment_monitor_started"):
                self.segment_monitor_started = time.time()
                logger.info(f"[{self.name}] üîç Surveillance du stream d√©marr√©e")
                time.sleep(5)
                if not hasattr(self, "_startup_time"):
                    self._startup_time = time.time() - 5
            
            # Initialiser le timestamp du dernier health check
            if not hasattr(self, "last_health_check"):
                self.last_health_check = time.time()
            
            # La boucle s'ex√©cute tant que le processus est en cours
            while self.process_manager.is_running():
                # V√©rification p√©riodique de la sant√© du stream
                if time.time() - self.last_health_check >= 30:
                    self.process_manager.check_stream_health()
                    self.last_health_check = time.time()
                
                # Pause entre les v√©rifications
                time.sleep(1)

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur dans la boucle de surveillance: {e}")

    def _handle_segment_created(self, segment_path, size):
        """G√®re la cr√©ation d'un nouveau segment HLS"""
        if self.logger:
            self.logger.log_segment(segment_path, size)

        # MAJ des stats de segments
        if hasattr(self, "stats_collector") and self.stats_collector:
            # Extraction de l'ID du segment depuis le nom
            segment_id = Path(segment_path).stem.split("_")[-1]
            self.stats_collector.update_segment_stats(self.name, segment_id, size)
        
        # Mise √† jour du timestamp du dernier segment
        self.last_segment_time = time.time()
        logger.debug(f"[{self.name}] ‚è±Ô∏è Segment cr√©√©: {Path(segment_path).name}")

    def _handle_process_died(self, exit_code, stderr=None):
        """G√®re la mort du processus FFmpeg et d√©cide des actions √† prendre"""
        try:
            # Log the exit code and stderr for debugging
            logger.info(f"[{self.name}] ‚ÑπÔ∏è Processus FFmpeg termin√© avec code: {exit_code}")
            if stderr:
                logger.info(f"[{self.name}] ‚ÑπÔ∏è FFmpeg stderr (premi√®res lignes):\n{stderr[:500]}")

            # --- Handle Successful Completion (Advance to Random Next Video) ---
            if exit_code == 0:
                logger.info(f"[{self.name}] ‚úÖ Fichier vid√©o termin√© avec succ√®s.")
                next_video_index = 0 # Default index
                num_videos = 0

                with self.lock:
                    if not self.processed_videos: # Should not happen if started, but check
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide apr√®s fin de lecture.")
                        return # Cannot proceed

                    num_videos = len(self.processed_videos)
                    old_index = self.current_video_index

                    if num_videos > 1:
                        # Pick a new random index, different from the old one
                        next_video_index = random.randrange(num_videos)
                        while next_video_index == old_index:
                            logger.debug(f"[{self.name}] üîÄ Vid√©o suivante identique ({next_video_index}), re-tirage...")
                            next_video_index = random.randrange(num_videos)
                        logger.info(f"[{self.name}] üîÄ S√©lection al√©atoire de la prochaine vid√©o: Index {next_video_index}")
                    elif num_videos == 1:
                        # Only one video, index must be 0
                        next_video_index = 0
                        logger.info(f"[{self.name}] ‚ÑπÔ∏è Une seule vid√©o disponible, lecture en boucle.")
                    else: # Should be caught above, but safety check
                         logger.error(f"[{self.name}] ‚ùå Incoh√©rence: 0 vid√©o mais blocage non d√©clench√© plus t√¥t.")
                         return

                    self.current_video_index = next_video_index

                # Schedule the start of the next video slightly delayed
                # Use the updated index for logging
                logger.info(f"[{self.name}] ‚è±Ô∏è Planification du d√©marrage du prochain fichier ({self.current_video_index + 1}/{num_videos}) dans 1 seconde...")
                threading.Timer(1.0, self.start_stream).start()
                return # Don't proceed to error handling
            # --- End Successful Completion Handling ---
            
            # --- Existing Error Handling (for crashes/non-zero exit codes) ---
            logger.warning(f"[{self.name}] ‚ö†Ô∏è Processus FFmpeg termin√© anormalement (code: {exit_code}).")
            
            # Analyser l'erreur pour d√©tecter le type
            error_type = "unknown_error"
            diagnosis = ""
            
            if exit_code < 0:
                # Signal n√©gatif, indique une terminaison par signal
                error_type = f"signal_{abs(exit_code)}"
                logger.warning(f"[{self.name}] Processus termin√© par signal {abs(exit_code)}")
                
            elif stderr and "error" in stderr.lower():
                # Extraction du type d'erreur √† partir du message
                if "no such file" in stderr.lower():
                    error_type = "missing_file"
                elif "invalid data" in stderr.lower():
                    error_type = "invalid_data"
                elif "dts" in stderr.lower():
                    error_type = "dts_error"
                elif "timeout" in stderr.lower():
                    error_type = "timeout"
                
                # Enregistrer le message d'erreur complet pour plus de contexte
                logger.warning(f"[{self.name}] üìù Message d'erreur FFmpeg: {stderr[:200]}...")
            
            # Traiter les erreurs de diagnostic enrichi (format dictionnaire)
            if stderr and stderr.startswith("{'type':"):
                try:
                    # Tenter de r√©cup√©rer le diagnostic structur√©
                    import ast
                    error_info = ast.literal_eval(stderr)
                    
                    if isinstance(error_info, dict) and 'diagnosis' in error_info:
                        diagnosis = error_info['diagnosis']
                        error_type = "health_check_detailed"
                        
                        # Logs d√©taill√©s du diagnostic
                        elapsed = error_info.get('elapsed', 0)
                        cpu_usage = error_info.get('cpu_usage', 0)
                        segments_count = error_info.get('segments_count', 0)
                        avg_segment_size = error_info.get('average_segment_size', 0)
                        
                        logger.warning(f"[{self.name}] üìä DIAGNOSTIC D√âTAILL√â: {diagnosis}")
                        logger.warning(f"[{self.name}] ‚è±Ô∏è {elapsed:.1f}s sans activit√© | CPU: {cpu_usage:.1f}% | Segments: {segments_count} | Taille moy: {avg_segment_size/1024:.1f}KB")
                except:
                    # Si √©chec du parsing, utiliser le message standard
                    error_type = "health_check_failed"
                    logger.warning(f"[{self.name}] Diagnostic non structur√©: {stderr[:100]}...")
            
            # Approche sp√©cifique pour les probl√®mes de sant√©
            if exit_code == -2:  # Code sp√©cial pour probl√®me de sant√©
                # On incr√©mente progressivement un compteur d'avertissements
                # au lieu de red√©marrer imm√©diatement
                if not hasattr(self, "_health_warnings"):
                    self._health_warnings = 0
                    self._health_check_details = []
                
                # Collecter des d√©tails sur le probl√®me de sant√©
                current_time = time.time()
                elapsed_since_last_segment = current_time - getattr(self.process_manager, "last_segment_time", current_time)
                duration_threshold = getattr(self, "current_file_duration", 0) or 300  # Dur√©e par d√©faut de 5 minutes
                
                health_details = {
                    "timestamp": current_time,
                    "elapsed_since_segment": elapsed_since_last_segment,
                    "file_duration": duration_threshold,
                    "diagnosis": diagnosis or "Probl√®me de sant√© non sp√©cifi√©",
                    "stderr": stderr[:100] if stderr else "Aucune erreur sp√©cifique"
                }
                
                self._health_warnings += 1
                self._health_check_details.append(health_details)
                
                # Log d√©taill√© du probl√®me de sant√©
                logger.warning(f"[{self.name}] ‚ö†Ô∏è Probl√®me de sant√© d√©tect√© - Avertissement {min(self._health_warnings, 3)}/3")
                
                if diagnosis:
                    logger.warning(f"[{self.name}] üîç Cause probable: {diagnosis}")
                else:
                    logger.warning(f"[{self.name}] ‚è±Ô∏è Temps √©coul√© depuis dernier segment: {elapsed_since_last_segment:.1f}s")
                
                # On red√©marre seulement apr√®s plusieurs avertissements
                if self._health_warnings >= 3:
                    logger.warning(f"[{self.name}] ‚ùó Red√©marrage apr√®s {self._health_warnings} avertissements de sant√©")
                    details_log = "\n".join([f"  - {i+1}: {details['elapsed_since_segment']:.1f}s sans segment, diagnostic: {details['diagnosis']}" 
                                            for i, details in enumerate(self._health_check_details)])
                    logger.warning(f"[{self.name}] üìä Historique des probl√®mes de sant√©:\n{details_log}")
                    
                    self._health_warnings = 0
                    self._health_check_details = []
                    self._restart_stream(diagnostic=diagnosis)
                else:
                    logger.info(f"[{self.name}] üîç Avertissement de sant√© {min(self._health_warnings, 3)}/3, surveillance continue")
            else:
                # Utiliser l'error handler seulement si ce n'est pas une fin normale (exit_code != 0)
                if self.error_handler.add_error(error_type):
                    logger.warning(f"[{self.name}] ‚ùó Red√©marrage n√©cessaire apr√®s erreur: {error_type}")
                    # Log des erreurs accumul√©es
                    error_counts = [f"{err_type}: {data['count']}" for err_type, data in self.error_handler.errors.items() if data['count'] > 0]
                    logger.warning(f"[{self.name}] üìä Erreurs accumul√©es: {', '.join(error_counts)}")
                    
                    # On ajoute un petit d√©lai al√©atoire pour √©viter les red√©marrages simultan√©s
                    # IMPORTANT: _restart_stream will call start_stream, which will use the *current* (failed) video index
                    time.sleep(random.uniform(0.5, 3.0))
                    self._restart_stream(diagnostic=error_type)
                elif self.error_handler.has_critical_errors():
                    logger.error(f"[{self.name}] ‚ùå Erreurs critiques d√©tect√©es, arr√™t du stream")
                    # Attendre un peu avant d'arr√™ter pour √©viter les actions trop rapproch√©es
                    time.sleep(2)
                    self.stop_stream_if_needed()
                
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors de la gestion du processus: {e}")
            logger.error(traceback.format_exc())

    def _restart_stream(self, diagnostic=None) -> bool:
        """Red√©marre le stream en choisissant un NOUVEAU fichier VID√âO al√©atoire en cas de probl√®me"""
        try:
            restart_reason = diagnostic or "Raison inconnue"
            logger.info(f"[{self.name}] üîÑ Tentative de red√©marrage du stream - Raison: {restart_reason}")

            # V√©rifier l'utilisation CPU du syst√®me
            try:
                cpu_system = psutil.cpu_percent(interval=0.5)
                mem_percent = psutil.virtual_memory().percent
                logger.info(f"[{self.name}] üñ•Ô∏è Ressources syst√®me: CPU {cpu_system}%, M√©moire {mem_percent}%")
                
                # Avertir si ressources critiques
                if cpu_system > 85:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Attention: CPU syst√®me √©lev√© ({cpu_system}%) pendant le red√©marrage")
                    time.sleep(5)  # Attendre un peu pour laisser le syst√®me se calmer
            except Exception as e:
                logger.debug(f"[{self.name}] Impossible de v√©rifier les ressources syst√®me: {e}")

            # Arr√™ter proprement les processus FFmpeg
            logger.info(f"[{self.name}] üõë Arr√™t du processus FFmpeg en cours...")
            self.process_manager.stop_process()

            # Nettoyer le dossier HLS
            logger.info(f"[{self.name}] üßπ Nettoyage des segments HLS...")
            hls_dir = Path(f"/app/hls/{self.name}")
            segments_before = len(list(hls_dir.glob("*.ts"))) if hls_dir.exists() else 0
            self.hls_cleaner.cleanup_channel(self.name)
            segments_after = len(list(hls_dir.glob("*.ts"))) if hls_dir.exists() else 0
            logger.info(f"[{self.name}] üßπ Nettoyage des segments: {segments_before} ‚Üí {segments_after}")

            # Attendre un peu avant de red√©marrer
            time.sleep(2)
            
            # *** SELECT RANDOM NEXT VIDEO ON ERROR RESTART ***
            with self.lock:
                if not self.processed_videos:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide, impossible de choisir un fichier pour le red√©marrage.")
                    return False # Can't restart if no videos

                num_videos = len(self.processed_videos)
                old_index = self.current_video_index # Index of the video that failed
                next_video_index = 0

                logger.info(f"[{self.name}] ‚è≠Ô∏è S√©lection d'un nouveau fichier al√©atoire apr√®s erreur sur l'index {old_index}")

                if num_videos > 1:
                    # Pick a new random index, different from the one that failed
                    next_video_index = random.randrange(num_videos)
                    while next_video_index == old_index:
                        logger.debug(f"[{self.name}] üîÄ Vid√©o suivante al√©atoire identique √† celle √©chou√©e ({next_video_index}), re-tirage...")
                        next_video_index = random.randrange(num_videos)
                    logger.info(f"[{self.name}] üîÄ S√©lection al√©atoire pour le red√©marrage: Index {next_video_index}")
                elif num_videos == 1:
                     next_video_index = 0
                     logger.info(f"[{self.name}] ‚ÑπÔ∏è Une seule vid√©o disponible, tentative de relance sur celle-ci.")
                else: # Should be caught above
                    logger.error(f"[{self.name}] ‚ùå Incoh√©rence lors de la s√©lection al√©atoire pour red√©marrage.")
                    return False

                self.current_video_index = next_video_index


            # Red√©marrer le stream (start_stream will now use the new random index)
            success = self.start_stream()
            if success:
                # Reset error handler counts maybe? Or only for the specific error type?
                # self.error_handler.reset() # Consider implications
                # Use the updated index for logging
                logger.info(f"[{self.name}] ‚úÖ Stream red√©marr√© avec succ√®s sur un nouveau fichier ({self.current_video_index+1}/{len(self.processed_videos)}) - Ancien probl√®me: {diagnostic}")
            else:
                logger.error(f"[{self.name}] ‚ùå √âchec du red√©marrage sur un nouveau fichier apr√®s probl√®me: {diagnostic}")
                # Maybe try another random video? Or stop? For now, just return False.
                return False

            return success
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur lors du red√©marrage: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def stop_stream_if_needed(self):
        """Arr√™te le stream si n√©cessaire"""
        try:
            # Utiliser le process manager pour arr√™ter proprement les processus FFmpeg
            self.process_manager.stop_process()

            # Nettoyer le dossier HLS avec le HLSCleaner
            self.hls_cleaner.cleanup_channel(self.name)

            logger.info(f"[{self.name}] ‚úÖ Stream arr√™t√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur arr√™t stream: {e}")
            return False

    def start_stream(self) -> bool:
        """D√©marre le stream pour le fichier vid√©o actuel de cette cha√Æne"""
        try:
            with self.lock: # Lock to prevent race conditions with index/list
                # V√©rifier que la cha√Æne est pr√™te et a des vid√©os
                if not self.ready_for_streaming or not self.processed_videos:
                    logger.error(f"[{self.name}] ‚ùå La cha√Æne n'est pas pr√™te ou n'a pas de vid√©os.")
                    return False

                # V√©rifier la validit√© de l'index
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Index vid√©o invalide ({self.current_video_index}), r√©initialisation √† 0.")
                    self.current_video_index = 0
                    if not self.processed_videos: # Double check after reset
                         logger.error(f"[{self.name}] ‚ùå Aucune vid√©o √† lire apr√®s r√©initialisation de l'index.")
                         return False
                         
                # S√©lectionner le fichier vid√©o actuel
                video_file = self.processed_videos[self.current_video_index]
                logger.info(f"[{self.name}] üé• Processing file ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")
                
                # Check if file still exists and is accessible
                if not video_file.exists() or not os.access(video_file, os.R_OK):
                    logger.error(f"[{self.name}] ‚ùå Fichier vid√©o inaccessible: {video_file}. Tentative de rescan...")
                    self._scan_videos() # Try to refresh the list
                    # Check index validity again after rescan
                    if not (0 <= self.current_video_index < len(self.processed_videos)):
                         self.current_video_index = 0 # Reset if still bad
                    if not self.processed_videos: 
                        logger.error(f"[{self.name}] ‚ùå Aucune vid√©o valide trouv√©e apr√®s rescan.")
                        return False
                    # Try to get the file again
                    video_file = self.processed_videos[self.current_video_index]
                    if not video_file.exists() or not os.access(video_file, os.R_OK):
                        logger.error(f"[{self.name}] ‚ùå Fichier toujours inaccessible apr√®s rescan: {video_file}. Abandon.")
                        return False # Give up if still inaccessible
                    logger.info(f"[{self.name}] üé• Reprise avec fichier ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")


                # Cr√©er le dossier HLS
                hls_dir = Path(f"/app/hls/{self.name}")
                hls_dir.mkdir(parents=True, exist_ok=True)

                # Nettoyer les anciens segments AVANT de d√©marrer un nouveau fichier
                self.hls_cleaner.cleanup_channel(self.name)

                # *** Select the single video file for this run ***
                video_file = self.processed_videos[self.current_video_index]
                logger.info(f"[{self.name}] üé• Processing file ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")
                
                # Check if it's an MKV file
                has_mkv = ('.mkv' in video_file.name.lower())

                # Construire la commande FFmpeg pour le fichier unique
                command = self.command_builder.build_command(
                    input_file=str(video_file), # Pass the single video file path
                    output_dir=str(hls_dir),
                    progress_file=f"/app/logs/ffmpeg/{self.name}_progress.log",
                    has_mkv=has_mkv, # Pass the MKV check result for this specific file
                    # is_playlist=False # Default or remove parameter
                )

                if not command:
                    logger.error(f"[{self.name}] ‚ùå Impossible de construire la commande FFmpeg pour {video_file.name}")
                    return False

                logger.debug(f"[{self.name}] ‚öôÔ∏è Commande FFmpeg: {' '.join(command)}")

                # D√©marrer le processus FFmpeg
                success = self.process_manager.start_process(command, str(hls_dir))

                if success:
                    logger.info(f"[{self.name}] ‚úÖ Processus FFmpeg d√©marr√© avec succ√®s pour {video_file.name}")
                    self.error_handler.reset() # Reset errors on successful start
                else:
                    logger.error(f"[{self.name}] ‚ùå √âchec du d√©marrage du processus FFmpeg pour {video_file.name}")

            return success # Return success status outside the lock

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur start_stream: {e}")
            logger.error(traceback.format_exc())
            return False

    def _scan_videos(self) -> bool:
        """Scanne le dossier ready_to_stream, valide les fichiers, les m√©lange et met √† jour self.processed_videos. Renvoie True si r√©ussi et au moins une vid√©o trouv√©e, False sinon."""
        try:
            with self.lock: # Use lock as we modify shared state
                ready_to_stream_dir = Path(self.video_dir) / "ready_to_stream"
                if not ready_to_stream_dir.exists():
                    logger.error(f"[{self.name}] ‚ùå Dossier ready_to_stream introuvable: {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False

                # Scanner le dossier ready_to_stream (removed sorted())
                video_files = list(ready_to_stream_dir.glob("*.mp4"))

                if not video_files:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Aucun fichier MP4 dans {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False
                    
                logger.info(f"[{self.name}] üîç {len(video_files)} fichiers trouv√©s dans ready_to_stream")

                # V√©rifier que tous les fichiers sont valides
                valid_files = []
                for video in video_files:
                    if video.exists() and os.access(video, os.R_OK):
                        # Optional: Add duration check if needed
                        # try:
                        #     duration = get_accurate_duration(video)
                        #     if duration and duration > 0:
                        #         valid_files.append(video)
                        #     else:
                        #         logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (dur√©e invalide)")
                        # except Exception as e:
                        #     logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (erreur validation: {e})")
                        valid_files.append(video) # Simpler validation for now
                    else:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (non accessible)")

                if not valid_files:
                    logger.error(f"[{self.name}] ‚ùå Aucun fichier MP4 valide trouv√© apr√®s v√©rification")
                    self.processed_videos = []
                    return False

                # *** Shuffle the valid files ***
                random.shuffle(valid_files)
                logger.info(f"[{self.name}] üîÄ Liste de vid√©os m√©lang√©e.")

                logger.info(f"[{self.name}] ‚úÖ {len(valid_files)} vid√©os valides trouv√©es.")
                self.processed_videos = valid_files # Update the list
                # Reset index if it's now out of bounds OR if the list changed significantly
                # (safer to reset to 0 on any successful scan with videos)
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                     logger.info(f"[{self.name}] üîÑ R√©initialisation de l'index vid√©o √† 0 apr√®s scan.")
                     self.current_video_index = 0
                elif len(self.processed_videos) > 0 and self.current_video_index >= len(self.processed_videos):
                    # Handle case where list shrank and index is now invalid
                    logger.info(f"[{self.name}] üîÑ Liste de vid√©os r√©duite, r√©initialisation de l'index vid√©o √† 0.")
                    self.current_video_index = 0


                return True # Success

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur _scan_videos: {e}")
            logger.error(traceback.format_exc())
            self.processed_videos = []
            return False # Failure

    def is_running(self) -> bool:
        """V√©rifie si la cha√Æne est actuellement en streaming"""
        return self.process_manager.is_running()

    def check_stream_health(self):
        """
        V√©rifie la sant√© du stream avec une approche plus tol√©rante
        Logge les probl√®mes mais ne force pas le red√©marrage imm√©diatement
        """
        try:
            # Initialiser le compteur d'avertissements si n√©cessaire
            if not hasattr(self, "_health_check_warnings"):
                self._health_check_warnings = 0
                self._last_health_check_time = time.time()
            
            # R√©initialiser p√©riodiquement les avertissements (toutes les 30 minutes)
            if time.time() - getattr(self, "_last_health_check_time", 0) > 1800:
                self._health_check_warnings = 0
                self._last_health_check_time = time.time()
                logger.info(f"[{self.name}] R√©initialisation p√©riodique des avertissements de sant√©")
            
            # V√©rifier l'√©tat de base: processus en cours?
            if not self.process_manager.is_running():
                logger.warning(f"[{self.name}] ‚ö†Ô∏è Processus FFmpeg inactif")
                self._health_check_warnings += 1
                
                # Seuil de tol√©rance plus √©lev√©
                if self._health_check_warnings >= 3 and getattr(self, "watchers_count", 0) > 0:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è {self._health_check_warnings} avertissements accumul√©s, tentative de red√©marrage")
                    self._health_check_warnings = 0
                    return self._restart_stream()
                else:
                    logger.info(f"[{self.name}] Avertissement {self._health_check_warnings}/3 (attente avant action)")
                    return False
            
            # Processus en cours, sant√© OK
            if self._health_check_warnings > 0:
                self._health_check_warnings -= 1  # R√©duction progressive des avertissements
                logger.info(f"[{self.name}] ‚úÖ Sant√© am√©lior√©e, avertissements: {self._health_check_warnings}")
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors du check de sant√© du stream: {e}")
            return False
            
    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    # def check_watchers_timeout(self):
    #    ...


    # M√©thode supprim√©e car la logique de timeout des watchers est maintenant g√©r√©e par IPTVManager
    # en se basant sur les informations du ChannelStatusManager (aliment√© par ClientMonitor).
    def check_watchers_timeout(self):
        """V√©rifie si le stream doit √™tre arr√™t√© en raison d'une absence de watchers"""
        # On ne v√©rifie pas le timeout s'il n'y a pas de watchers_count
        if not hasattr(self, "watchers_count"):
            return False
            
        # On ne v√©rifie pas le timeout s'il n'est pas actif
        if not self.process_manager.is_running():
            return False
            
        # On ne v√©rifie pas le timeout s'il y a des watchers actifs
        if self.watchers_count > 0:
            return False
            
        # On ne v√©rifie pas le timeout s'il y a des erreurs critiques
        if self.error_handler.has_critical_errors():
            return False
            
        # Le stream continue de tourner m√™me sans watchers
        return False 