# iptv_channel.py
import os
import time
import threading
import random
from pathlib import Path
from typing import Optional, List
import shutil
from video_processor import VideoProcessor
from hls_cleaner import HLSCleaner
from ffmpeg_logger import FFmpegLogger
from ffmpeg_command_builder import FFmpegCommandBuilder
from ffmpeg_process_manager import FFmpegProcessManager
from playback_position_manager import PlaybackPositionManager
import subprocess
from config import (
    logger,
    CRASH_THRESHOLD,
    HLS_DIR,
)
from video_processor import get_accurate_duration
import datetime
from error_handler import ErrorHandler
import psutil
import traceback


class IPTVChannel:
    """G√®re une cha√Æne IPTV, son streaming et sa surveillance"""
    
    # Initialisation des variables de classe (statiques)
    # _playlist_creation_timestamps = {} # Removed - No longer needed for single file playback

    def __init__(
        self,
        name: str,
        video_dir: str,
        hls_cleaner: HLSCleaner,
        use_gpu: bool = False,
        stats_collector=None,
    ):
        """Initialise une cha√Æne IPTV"""
        self.name = name
        self.video_dir = video_dir
        self.hls_cleaner = hls_cleaner
        self.use_gpu = use_gpu

        # Configuration du logger
        self.logger = FFmpegLogger(name)

        # Stats collector optionnel
        self.stats_collector = stats_collector

        # Gestion des erreurs et des arr√™ts d'urgence
        self.error_handler = ErrorHandler(
            channel_name=self.name,
            max_restarts=5,
            restart_cooldown=60
        )
        
        # Chemin du fichier de log
        self.crash_log_path = Path(f"/app/logs/crashes_{self.name}.log")
        self.crash_log_path.parent.mkdir(exist_ok=True)

        self.lock = threading.Lock()
        self.ready_for_streaming = False
        self.total_duration = 0
        self.processed_videos = [] # List to hold video file Paths
        self.current_video_index = 0 # Index for the current video

        # Initialiser les composants dans le bon ordre
        self.position_manager = PlaybackPositionManager(name)
        self.command_builder = FFmpegCommandBuilder(name, use_gpu=use_gpu)
        self.process_manager = FFmpegProcessManager(
            self.name, self.logger
        )

        # Ajouter cette cha√Æne au registre global
        if hasattr(FFmpegProcessManager, "all_channels"):
            FFmpegProcessManager.all_channels[name] = self

        # Configuration des callbacks
        self.process_manager.on_process_died = self._handle_process_died
        self.process_manager.on_position_update = self._handle_position_update
        self.process_manager.on_segment_created = self._handle_segment_created

        # Autres composants
        self.processor = VideoProcessor(self.video_dir)

        # Variables de surveillance
        self.watchers_count = 0
        self.last_watcher_time = time.time()
        self.last_segment_time = time.time()

        # Flag pour la navigation manuelle (√©viter l'auto-avancement pendant previous/next)
        self.manual_navigation = False

        # √âtat du scan initial
        self.initial_scan_complete = False
        self.scan_lock = threading.Lock()

        # Initial scan to populate processed_videos
        logger.info(f"[{self.name}] üîÑ Pr√©paration initiale de la cha√Æne")
        if not self._scan_videos(): # Scan and check if successful
            logger.error(f"[{self.name}] ‚ùå Scan initial √©chou√©, impossible d'initialiser")
            return # Prevent further initialization if scan fails
        
        # No longer need concat file creation here
        # self._create_concat_file()

        # No longer need total duration calculation here, maybe later per-file
        # total_duration = self._calculate_total_duration()
        # self.position_manager.set_total_duration(total_duration)
        # self.process_manager.set_total_duration(total_duration)

        self.initial_scan_complete = True
        self.ready_for_streaming = len(self.processed_videos) > 0

        logger.info(
            f"[{self.name}] ‚úÖ Initialisation compl√®te. Cha√Æne pr√™te: {self.ready_for_streaming} avec {len(self.processed_videos)} vid√©os."
        )

    def _safe_start_stream(self):
        """Wrapper s√©curis√© pour start_stream() appel√© depuis un Timer thread"""
        try:
            logger.debug(f"[{self.name}] üîÑ D√©marrage du stream depuis Timer thread...")
            result = self.start_stream()
            if not result:
                logger.error(f"[{self.name}] ‚ùå √âchec du d√©marrage du stream depuis Timer thread")
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Exception critique dans Timer thread: {e}")
            logger.error(traceback.format_exc())
            # Tenter un red√©marrage d'urgence apr√®s un d√©lai
            logger.warning(f"[{self.name}] üîÑ Tentative de r√©cup√©ration automatique dans 10 secondes...")
            threading.Timer(10.0, self._safe_start_stream).start()

    def _handle_position_update(self, position):
        """Re√ßoit les mises √† jour de position du ProcessManager"""
        try:
            # D√©tecter les sauts de position
            if hasattr(self, "last_logged_position"):
                if abs(position - self.last_logged_position) > 30:
                    logger.info(f"[{self.name}] üìä Saut d√©tect√©: {self.last_logged_position:.2f}s ‚Üí {position:.2f}s")
                    
                    # V√©rifier si on a des erreurs de DTS
                    if position < self.last_logged_position:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è DTS non-monotone d√©tect√©")
                        self.last_dts_error_time = time.time()
                        
                        # Si on a trop d'erreurs DTS, on force un red√©marrage
                        if hasattr(self, "dts_error_count"):
                            self.dts_error_count += 1
                            if self.dts_error_count >= 3:
                                logger.error(f"[{self.name}] ‚ùå Trop d'erreurs DTS, red√©marrage forc√©")
                                self.process_manager.restart_process()
                                self.dts_error_count = 0
                        else:
                            self.dts_error_count = 1
            
            # Mettre √† jour la position
            self.last_logged_position = position
            
            # V√©rifier si on a calcul√© la dur√©e du fichier actuel
            if not hasattr(self, "current_file_duration") and position > 0:
                # Estimer la dur√©e en fonction de la position (approximation)
                duration = get_accurate_duration(self.current_video_file) if hasattr(self, "current_video_file") else 0
                if duration > 0:
                    self.current_file_duration = duration
                    logger.info(f"[{self.name}] ‚ÑπÔ∏è Dur√©e du fichier actuel: {duration:.2f}s")
            
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur dans _handle_position_update: {e}")

    def _scan_videos_async(self):
        """Scanne les vid√©os en t√¢che de fond pour les mises √† jour ult√©rieures"""
        # √âviter les ex√©cutions multiples concurrentes
        if hasattr(self, "_scan_in_progress") and self._scan_in_progress:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Scan d√©j√† en cours, ignor√©")
            return

        # V√©rifier si un scan a √©t√© fait r√©cemment
        current_time = time.time()
        if hasattr(self, "_last_scan_time") and (current_time - self._last_scan_time) < 60:
            logger.debug(f"[{self.name}] ‚è≠Ô∏è Dernier scan trop r√©cent, ignor√©")
            return

        self._scan_in_progress = True
        try:
            with self.scan_lock:
                logger.info(f"[{self.name}] üîç Scan de mise √† jour des vid√©os en cours...")
                old_videos = set(self.processed_videos)
                self._scan_videos()

                # Ne continuer que si des changements ont √©t√© d√©tect√©s
                new_videos = set(self.processed_videos)
                if old_videos == new_videos:
                    logger.debug(f"[{self.name}] ‚ÑπÔ∏è Aucun changement d√©tect√© dans les vid√©os")
                    return

                # Mise √† jour de la dur√©e totale - Removed as total duration isn't used for single file playback
                # total_duration = self._calculate_total_duration()
                # self.position_manager.set_total_duration(total_duration) # Removed
                # self.process_manager.set_total_duration(total_duration) # Removed

                # Mise √† jour de la playlist - Removed as concat file isn't used
                # self._create_concat_file()

                logger.info(f"[{self.name}] ‚úÖ Scan de mise √† jour termin√©. Cha√Æne pr√™te: {self.ready_for_streaming}")
                self._last_scan_time = current_time

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur scan de mise √† jour: {e}")
        finally:
            self._scan_in_progress = False

    # M√âTHODE SUPPRIM√âE: _segment_monitor_loop()
    # Cette boucle est REDONDANTE avec FFmpegProcessManager._monitor_process()
    # qui appelle d√©j√† check_stream_health() toutes les 60 secondes.
    # Avoir deux boucles qui appellent la m√™me v√©rification est inefficace et peut
    # causer des race conditions.

    def _handle_segment_created(self, segment_path, size):
        """G√®re la cr√©ation d'un nouveau segment HLS"""
        if self.logger:
            self.logger.log_segment(segment_path, size)

        # MAJ des stats de segments
        if hasattr(self, "stats_collector") and self.stats_collector:
            # Extraction de l'ID du segment depuis le nom
            segment_id = Path(segment_path).stem.split("_")[-1]
            self.stats_collector.update_segment_stats(self.name, segment_id, size)
        
        # Mise √† jour du timestamp du dernier segment
        self.last_segment_time = time.time()
        logger.debug(f"[{self.name}] ‚è±Ô∏è Segment cr√©√©: {Path(segment_path).name}")

    def _handle_process_died(self, exit_code, stderr=None):
        """
        G√®re la mort du processus FFmpeg et d√©cide des actions √† prendre.

        Cette m√©thode a √©t√© simplifi√©e en d√©l√©guant l'analyse d'erreurs √† ErrorHandler.
        """
        try:
            # Log initial
            logger.info(f"[{self.name}] ‚ÑπÔ∏è Processus FFmpeg termin√© avec code: {exit_code}")
            if stderr and len(stderr) > 0:
                logger.debug(f"[{self.name}] FFmpeg stderr: {stderr[:200]}...")

            # Analyser l'erreur avec ErrorHandler (m√©thode statique)
            from error_handler import ErrorHandler
            error_type, diagnosis = ErrorHandler.analyze_ffmpeg_error(exit_code, stderr)

            # --- Handle Successful Completion (Advance to Next Video) ---
            if error_type == "success":
                # V√©rifier si on est en navigation manuelle
                if self.manual_navigation:
                    logger.info(f"[{self.name}] üîÑ Navigation manuelle en cours, pas d'auto-avancement")
                    self.manual_navigation = False
                    return

                logger.info(f"[{self.name}] ‚úÖ Fichier vid√©o termin√© avec succ√®s.")

                # NOUVEAU: Marquer qu'on est en transition pour d√©sactiver les checks de sant√©
                self.process_manager.transitioning = True

                next_video_index = 0 # Default index
                num_videos = 0

                with self.lock:
                    if not self.processed_videos: # Should not happen if started, but check
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide apr√®s fin de lecture.")
                        self.process_manager.transitioning = False
                        return # Cannot proceed

                    # Check if series.txt exists for sequential playback
                    channel_root_dir = Path(self.video_dir)
                    series_file = channel_root_dir / "series.txt"
                    use_sequential_order = series_file.exists()

                    num_videos = len(self.processed_videos)
                    old_index = self.current_video_index

                    if num_videos > 1:
                        if use_sequential_order:
                            # Sequential: advance to next video
                            next_video_index = (old_index + 1) % num_videos
                            logger.info(f"[{self.name}] ‚û°Ô∏è Passage √† la vid√©o suivante (mode s√©rie): Index {next_video_index}")
                        else:
                            # Random: pick a new random index, different from the old one
                            next_video_index = random.randrange(num_videos)
                            while next_video_index == old_index:
                                logger.debug(f"[{self.name}] üîÄ Vid√©o suivante identique ({next_video_index}), re-tirage...")
                                next_video_index = random.randrange(num_videos)
                            logger.info(f"[{self.name}] üîÄ S√©lection al√©atoire de la prochaine vid√©o: Index {next_video_index}")
                    elif num_videos == 1:
                        # Only one video, index must be 0
                        next_video_index = 0
                        logger.info(f"[{self.name}] ‚ÑπÔ∏è Une seule vid√©o disponible, lecture en boucle.")
                    else: # Should be caught above, but safety check
                         logger.error(f"[{self.name}] ‚ùå Incoh√©rence: 0 vid√©o mais blocage non d√©clench√© plus t√¥t.")
                         self.process_manager.transitioning = False
                         return

                    self.current_video_index = next_video_index

                # Schedule the start of the next video with a delay to ensure proper cleanup
                # Use the updated index for logging
                logger.info(f"[{self.name}] ‚è±Ô∏è Planification du d√©marrage du prochain fichier ({self.current_video_index + 1}/{num_videos}) dans 2 secondes...")
                threading.Timer(2.0, self._safe_start_stream).start()
                return # Don't proceed to error handling
            # --- End Successful Completion Handling ---

            # --- Error Handling (Simplifi√© et d√©l√©gu\u00e9 √† ErrorHandler) ---
            logger.warning(f"[{self.name}] ‚ö†Ô∏è Processus termin√© anormalement: {error_type}")
            if diagnosis:
                logger.info(f"[{self.name}] üìã Diagnostic: {diagnosis}")

            # G√©rer les probl√®mes de sant√© avec ErrorHandler
            if error_type in ["health_check_failed", "health_check_detailed"]:
                current_time = time.time()
                elapsed = current_time - getattr(self.process_manager, "last_segment_time", current_time)

                # D√©l√©guer √† ErrorHandler
                should_restart = self.error_handler.handle_health_warning(
                    diagnosis=diagnosis,
                    elapsed_since_segment=elapsed
                )

                if should_restart:
                    time.sleep(random.uniform(0.5, 2.0))
                    self._restart_stream(diagnostic=diagnosis)
                # Sinon, on attend le prochain warning

            # G√©rer les autres erreurs
            else:
                # Ajouter l'erreur √† ErrorHandler
                should_restart = self.error_handler.add_error(error_type)

                if should_restart:
                    logger.warning(f"[{self.name}] ‚ùó Red√©marrage n√©cessaire: {error_type}")
                    logger.info(f"[{self.name}] üìä {self.error_handler.get_errors_summary()}")

                    time.sleep(random.uniform(0.5, 3.0))
                    self._restart_stream(diagnostic=error_type)

                elif self.error_handler.has_critical_errors():
                    logger.error(f"[{self.name}] ‚ùå Erreurs critiques d√©tect√©es, arr√™t du stream")
                    # Attendre un peu avant d'arr√™ter pour √©viter les actions trop rapproch√©es
                    time.sleep(2)
                    self.stop_stream_if_needed()
                
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors de la gestion du processus: {e}")
            logger.error(traceback.format_exc())

    def _restart_stream(self, diagnostic=None, reset_to_first=False) -> bool:
        """Red√©marre le stream en choisissant un NOUVEAU fichier VID√âO (s√©quentiel si series.txt existe, sinon al√©atoire)

        Args:
            diagnostic: Raison du red√©marrage
            reset_to_first: Si True, repart du premier √©pisode (index 0) au lieu de passer au suivant
        """
        try:
            restart_reason = diagnostic or "Raison inconnue"
            logger.info(f"[{self.name}] üîÑ Tentative de red√©marrage du stream - Raison: {restart_reason}")

            # Arr√™ter proprement les processus FFmpeg
            self.process_manager.stop_process()

            # Nettoyer le dossier HLS
            self.hls_cleaner.cleanup_channel(self.name)

            # Attendre un peu avant de red√©marrer
            time.sleep(random.uniform(1.5, 3.0))

            # S√©lectionner un nouveau fichier (s√©quentiel ou al√©atoire selon series.txt)
            with self.lock:
                if not self.processed_videos:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Liste de vid√©os vide, impossible de red√©marrer.")
                    return False

                # Si la navigation manuelle est active, ne PAS changer l'index
                if self.manual_navigation:
                    logger.info(f"[{self.name}] üéØ Navigation manuelle: index d√©j√† d√©fini √† {self.current_video_index}")
                    # Le flag sera r√©initialis√© dans _handle_process_died ou start_stream
                else:
                    # Check if series.txt exists for sequential playback
                    channel_root_dir = Path(self.video_dir)
                    series_file = channel_root_dir / "series.txt"
                    use_sequential_order = series_file.exists()

                    num_videos = len(self.processed_videos)

                    # Si demand√©, r√©initialiser au premier √©pisode
                    if reset_to_first:
                        self.current_video_index = 0
                        logger.info(f"[{self.name}] ‚èÆÔ∏è R√©initialisation au premier √©pisode (index 0)")
                    elif num_videos > 1:
                        old_index = self.current_video_index

                        if use_sequential_order:
                            # Mode s√©rie: passer √† la vid√©o suivante dans l'ordre
                            next_video_index = (old_index + 1) % num_videos
                            logger.info(f"[{self.name}] ‚û°Ô∏è Passage √† la vid√©o suivante (mode s√©rie): Index {next_video_index}")
                        else:
                            # Mode al√©atoire: s√©lectionner une nouvelle vid√©o al√©atoire
                            next_video_index = random.randrange(num_videos)
                            while next_video_index == old_index:
                                next_video_index = random.randrange(num_videos)
                            logger.info(f"[{self.name}] üîÄ S√©lection d'un nouveau fichier al√©atoire: Index {next_video_index}")

                        self.current_video_index = next_video_index
                    else:
                        self.current_video_index = 0

            # Red√©marrer le stream
            success = self.start_stream()
            if success:
                logger.info(f"[{self.name}] ‚úÖ Stream red√©marr√© avec succ√®s sur un nouveau fichier.")
            else:
                logger.error(f"[{self.name}] ‚ùå √âchec du red√©marrage sur un nouveau fichier.")

            return success
        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur majeure lors du red√©marrage: {e}", exc_info=True)
            return False

    def stop_stream_if_needed(self):
        """Arr√™te le stream si n√©cessaire"""
        try:
            # Utiliser le process manager pour arr√™ter proprement les processus FFmpeg
            self.process_manager.stop_process()

            # Nettoyer le dossier HLS avec le HLSCleaner
            self.hls_cleaner.cleanup_channel(self.name)

            logger.info(f"[{self.name}] ‚úÖ Stream arr√™t√© avec succ√®s")
            return True

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur arr√™t stream: {e}")
            return False

    def start_stream(self) -> bool:
        """D√©marre le stream pour le fichier vid√©o actuel de cette cha√Æne"""
        try:
            with self.lock: # Lock to prevent race conditions with index/list
                # V√©rifier que la cha√Æne est pr√™te et a des vid√©os
                if not self.ready_for_streaming or not self.processed_videos:
                    logger.error(f"[{self.name}] ‚ùå La cha√Æne n'est pas pr√™te ou n'a pas de vid√©os.")
                    return False

                # V√©rifier la validit√© de l'index
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Index vid√©o invalide ({self.current_video_index}), r√©initialisation √† 0.")
                    self.current_video_index = 0
                    if not self.processed_videos: # Double check after reset
                         logger.error(f"[{self.name}] ‚ùå Aucune vid√©o √† lire apr√®s r√©initialisation de l'index.")
                         return False
                
                # Ensure permissions on all content files before starting
                self._ensure_permissions()
                         
                # S√©lectionner le fichier vid√©o actuel
                video_file = self.processed_videos[self.current_video_index]
                logger.info(f"[{self.name}] üé• Processing file ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")
                
                # Check if file still exists and is accessible
                if not video_file.exists() or not os.access(video_file, os.R_OK):
                    logger.error(f"[{self.name}] ‚ùå Fichier vid√©o inaccessible: {video_file}. Tentative de rescan...")

                    # CORRECTION: V√©rifier le succ√®s du rescan et ajouter de la robustesse
                    try:
                        scan_success = self._scan_videos() # Try to refresh the list
                        if not scan_success:
                            logger.error(f"[{self.name}] ‚ùå √âchec du rescan de la liste de vid√©os.")
                            return False

                        logger.info(f"[{self.name}] ‚úÖ Rescan r√©ussi, {len(self.processed_videos)} vid√©os trouv√©es")

                        # Check index validity again after rescan
                        if not (0 <= self.current_video_index < len(self.processed_videos)):
                            logger.warning(f"[{self.name}] ‚ö†Ô∏è Index {self.current_video_index} invalide apr√®s rescan, r√©initialisation √† 0")
                            self.current_video_index = 0

                        if not self.processed_videos:
                            logger.error(f"[{self.name}] ‚ùå Aucune vid√©o valide trouv√©e apr√®s rescan.")
                            return False

                        # Try to get the file again
                        video_file = self.processed_videos[self.current_video_index]
                        logger.info(f"[{self.name}] üîÑ Nouveau fichier s√©lectionn√© apr√®s rescan: {video_file.name}")

                        if not video_file.exists() or not os.access(video_file, os.R_OK):
                            logger.error(f"[{self.name}] ‚ùå Fichier toujours inaccessible apr√®s rescan: {video_file}. Abandon.")
                            return False # Give up if still inaccessible

                        logger.info(f"[{self.name}] üé• Reprise avec fichier ({self.current_video_index + 1}/{len(self.processed_videos)}): {video_file.name}")

                    except Exception as rescan_error:
                        logger.error(f"[{self.name}] ‚ùå Exception lors du rescan: {rescan_error}")
                        logger.error(traceback.format_exc())
                        return False


                # Cr√©er le dossier HLS
                hls_dir = Path(f"{HLS_DIR}/{self.name}")
                hls_dir.mkdir(parents=True, exist_ok=True)

                # Nettoyer les anciens segments AVANT de d√©marrer un nouveau fichier
                self.hls_cleaner.cleanup_channel(self.name)

                # Check if it's an MKV file
                has_mkv = ('.mkv' in video_file.name.lower())

                # Construire la commande FFmpeg pour le fichier unique
                command = self.command_builder.build_command(
                    input_file=str(video_file), # Pass the single video file path
                    output_dir=str(hls_dir),
                    progress_file=f"/app/logs/ffmpeg/{self.name}_progress.log",
                    has_mkv=has_mkv, # Pass the MKV check result for this specific file
                    # is_playlist=False # Default or remove parameter
                )

                if not command:
                    logger.error(f"[{self.name}] ‚ùå Impossible de construire la commande FFmpeg pour {video_file.name}")
                    
                    # Tentative avec le prochain fichier de la playlist
                    if len(self.processed_videos) > 1:
                        logger.warning(f"[{self.name}] üîÑ Tentative avec le prochain fichier dans la playlist...")
                        old_index = self.current_video_index
                        
                        # Select a new random index different from the current one
                        next_video_index = random.randrange(len(self.processed_videos))
                        while next_video_index == old_index:
                            next_video_index = random.randrange(len(self.processed_videos))
                            
                        logger.info(f"[{self.name}] üîÄ Passage au fichier suivant: {old_index} ‚Üí {next_video_index}")
                        self.current_video_index = next_video_index

                        # Lancer un nouveau thread pour red√©marrer le stream avec le nouvel index
                        threading.Timer(1.0, self._safe_start_stream).start()
                        return False
                    
                    return False

                logger.debug(f"[{self.name}] ‚öôÔ∏è Commande FFmpeg: {' '.join(command)}")

                # D√©marrer le processus FFmpeg
                success = self.process_manager.start_process(command, str(hls_dir))

                if success:
                    logger.info(f"[{self.name}] ‚úÖ Processus FFmpeg d√©marr√© avec succ√®s pour {video_file.name}")
                    self.error_handler.reset() # Reset errors on successful start
                    # NOUVEAU: R√©activer les checks de sant√© apr√®s un d√©marrage r√©ussi
                    self.process_manager.transitioning = False
                    # R√©initialiser le flag de navigation manuelle apr√®s un d√©marrage r√©ussi
                    self.manual_navigation = False
                else:
                    logger.error(f"[{self.name}] ‚ùå √âchec du d√©marrage du processus FFmpeg pour {video_file.name}")
                    
                    # Tentative avec le prochain fichier de la playlist en cas d'√©chec du d√©marrage
                    if len(self.processed_videos) > 1:
                        logger.warning(f"[{self.name}] üîÑ √âchec du d√©marrage, tentative avec le prochain fichier...")
                        old_index = self.current_video_index
                        
                        # Select a new random index different from the current one
                        next_video_index = random.randrange(len(self.processed_videos))
                        while next_video_index == old_index:
                            next_video_index = random.randrange(len(self.processed_videos))
                            
                        logger.info(f"[{self.name}] üîÄ Passage au fichier suivant apr√®s √©chec: {old_index} ‚Üí {next_video_index}")
                        self.current_video_index = next_video_index

                        # Lancer un nouveau thread pour red√©marrer le stream avec le nouvel index
                        threading.Timer(1.0, self._safe_start_stream).start()

                return success # Return success status outside the lock

        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors de la d√©marrage du stream: {e}")
            logger.error(traceback.format_exc())
            return False

    def _scan_videos(self) -> bool:
        """Scanne le dossier ready_to_stream, valide les fichiers, les m√©lange et met √† jour self.processed_videos. Renvoie True si r√©ussi et au moins une vid√©o trouv√©e, False sinon."""
        try:
            with self.lock: # Use lock as we modify shared state
                ready_to_stream_dir = Path(self.video_dir) / "ready_to_stream"
                if not ready_to_stream_dir.exists():
                    logger.error(f"[{self.name}] ‚ùå Dossier ready_to_stream introuvable: {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False

                # Check if series.txt exists in the channel folder root
                channel_root_dir = Path(self.video_dir)
                series_file = channel_root_dir / "series.txt"
                use_alphabetic_order = series_file.exists()

                if use_alphabetic_order:
                    logger.info(f"[{self.name}] üìÑ Fichier series.txt d√©tect√© - ordre alphab√©tique activ√©")

                # Scanner le dossier ready_to_stream (removed sorted())
                all_video_files = list(ready_to_stream_dir.glob("*.mp4"))

                # IMPORTANT: Filtrer les fichiers macOS (._*) et autres fichiers cach√©s
                video_files = [v for v in all_video_files if not v.name.startswith('._') and not v.name.startswith('.')]

                if len(all_video_files) != len(video_files):
                    filtered_count = len(all_video_files) - len(video_files)
                    logger.info(f"[{self.name}] üóëÔ∏è {filtered_count} fichiers cach√©s/m√©tadonn√©es ignor√©s")

                if not video_files:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Aucun fichier MP4 valide dans {ready_to_stream_dir}")
                    self.processed_videos = []
                    return False

                logger.info(f"[{self.name}] üîç {len(video_files)} fichiers valides trouv√©s dans ready_to_stream")

                # V√©rifier que tous les fichiers sont valides
                valid_files = []
                for video in video_files:
                    if video.exists() and os.access(video, os.R_OK):
                        # Optional: Add duration check if needed
                        # try:
                        #     duration = get_accurate_duration(video)
                        #     if duration and duration > 0:
                        #         valid_files.append(video)
                        #     else:
                        #         logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (dur√©e invalide)")
                        # except Exception as e:
                        #     logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (erreur validation: {e})")
                        valid_files.append(video) # Simpler validation for now
                    else:
                        logger.warning(f"[{self.name}] ‚ö†Ô∏è Fichier ignor√©: {video.name} (non accessible)")

                if not valid_files:
                    logger.error(f"[{self.name}] ‚ùå Aucun fichier MP4 valide trouv√© apr√®s v√©rification")
                    self.processed_videos = []
                    return False

                # Sort alphabetically or shuffle based on series.txt presence
                if use_alphabetic_order:
                    valid_files.sort(key=lambda x: x.name.lower())
                    logger.info(f"[{self.name}] üî§ Liste de vid√©os tri√©e alphab√©tiquement.")
                else:
                    random.shuffle(valid_files)
                    logger.info(f"[{self.name}] üîÄ Liste de vid√©os m√©lang√©e.")

                logger.info(f"[{self.name}] ‚úÖ {len(valid_files)} vid√©os valides trouv√©es.")
                self.processed_videos = valid_files # Update the list
                # Reset index if it's now out of bounds OR if the list changed significantly
                # (safer to reset to 0 on any successful scan with videos)
                if not (0 <= self.current_video_index < len(self.processed_videos)):
                     logger.info(f"[{self.name}] üîÑ R√©initialisation de l'index vid√©o √† 0 apr√®s scan.")
                     self.current_video_index = 0
                elif len(self.processed_videos) > 0 and self.current_video_index >= len(self.processed_videos):
                    # Handle case where list shrank and index is now invalid
                    logger.info(f"[{self.name}] üîÑ Liste de vid√©os r√©duite, r√©initialisation de l'index vid√©o √† 0.")
                    self.current_video_index = 0


                return True # Success

        except Exception as e:
            logger.error(f"[{self.name}] ‚ùå Erreur _scan_videos: {e}")
            logger.error(traceback.format_exc())
            self.processed_videos = []
            return False # Failure 

    def is_running(self) -> bool:
        """V√©rifie si la cha√Æne est actuellement en streaming"""
        return self.process_manager.is_running()

    def is_ready_for_streaming(self) -> bool:
        """V√©rifie si la cha√Æne est pr√™te √† √™tre ajout√©e √† la playlist principale."""
        return self.ready_for_streaming and self.initial_scan_complete and len(self.processed_videos) > 0

    def _clean_processes(self):
        """Nettoie tous les processus FFmpeg associ√©s √† cette cha√Æne."""
        try:
            if self.process_manager:
                self.process_manager.stop_process()
            logger.info(f"[{self.name}] Processus FFmpeg nettoy√©s.")
        except Exception as e:
            logger.error(f"[{self.name}] Erreur lors du nettoyage des processus: {e}")

    def _ensure_permissions(self):
        """S'assure que tous les fichiers et dossiers de la cha√Æne ont les bonnes permissions."""
        # Cette fonction est conserv√©e pour la structure mais les appels chmod sont d√©sactiv√©s.
        if not hasattr(self, 'video_extensions'):
            self.video_extensions = (".mp4", ".avi", ".mkv", ".mov", ".m4v")
        return True
            
    def refresh_videos(self):
        """
        Rafra√Æchit la liste des vid√©os et red√©marre le stream si n√©cessaire.
        Cette m√©thode est appel√©e quand des fichiers sont ajout√©s/supprim√©s dans ready_to_stream.
        """
        logger.info(f"[{self.name}] üîÑ Rafra√Æchissement des vid√©os suite √† un changement")
        
        # Sauvegarder la liste actuelle pour d√©tecter les changements
        old_videos = set()
        if hasattr(self, "processed_videos") and self.processed_videos:
            old_videos = set(str(v) for v in self.processed_videos)
        
        # Scanner les vid√©os
        with self.lock:  # Verrouiller pour modifier l'√©tat partag√©
            scan_success = self._scan_videos()
            if not scan_success:
                logger.warning(f"[{self.name}] ‚ö†Ô∏è √âchec du scan lors du rafra√Æchissement des vid√©os")
                # Si √©chec du scan et qu'on √©tait en cours de lecture, il faut arr√™ter
                if self.is_running() and not self.processed_videos:
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Plus de vid√©os disponibles, arr√™t du stream")
                    self.process_manager.stop_process()
                return False
        
        # V√©rifier si la liste des vid√©os a chang√©
        new_videos = set(str(v) for v in self.processed_videos)
        if old_videos == new_videos:
            logger.info(f"[{self.name}] ‚ÑπÔ∏è Aucun changement d√©tect√© dans la liste des vid√©os")
            return True
            
        # La liste a chang√©, v√©rifier si le stream est en cours
        if self.is_running():
            # Si on lit actuellement un fichier qui a √©t√© supprim√©
            if self.current_video_index < len(self.processed_videos):
                current_file = str(self.processed_videos[self.current_video_index])
                # V√©rifier si le fichier actuel existe toujours
                if current_file not in old_videos or not Path(current_file).exists():
                    logger.warning(f"[{self.name}] ‚ö†Ô∏è Le fichier actuel a √©t√© supprim√© ou modifi√©, red√©marrage n√©cessaire")
                    # Red√©marrer le stream avec un nouveau fichier
                    return self._restart_stream(diagnostic="file_deleted")
            else:
                # Index invalide, n√©cessite un red√©marrage
                logger.warning(f"[{self.name}] ‚ö†Ô∏è Index vid√©o ({self.current_video_index}) invalide apr√®s changement de liste")
                return self._restart_stream(diagnostic="index_invalid")
        
        # Le stream n'est pas en cours, ou le fichier actuel existe toujours
        logger.info(f"[{self.name}] ‚úÖ Liste de vid√©os mise √† jour: {len(self.processed_videos)} fichiers")
        return True

