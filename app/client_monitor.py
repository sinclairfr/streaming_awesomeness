import os
import time
import threading
from pathlib import Path
from config import logger
from typing import Dict, Tuple, List, Set
import re
from config import TIMEOUT_NO_VIEWERS


class ClientMonitor(threading.Thread):
    def __init__(self, log_path, update_watchers_callback, manager):
        super().__init__(daemon=True)
        self.log_path = log_path
        self.update_watchers = update_watchers_callback
        self.manager = manager
        self.watchers = {}  # {(channel, ip): last_seen_time}
        self.segments_by_channel = {}  # {channel: {segment_id: last_requested_time}}
        self.lock = threading.Lock()

        # On augmente le seuil d'inactivit√© pour √©viter les d√©connexions trop rapides
        self.inactivity_threshold = TIMEOUT_NO_VIEWERS

        # Thread de nettoyage
        self.cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self.cleanup_thread.start()

        # Nouveau thread pour surveiller les sauts de segments
        self.segment_monitor_thread = threading.Thread(
            target=self._monitor_segment_jumps, daemon=True
        )
        self.segment_monitor_thread.start()

    def _cleanup_loop(self):
        """Nettoie les watchers inactifs plus fr√©quemment"""
        while True:
            time.sleep(10)
            self._cleanup_inactive()

    def _cleanup_inactive(self):
        """Nettoie les watchers inactifs avec un d√©lai plus strict"""
        now = time.time()
        to_remove = []

        with self.lock:
            # Crit√®res de nettoyage plus stricts
            for (channel, ip), data in self.watchers.items():
                if isinstance(data, dict):
                    watcher_time = data.get("time", 0)
                    watcher_type = data.get("type", "unknown")
                else:
                    watcher_time = data
                    watcher_type = "unknown"

                # Diff√©rents timeouts selon le type de requ√™te
                if (
                    (watcher_type == "segment" and now - watcher_time > 40)
                    or (watcher_type == "playlist" and now - watcher_time > 20)
                    or (watcher_type == "unknown" and now - watcher_time > 30)
                ):
                    to_remove.append((channel, ip))

            affected_channels = set()

            for key in to_remove:
                channel, ip = key
                if key in self.watchers:  # V√©rification suppl√©mentaire
                    data = self.watchers[key]
                    if isinstance(data, dict):
                        watcher_time = data.get("time", 0)
                    else:
                        watcher_time = data

                    del self.watchers[key]
                    affected_channels.add(channel)
                    logger.info(
                        f"üóëÔ∏è Watcher supprim√©: {ip} -> {channel} (inactif depuis {now - watcher_time:.1f}s)"
                    )

            # Pour chaque cha√Æne affect√©e, recalculer le nombre exact de watchers
            for channel in affected_channels:
                # Comptage pr√©cis par type de requ√™te
                now = time.time()
                segment_watchers = set()
                playlist_watchers = set()

                for (ch, watcher_ip), data in self.watchers.items():
                    if ch != channel:
                        continue

                    if isinstance(data, dict):
                        watcher_time = data.get("time", 0)
                        watcher_type = data.get("type", "unknown")
                    else:
                        watcher_time = data
                        watcher_type = "unknown"

                    if watcher_type == "segment" and now - watcher_time < 40:
                        segment_watchers.add(watcher_ip)
                    elif watcher_type == "playlist" and now - watcher_time < 20:
                        playlist_watchers.add(watcher_ip)

                # Un watcher est actif s'il a demand√© soit un segment r√©cemment, soit une playlist
                active_ips = segment_watchers.union(playlist_watchers)
                count = len(active_ips)

                # Mise √† jour explicite du compteur
                if count != self.get_channel_watchers(channel):
                    logger.info(
                        f"[{channel}] üîÑ Mise √† jour forc√©e: {count} watchers actifs (seg: {len(segment_watchers)}, pl: {len(playlist_watchers)})"
                    )
                    self.update_watchers(channel, count, "/hls/")

    def _monitor_segment_jumps(self):
        """Surveille les sauts anormaux dans les segments"""
        while True:
            try:
                with self.lock:
                    for channel, segments in self.segments_by_channel.items():
                        if len(segments) < 2:
                            continue

                        # R√©cup√©ration des segments ordonn√©s par ID
                        ordered_segments = sorted(
                            [
                                (int(seg_id), ts)
                                for seg_id, ts in segments.items()
                                if seg_id.isdigit()
                            ],
                            key=lambda x: x[0],
                        )

                        # V√©rification des sauts
                        for i in range(1, len(ordered_segments)):
                            current_id, current_ts = ordered_segments[i]
                            prev_id, prev_ts = ordered_segments[i - 1]

                            # Si le saut est sup√©rieur √† 5 segments et r√©cent (< 20 secondes)
                            if (
                                current_id - prev_id > 5
                                and time.time() - current_ts < 20
                            ):
                                logger.warning(
                                    f"‚ö†Ô∏è Saut d√©tect√© pour {channel}: segment {prev_id} ‚Üí {current_id} "
                                    f"(saut de {current_id - prev_id} segments)"
                                )

                                # On peut notifier ici ou prendre des mesures
                                channel_obj = self.manager.channels.get(channel)
                                if channel_obj and hasattr(
                                    channel_obj, "report_segment_jump"
                                ):
                                    channel_obj.report_segment_jump(prev_id, current_id)
            except Exception as e:
                logger.error(f"‚ùå Erreur surveillance segments: {e}")

            time.sleep(10)  # V√©rification toutes les 10 secondes

    def _check_log_file(self):
        """V√©rifie p√©riodiquement l'√©tat du fichier de log et force une reconnexion si n√©cessaire"""
        while True:
            try:
                # V√©rifier si le fichier existe
                if not os.path.exists(self.log_path):
                    logger.error(
                        f"‚ùå Log file introuvable lors de la v√©rification p√©riodique: {self.log_path}"
                    )
                    # Forcer la reconnexion
                    self._force_reconnect = True

                # V√©rifier la taille et les permissions
                try:
                    file_info = os.stat(self.log_path)
                    file_size = file_info.st_size

                    # Si le fichier est vide ou trop petit
                    if file_size < 10:
                        logger.warning(
                            f"‚ö†Ô∏è Fichier log anormalement petit: {file_size} bytes"
                        )

                    # V√©rifier les permissions
                    if not os.access(self.log_path, os.R_OK):
                        logger.error(f"‚ùå Permissions insuffisantes sur le fichier log")
                        self._force_reconnect = True

                except Exception as e:
                    logger.error(f"‚ùå Erreur v√©rification stats fichier log: {e}")

                # V√©rifier l'activit√© Nginx
                try:
                    nginx_running = False
                    for proc in psutil.process_iter(["name"]):
                        if "nginx" in proc.info["name"]:
                            nginx_running = True
                            break

                    if not nginx_running:
                        logger.critical(
                            f"üö® Nginx semble ne pas √™tre en cours d'ex√©cution!"
                        )
                        # Tenter de voir si le containeur est en cours d'ex√©cution
                        result = subprocess.run(
                            ["docker", "ps", "--filter", "name=iptv-nginx"],
                            capture_output=True,
                            text=True,
                        )
                        logger.info(f"√âtat containeur Nginx: {result.stdout}")
                except Exception as e:
                    logger.error(f"‚ùå Erreur v√©rification Nginx: {e}")

            except Exception as e:
                logger.error(f"‚ùå Erreur dans _check_log_file: {e}")

            time.sleep(60)  # V√©rification toutes les minutes

    def get_channel_watchers(self, channel):
        """R√©cup√®re le nombre actuel de watchers pour une cha√Æne"""
        if hasattr(self.manager, "channels") and channel in self.manager.channels:
            return getattr(self.manager.channels[channel], "watchers_count", 0)
        return 0

    def _parse_access_log(self, line):
        """
        Analyse une ligne de log nginx pour d√©tecter l'activit√©
        Retourne (ip, channel, request_type, is_valid_request)
        """
        try:
            # Ajout de l'extraction de l'user agent
            user_agent = None
            ua_match = re.search(r'"([^"]+)"$', line) or re.search(
                r'"([^"]+)" "-"', line
            )
            if ua_match:
                user_agent = ua_match.group(1)

            # Format analys√© avec plus de robustesse
            # Extraction de l'IP (au d√©but de la ligne)
            ip_match = re.match(r"^([0-9.]+)", line)
            if not ip_match:
                return None, None, None, False

            ip = ip_match.group(1)

            # Extraction de la requ√™te avec une regex plus souple
            req_match = re.search(r'"(?:GET|HEAD) ([^"]+) HTTP', line)
            if not req_match:
                return None, None, None, False

            request_path = req_match.group(1)

            # Extraction du statut HTTP avec plus de robustesse
            status_match = re.search(r'" (\d{3}) ', line)
            status_code = status_match.group(1) if status_match else "???"

            # V√©rification HLS
            if "/hls/" not in request_path:
                return None, None, None, False

            # D√©termination du type de requ√™te
            request_type = "unknown"
            if ".m3u8" in request_path:
                request_type = "playlist"
            elif ".ts" in request_path:
                request_type = "segment"

            # Extraction du nom de cha√Æne avec une regex plus robuste
            channel_match = re.search(r"/hls/([^/]+)/", request_path)
            if not channel_match:
                return ip, None, request_type, False

            channel = channel_match.group(1)

            # Valide si 200 ou 206 (partial content)
            is_valid = status_code in ["200", "206"]

            # Log plus explicite
            if is_valid:
                logger.info(f"üì± Client actif: {ip} ‚Üí {channel} ({request_type})")

            return ip, channel, request_type, is_valid, user_agent

        except Exception as e:
            logger.error(f"‚ùå Erreur analyse log: {e}")
            logger.error(traceback.format_exc())
            return None, None, None, False

    def run(self):
        """On surveille les requ√™tes clients"""
        logger.info("üëÄ D√©marrage de la surveillance des requ√™tes...")

        retry_count = 0
        max_retries = 5

        while True:
            try:
                # V√©rifier si le fichier existe
                if not os.path.exists(self.log_path):
                    logger.error(f"‚ùå Log file introuvable: {self.log_path}")
                    # Attendre et r√©essayer
                    time.sleep(10)
                    retry_count += 1
                    if retry_count > max_retries:
                        logger.critical(
                            f"‚ùå Impossible de trouver le fichier de log apr√®s {max_retries} tentatives"
                        )
                        # Red√©marrage forc√© du monitoring
                        time.sleep(30)
                        retry_count = 0
                    continue

                logger.info(f"üìñ Ouverture du log: {self.log_path}")

                # Tester si le fichier est accessible en lecture
                try:
                    with open(self.log_path, "r") as test_file:
                        last_pos = test_file.seek(0, 2)  # Se positionne √† la fin
                        logger.info(
                            f"‚úÖ Fichier de log accessible, taille: {last_pos} bytes"
                        )
                except Exception as e:
                    logger.error(f"‚ùå Impossible de lire le fichier de log: {e}")
                    time.sleep(10)
                    continue

                with open(self.log_path, "r") as f:
                    # Se positionne √† la fin du fichier
                    f.seek(0, 2)

                    # Log pour debug
                    logger.info(f"üëÅÔ∏è Monitoring actif sur {self.log_path}")
                    retry_count = 0

                    last_activity_time = time.time()
                    last_heartbeat_time = time.time()
                    last_cleanup_time = time.time()

                    while True:
                        line = f.readline().strip()
                        current_time = time.time()

                        # V√©rification p√©riodique pour nettoyer les watchers inactifs
                        if (
                            current_time - last_cleanup_time > 10
                        ):  # Tous les 10 secondes
                            self._cleanup_inactive()
                            last_cleanup_time = current_time

                        # Heartbeat p√©riodique pour s'assurer que le monitoring est actif
                        if (
                            current_time - last_heartbeat_time > 60
                        ):  # Toutes les minutes
                            logger.info(
                                f"üíì ClientMonitor actif, derni√®re activit√© il y a {current_time - last_activity_time:.1f}s"
                            )
                            last_heartbeat_time = current_time

                            # V√©rification p√©riodique du fichier
                            try:
                                if not os.path.exists(self.log_path):
                                    logger.error(
                                        f"‚ùå Fichier log disparu: {self.log_path}"
                                    )
                                    break

                                # V√©rification que le fichier n'a pas √©t√© tronqu√©
                                current_pos = f.tell()
                                file_size = os.path.getsize(self.log_path)
                                if current_pos > file_size:
                                    logger.error(
                                        f"‚ùå Fichier log tronqu√©: position {current_pos}, taille {file_size}"
                                    )
                                    break
                            except Exception as e:
                                logger.error(f"‚ùå Erreur v√©rification fichier log: {e}")
                                break

                        if not line:
                            # Si pas d'activit√© depuis longtemps, forcer une relecture des derni√®res lignes
                            if current_time - last_activity_time > 300:  # 5 minutes
                                logger.warning(
                                    f"‚ö†Ô∏è Pas d'activit√© depuis 5 minutes, relecture forc√©e des derni√®res lignes"
                                )
                                f.seek(
                                    max(0, f.tell() - 10000)
                                )  # Retour en arri√®re de 10Ko
                                last_activity_time = current_time

                            time.sleep(0.1)  # R√©duit la charge CPU
                            continue

                        # Une ligne a √©t√© lue, mise √† jour du temps d'activit√©
                        last_activity_time = current_time

                        # Analyse plus pr√©cise de la ligne avec la m√©thode am√©lior√©e
                        ip, channel, request_type, is_valid = self._parse_access_log(
                            line
                        )

                        if not channel or not is_valid:
                            continue  # Ignorer les requ√™tes invalides ou sans cha√Æne

                        # Log d√©taill√© pour debug (niveau info pour voir si √ßa fonctionne)
                        logger.debug(
                            f"üîç [{channel}] {request_type} ({ip}) - Valide: {is_valid}"
                        )

                        with self.lock:
                            # Mise √† jour du timestamp pour ce watcher
                            if channel and ip:
                                # Stockage pr√©cis du type de requ√™te et du temps
                                self.watchers[(channel, ip)] = {
                                    "time": time.time(),
                                    "type": request_type,
                                }

                                # Si c'est une requ√™te de segment, on l'enregistre
                                if request_type == "segment":
                                    segment_match = re.search(
                                        r"segment_(\d+)\.ts", line
                                    )
                                    segment_id = (
                                        segment_match.group(1)
                                        if segment_match
                                        else "unknown"
                                    )

                                    self.segments_by_channel.setdefault(channel, {})[
                                        segment_id
                                    ] = time.time()

                                    # Ajouter du temps de visionnage (chaque segment = ~4 secondes)
                                    if hasattr(self.manager, "stats_collector"):
                                        self.manager.stats_collector.add_watch_time(
                                            channel, ip, 4
                                        )

                                # Si c'est une requ√™te de playlist, consid√©rer comme un heartbeat
                                if request_type == "playlist":
                                    # Heartbeat playlist = ~0.5 secondes de visionnage (rafra√Æchissement)
                                    if hasattr(self.manager, "stats_collector"):
                                        self.manager.stats_collector.add_watch_time(
                                            channel, ip, 0.5
                                        )

                                # Calcul SIMPLIFI√â des watchers par cha√Æne
                                # Un watcher est unique par IP pour une cha√Æne donn√©e
                                active_ips = set()
                                for (ch, watcher_ip), data in self.watchers.items():
                                    if ch != channel:
                                        continue

                                    # On consid√®re un watcher actif s'il a une activit√© r√©cente
                                    watcher_time = (
                                        data["time"] if isinstance(data, dict) else data
                                    )
                                    if (
                                        time.time() - watcher_time < 60
                                    ):  # 60 secondes max d'inactivit√©
                                        active_ips.add(watcher_ip)

                                active_watchers = len(active_ips)

                                # Mise √† jour du compteur uniquement si √ßa a chang√©
                                if active_watchers != self.get_channel_watchers(
                                    channel
                                ):
                                    logger.info(
                                        f"[{channel}] üëÅÔ∏è MAJ watchers: {active_watchers} (analyse simplifi√©e)"
                                    )
                                    self.update_watchers(
                                        channel, active_watchers, request_type
                                    )

            except Exception as e:
                logger.error(f"‚ùå Erreur fatale dans client_monitor: {e}")
                import traceback

                logger.error(traceback.format_exc())

                # Attente avant de r√©essayer
                time.sleep(10)
