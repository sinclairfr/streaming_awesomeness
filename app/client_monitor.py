import os
import time
import threading
from pathlib import Path
from config import logger
from typing import Dict, Tuple, List, Set
import re
from log_utils import parse_access_log
from time_tracker import TimeTracker

os.environ['TZ'] = 'Europe/Paris'
time.tzset()  # Applique le changement

class ClientMonitor(threading.Thread):

    # Timeouts pour les diff√©rents types de requ√™tes (en secondes)
    SEGMENT_TIMEOUT = int(os.getenv('CLIENT_MONITOR_SEGMENT_TIMEOUT', 30))
    PLAYLIST_TIMEOUT = int(os.getenv('CLIENT_MONITOR_PLAYLIST_TIMEOUT', 20))
    UNKNOWN_TIMEOUT = int(os.getenv('CLIENT_MONITOR_UNKNOWN_TIMEOUT', 25))
    WATCHER_INACTIVITY_TIMEOUT = int(os.getenv('CLIENT_MONITOR_WATCHER_INACTIVITY_TIMEOUT', 60))  # Timeout pour consid√©rer un watcher comme inactif
    
    # Ajouter des timeouts sp√©cifiques pour le nettoyage
    CLEANUP_SEGMENT_TIMEOUT = int(os.getenv('CLIENT_MONITOR_CLEANUP_SEGMENT_TIMEOUT', 300))  # 5 minutes pour les segments
    CLEANUP_PLAYLIST_TIMEOUT = int(os.getenv('CLIENT_MONITOR_CLEANUP_PLAYLIST_TIMEOUT', 180))  # 3 minutes pour les playlists  
    CLEANUP_UNKNOWN_TIMEOUT = int(os.getenv('CLIENT_MONITOR_CLEANUP_UNKNOWN_TIMEOUT', 240))   # 4 minutes pour les autres types

    def __init__(self, log_path, update_watchers_callback, manager, stats_collector=None):
        super().__init__(daemon=True)
        self.log_path = log_path

        # Callback pour mettre √† jour les watchers dans le manager
        self.update_watchers = update_watchers_callback
        # Manager pour acc√©der aux segments et aux canaux
        self.manager = manager
        # StatsCollector pour les statistiques
        self.stats_collector = stats_collector

        # Initialiser le TimeTracker
        self.time_tracker = TimeTracker(stats_collector)

        # dictionnaire pour stocker les watchers actifs avec leurs minuteurs
        self.watchers = {}  # {ip: {"timer": WatcherTimer, "last_seen": time, "type": str, "current_channel": str}}

        # dictionnaire pour stocker les segments demand√©s par chaque canal
        self.segments_by_channel = {}  # {channel: {segment_id: last_requested_time}}

        # Pour √©viter les acc√®s concurrents
        self.lock = threading.Lock()

        # √âv√©nement pour l'arr√™t propre du thread de nettoyage
        self.stop_event = threading.Event()

        logger.info(f"‚è±Ô∏è Timeouts configur√©s - Watcher inactif: {self.WATCHER_INACTIVITY_TIMEOUT}s, Segment: {self.SEGMENT_TIMEOUT}s, Playlist: {self.PLAYLIST_TIMEOUT}s")

        # Thread de nettoyage
        self.cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self.cleanup_thread.start()
        
        # Pour le logging p√©riodique
        self.last_cleanup_log = time.time()

    def run(self):
        """M√©thode principale du thread"""
        logger.info("üöÄ D√©marrage du ClientMonitor")
        self.run_client_monitor()

    def _cleanup_loop(self):
        """Nettoie les watchers inactifs et v√©rifie l'√©tat des logs"""
        while not self.stop_event.is_set():
            try:
                # Utiliser le TimeTracker pour le nettoyage
                self.time_tracker.cleanup_inactive_watchers()
                
                # Forcer la mise √† jour des compteurs pour toutes les cha√Ænes
                active_channels = {}
                for ip, data in self.watchers.items():
                    channel = data.get("current_channel")
                    if channel and channel not in active_channels:
                        active_channels[channel] = set()
                    if channel:
                        active_channels[channel].add(ip)
                
                # Mettre √† jour chaque cha√Æne
                for channel in active_channels:
                    self._update_channel_watchers_count(channel)
                
                # Log p√©riodique des watchers actifs
                current_time = time.time()
                if current_time - self.last_cleanup_log > 30:
                    active_channels = {}
                    for channel in self.time_tracker._active_segments:
                        active_ips = self.time_tracker.get_active_watchers(channel)
                        if active_ips:
                            active_channels[channel] = active_ips
                    
                    for channel, watchers in active_channels.items():
                        logger.info(f"[{channel}] üë• {len(watchers)} watchers actifs: {', '.join(watchers)}")
                    
                    self.last_cleanup_log = current_time
                
                time.sleep(5)  # V√©rification toutes les 5s
                
            except Exception as e:
                logger.error(f"‚ùå Erreur cleanup_loop: {e}")
                time.sleep(5)

    def _print_channels_summary(self):
        """Affiche un r√©sum√© des cha√Ænes et de leurs watchers"""
        try:
            active_channels = {}
            for ip, watcher in self.watchers.items():
                channel = watcher.get("current_channel", "unknown")
                if channel not in active_channels:
                    active_channels[channel] = set()
                active_channels[channel].add(ip)
            
            if active_channels:
                logger.info("üìä R√©sum√© des cha√Ænes:")
                for channel, watchers in active_channels.items():
                    logger.info(f"[{channel}] üë• {len(watchers)} watchers: {', '.join(watchers)}")
            else:
                logger.info("üìä Aucun watcher actif")
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©sum√© cha√Ænes: {e}")

    def get_channel_watchers(self, channel):
        """R√©cup√®re le nombre actuel de watchers pour une cha√Æne"""
        if hasattr(self.manager, "channels") and channel in self.manager.channels:
            return getattr(self.manager.channels[channel], "watchers_count", 0)
        return 0

    def _parse_access_log(self, line):
        """Version harmonis√©e qui utilise la fonction utilitaire"""
        return parse_access_log(line)

    def _process_log_line(self, line):
        """Traite une ligne de log nginx"""
        try:
            # Parse la ligne
            ip, channel, request_type, is_valid, user_agent = self._parse_access_log(line)

            # Log plus d√©taill√© pour le diagnostic
            if is_valid and channel and "/hls/" in line:
                logger.info(f"üìù TRAITEMENT LIGNE: ip={ip}, channel={channel}, type={request_type}, valid={is_valid}")

            # Si la ligne n'est pas valide ou pas de channel, on ignore
            if not is_valid or not channel:
                if "/hls/" in line and not is_valid:
                    logger.warning(f"‚ö†Ô∏è Ligne non valide ignor√©e: {line[:100]}...")
                return

            # Si c'est la playlist principale, on ignore
            if channel == "master_playlist":
                return

            # V√©rifier que la cha√Æne existe dans le manager
            if not hasattr(self.manager, "channels"):
                logger.error("‚ùå Le manager n'a pas d'attribut 'channels'")
                return

            # Log des cha√Ænes disponibles
            logger.debug(f"üìã Cha√Ænes disponibles: {list(self.manager.channels.keys())}")
            logger.debug(f"üîç Recherche de la cha√Æne: {channel}")

            if channel not in self.manager.channels:
                logger.debug(f"‚ö†Ô∏è Cha√Æne {channel} non trouv√©e dans le manager, ignor√©e")
                return

            # Log d√©taill√© de la requ√™te
            logger.debug(f"üìù Requ√™te d√©taill√©e: IP={ip}, Channel={channel}, Type={request_type}, User-Agent={user_agent}")

            # Mise √† jour du watcher avec la nouvelle structure
            self._update_watcher(ip, channel, request_type, user_agent, line)

            # Si c'est une requ√™te de playlist, on force une mise √† jour des watchers
            if request_type == "playlist":
                logger.debug(f"üîÑ Requ√™te playlist d√©tect√©e pour {channel} par {ip}")
                self._update_channel_watchers_count(channel)

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement ligne log: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _update_watcher(self, ip, channel, request_type, user_agent, line):
        """Met √† jour les informations d'un watcher sp√©cifique"""
        with self.lock:
            current_time = time.time()
            
            # Si le watcher n'existe pas, cr√©er un nouveau minuteur
            if ip not in self.watchers:
                self.watchers[ip] = {
                    "last_seen": current_time,
                    "type": request_type,
                    "user_agent": user_agent,
                    "current_channel": channel,
                    "last_activity": current_time
                }
                logger.info(f"üÜï Nouveau watcher d√©tect√©: {ip} sur {channel}")
                # Forcer une mise √† jour du compteur de watchers
                self._update_channel_watchers_count(channel)
            else:
                # V√©rifier si la cha√Æne a chang√©
                old_channel = self.watchers[ip].get("current_channel")
                if old_channel != channel:
                    logger.info(f"üîÑ Changement de cha√Æne pour {ip}: {old_channel} -> {channel}")
                    # Notifier le StatsCollector du changement de cha√Æne
                    if self.stats_collector:
                        self.stats_collector.handle_channel_change(ip, old_channel, channel)
                    self.watchers[ip]["current_channel"] = channel
                    
                    # Mettre √† jour les compteurs pour l'ancienne et la nouvelle cha√Æne
                    if old_channel:
                        self._update_channel_watchers_count(old_channel)
                    self._update_channel_watchers_count(channel)
                else:
                    # M√™me cha√Æne, v√©rifier le temps √©coul√© depuis la derni√®re requ√™te
                    last_seen = self.watchers[ip].get("last_seen", 0)
                    if current_time - last_seen < 0.5 and request_type == "playlist":  # R√©duit de 1.0 √† 0.5 secondes
                        # Ignorer les mises √† jour trop rapproch√©es pour √©viter le spam
                        logger.debug(f"Ignor√© mise √† jour rapproch√©e pour {ip} sur {channel} (interval: {current_time - last_seen:.2f}s)")
                        # On met quand m√™me √† jour last_activity pour garder le watcher actif
                        self.watchers[ip]["last_activity"] = current_time
                        return

                # Mise √† jour des infos
                self.watchers[ip]["last_seen"] = current_time
                self.watchers[ip]["type"] = request_type
                self.watchers[ip]["user_agent"] = user_agent
                self.watchers[ip]["last_activity"] = current_time

            # D√©l√©guer la collecte des statistiques au StatsCollector
            if self.stats_collector:
                if request_type == "segment":
                    self.stats_collector.handle_segment_request(channel, ip, line, user_agent)
                elif request_type == "playlist":
                    # Pour les playlists, on n'ajoute du temps que si √ßa fait au moins 1 seconde
                    # depuis la derni√®re requ√™te, pour √©viter les doublons
                    last_seen = self.watchers[ip].get("last_seen", 0)
                    if current_time - last_seen >= 1.0:  # R√©duit de 3.0 √† 1.0 secondes
                        elapsed = min(current_time - last_seen, 5.0)
                        self.stats_collector.handle_playlist_request(channel, ip, elapsed, user_agent)

            # Si c'est un segment ou une playlist, forcer la mise √† jour du compteur
            if request_type in ["segment", "playlist"]:
                self._update_channel_watchers_count(channel)

    def _check_log_file_exists(self, retry_count, max_retries):
        """V√©rifie si le fichier de log existe et est accessible"""
        if not os.path.exists(self.log_path):
            logger.error(f"‚ùå Log file introuvable: {self.log_path}")

            # Abandon apr√®s trop d'essais
            if retry_count > max_retries:
                logger.critical(
                    f"‚ùå Impossible de trouver le fichier de log apr√®s {max_retries} tentatives"
                )
                # Red√©marrage forc√© du monitoring
                time.sleep(30)
                return False
            return False

        # Test d'acc√®s en lecture
        try:
            with open(self.log_path, "r") as test_file:
                last_pos = test_file.seek(0, 2)  # Se positionne √† la fin
                logger.info(f"‚úÖ Fichier de log accessible, taille: {last_pos} bytes")
        except Exception as e:
            logger.error(f"‚ùå Impossible de lire le fichier de log: {e}")
            return False

        return True

    def _periodic_scan_thread(self):
        """Thread d√©di√© au scan initial uniquement"""
        try:
            # Attente initiale pour laisser le syst√®me d√©marrer
            time.sleep(5)  # R√©duit de 20s √† 5s

            # Un seul scan complet au d√©marrage
            logger.info("üîÑ Scan initial des cha√Ænes...")
            self.scan_channels(force=True)

            # Configuration unique de l'observateur ready_to_stream
            self._setup_ready_observer()

            # Ensuite, on bloque jusqu'√† l'arr√™t
            self.scan_thread_stop.wait()

        except Exception as e:
            logger.error(f"‚ùå Erreur dans le thread de scan: {e}")

        logger.info("üõë Thread de scan arr√™t√©")

    def _monitor_log_file(self):
        """Lit et traite le fichier de log ligne par ligne"""
        with open(self.log_path, "r") as f:
            # Se positionne √† la fin du fichier
            f.seek(0, 2)

            # Log pour debug
            logger.info(f"üëÅÔ∏è Monitoring actif sur {self.log_path}")

            last_activity_time = time.time()
            last_heartbeat_time = time.time()
            last_cleanup_time = time.time()

            while True:
                line = f.readline().strip()
                current_time = time.time()

                # V√©rifications p√©riodiques
                if self._handle_periodic_tasks(
                    current_time,
                    last_cleanup_time,
                    last_heartbeat_time,
                    last_activity_time,
                    f,
                ):
                    last_cleanup_time = current_time
                    last_heartbeat_time = current_time

                # Si pas de nouvelle ligne, attendre
                if not line:
                    # V√©rifier l'inactivit√© prolong√©e
                    if current_time - last_activity_time > 300:  # 5 minutes
                        f.seek(max(0, f.tell() - 10000))  # Retour en arri√®re de 10Ko
                        last_activity_time = current_time
                        logger.warning(
                            f"‚ö†Ô∏è Pas d'activit√© depuis 5 minutes, relecture forc√©e des derni√®res lignes"
                        )

                    time.sleep(0.1)  # R√©duit la charge CPU
                    continue

                # Une ligne a √©t√© lue, mise √† jour du temps d'activit√©
                last_activity_time = current_time

                # Traiter la ligne
                self._process_log_line(line)

    def process_client_log_lines(self):
        """Traite les nouvelles lignes ajout√©es au fichier de log nginx"""
        try:
            # V√©rification de l'existence du fichier
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log introuvable: {self.log_path}")
                return False

            # Initialisation de la position si c'est la premi√®re ex√©cution
            if not hasattr(self, "last_position"):
                # On se met √† la fin du fichier pour ne traiter que les nouvelles lignes
                with open(self.log_path, "r") as f:
                    f.seek(0, 2)  # Positionnement √† la fin
                    self.last_position = f.tell()
                return True

            file_size = os.path.getsize(self.log_path)

            # Si le fichier a √©t√© rotat√© (taille plus petite qu'avant)
            if file_size < self.last_position:
                logger.warning(f"‚ö†Ô∏è D√©tection rotation log: {self.log_path}")
                self.last_position = 0  # On repart du d√©but

            # Lecture des nouvelles lignes
            with open(self.log_path, "r") as f:
                f.seek(self.last_position)
                new_lines = f.readlines()

                # Mise √† jour de la position
                self.last_position = f.tell()

                if not new_lines:
                    return True  # Pas de nouvelles lignes, tout est ok

                # Traitement des nouvelles lignes
                for line in new_lines:
                    if not line.strip():
                        continue

                    # Traiter la ligne avec la nouvelle structure
                    self._process_log_line(line.strip())

                return True

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement nouvelles lignes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _apply_pending_updates(self):
        """Applique les mises √† jour en attente pour √©viter les doublons"""
        if not hasattr(self, "modified_channels") or not self.modified_channels:
            return

        current_time = time.time()

        # Pour √©viter les mises √† jour trop fr√©quentes
        if hasattr(self, "last_update_time"):
            elapsed = current_time - self.last_update_time
            if elapsed < 1:  # Au moins 1 seconde entre les mises √† jour (r√©duit de 2 √† 1)
                return

        channels_updated = 0

        # V√©rifier √©galement les cha√Ænes avec des watchers actifs via TimeTracker
        all_channels_to_update = set(self.modified_channels)
        
        # Ajouter toutes les cha√Ænes avec des watchers actifs dans TimeTracker
        if hasattr(self.time_tracker, "_active_segments"):
            for channel in self.time_tracker._active_segments:
                if channel and channel != "master_playlist":
                    all_channels_to_update.add(channel)

        with self.lock:
            for channel in list(all_channels_to_update):
                # IMPORTANT: Ignorer la playlist principale
                if channel == "master_playlist":
                    continue

                # Calcule les watchers actifs pour cette cha√Æne
                active_ips = set()

                # M√©thode 1: via TimeTracker (plus fiable)
                active_ips = self.time_tracker.get_active_watchers(channel)
                
                # M√©thode 2: via self.watchers en backup
                if not active_ips:
                    for ip, data in self.watchers.items():
                        if (data.get("current_channel") == channel and 
                            current_time - data.get("last_activity", 0) < self.time_tracker.WATCHER_INACTIVITY_TIMEOUT):
                            active_ips.add(ip)
                
                # Nombre de watchers pour cette cha√Æne
                count = len(active_ips)

                # √âvite les logs si aucun changement r√©el
                old_count = self.get_channel_watchers(channel)
                if count != old_count or count > 0:  # Toujours mettre √† jour si count > 0
                    logger.info(
                        f"[{channel}] üëÅÔ∏è MAJ watchers: {count} actifs - {list(active_ips)}"
                    )
                    if self.update_watchers:
                        self.update_watchers(channel, count, "/hls/")
                        channels_updated += 1
                    else:
                        logger.warning(f"[{channel}] ‚ö†Ô∏è Callback update_watchers non disponible")
                elif old_count > 0 and count == 0:
                    # Si on avait des watchers avant mais plus maintenant, mettre √† jour
                    logger.info(f"[{channel}] üëÅÔ∏è R√©initialisation watchers: {old_count} -> 0")
                    if self.update_watchers:
                        self.update_watchers(channel, 0, "/hls/")
                        channels_updated += 1

            # R√©initialise les cha√Ænes modifi√©es
            self.modified_channels.clear()
            self.last_update_time = current_time

        if channels_updated > 0:
            logger.debug(f"üîÑ {channels_updated} cha√Ænes mises √† jour en mode group√©")

    def _handle_periodic_tasks(
        self,
        current_time,
        last_cleanup_time,
        last_heartbeat_time,
        last_activity_time,
        file_handle,
    ):
        """G√®re les t√¢ches p√©riodiques (nettoyage, heartbeat, v√©rification fichier)"""
        tasks_executed = False

        # Nettoyage p√©riodique des watchers inactifs
        if current_time - last_cleanup_time > 10:  # Tous les 10 secondes
            self._cleanup_loop()
            tasks_executed = True

        # Heartbeat p√©riodique
        if current_time - last_heartbeat_time > 60:  # Toutes les minutes
            active_count = 0
            for ip, data in self.watchers.items():
                if isinstance(data, dict) and "timer" in data:
                    timer = data["timer"]
                    if timer.is_running():
                        active_count += 1
                        
            logger.info(
                f"üíì Heartbeat: {active_count} watchers actifs, {len(self.segments_by_channel)} cha√Ænes en suivi"
            )
            last_heartbeat_time = current_time

            # V√©rification p√©riodique du fichier
            if not self._verify_log_file_integrity(file_handle):
                return False

        return tasks_executed

    def _verify_log_file_integrity(self, file_handle):
        """V√©rifie que le fichier de log est toujours valide"""
        try:
            # V√©rifier que le fichier existe toujours
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log disparu: {self.log_path}")
                return False

            # V√©rifier que le fichier n'a pas √©t√© tronqu√©
            current_pos = file_handle.tell()
            file_size = os.path.getsize(self.log_path)
            if current_pos > file_size:
                logger.error(
                    f"‚ùå Fichier log tronqu√©: position {current_pos}, taille {file_size}"
                )
                return False

            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification fichier log: {e}")
            return False

    def _handle_segment_request(self, channel, ip, line, user_agent):
        """Traite une requ√™te de segment"""
        with self.lock:
            logger.debug(f"[{channel}] üîç Traitement requ√™te segment pour {ip}")
            
            # Mettre √† jour le watcher dans le dictionnaire
            current_time = time.time()
            if ip not in self.watchers:
                self.watchers[ip] = {
                    "last_seen": current_time,
                    "type": "segment",
                    "user_agent": user_agent,
                    "current_channel": channel,
                    "last_activity": current_time
                }
                logger.info(f"üÜï Nouveau watcher d√©tect√©: {ip} sur {channel}")
            else:
                # Mettre √† jour les informations du watcher
                self.watchers[ip]["last_seen"] = current_time
                self.watchers[ip]["type"] = "segment"
                self.watchers[ip]["user_agent"] = user_agent
                self.watchers[ip]["current_channel"] = channel
                self.watchers[ip]["last_activity"] = current_time
            
            # Utiliser le TimeTracker pour g√©rer le segment
            self.time_tracker.handle_segment_request(channel, ip)
            
            # Mettre √† jour le compteur de watchers pour cette cha√Æne
            self._update_channel_watchers_count(channel)

    def _handle_playlist_request(self, channel, ip):
        """Traite une requ√™te de playlist"""
        with self.lock:
            # Mettre √† jour le watcher dans le dictionnaire
            current_time = time.time()
            if ip not in self.watchers:
                self.watchers[ip] = {
                    "last_seen": current_time,
                    "type": "playlist",
                    "current_channel": channel,
                    "last_activity": current_time
                }
                logger.info(f"üÜï Nouveau watcher d√©tect√©: {ip} sur {channel}")
            else:
                # Mettre √† jour les informations du watcher
                self.watchers[ip]["last_seen"] = current_time
                self.watchers[ip]["type"] = "playlist"
                self.watchers[ip]["current_channel"] = channel
                self.watchers[ip]["last_activity"] = current_time
            
            # Utiliser le TimeTracker pour g√©rer la playlist
            self.time_tracker.handle_playlist_request(channel, ip)
            
            # Mettre √† jour le compteur de watchers pour cette cha√Æne
            self._update_channel_watchers_count(channel)

    def _update_channel_watchers_count(self, channel):
        """Met √† jour le compteur de watchers pour une cha√Æne"""
        try:
            # Compter les watchers actifs pour cette cha√Æne
            active_watchers = set()
            current_time = time.time()
            
            # M√©thode 1: Utiliser TimeTracker (prioritaire et plus fiable)
            active_watchers = self.time_tracker.get_active_watchers(channel)
            
            # M√©thode 2: Si TimeTracker n'a pas de watchers, utiliser notre dictionnaire local
            if not active_watchers:
                for ip, data in self.watchers.items():
                    # V√©rifier si l'IP est en cours de suppression dans le buffer
                    if hasattr(self.time_tracker, 'is_being_removed') and self.time_tracker.is_being_removed(ip):
                        logger.debug(f"[{channel}] üïí Watcher {ip} dans le buffer de suppression, mais toujours pris en compte")
                        if data.get("current_channel") == channel:
                            active_watchers.add(ip)
                        continue
                            
                    # Validation stricte de l'IP
                    try:
                        # V√©rifier le format de base
                        ip_pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
                        if not ip or not re.match(ip_pattern, ip):
                            logger.warning(f"‚ö†Ô∏è Format IP invalide ignor√© dans le compteur: {ip}")
                            continue
                            
                        # V√©rifier que chaque partie est un nombre valide
                        ip_parts = ip.split('.')
                        if not all(0 <= int(part) <= 255 for part in ip_parts):
                            logger.warning(f"‚ö†Ô∏è Valeurs IP hors limites ignor√©es dans le compteur: {ip}")
                            continue
                    except ValueError:
                        logger.warning(f"‚ö†Ô∏è IP avec valeurs non num√©riques ignor√©e dans le compteur: {ip}")
                        continue
                    
                    # Utiliser un timeout plus long pour √©viter les suppressions pr√©matur√©es
                    extended_timeout = self.time_tracker.WATCHER_INACTIVITY_TIMEOUT
                    
                    # V√©rifier que le watcher est actif et sur la bonne cha√Æne
                    if (data.get("current_channel") == channel and 
                        current_time - data.get("last_activity", 0) < extended_timeout):
                        active_watchers.add(ip)
                        log_level = "debug" if current_time - data.get("last_activity", 0) > 60 else "info"
                        if log_level == "debug":
                            logger.debug(f"[{channel}] ‚úÖ Watcher actif d√©tect√©: {ip} (derni√®re activit√© il y a {current_time - data.get('last_activity', 0):.1f}s)")
                        elif len(active_watchers) <= 5:  # Limiter les logs info pour √©viter le spam
                            logger.info(f"[{channel}] ‚úÖ Watcher actif d√©tect√©: {ip} (derni√®re activit√© il y a {current_time - data.get('last_activity', 0):.1f}s)")

            # √âviter de mettre √† jour trop fr√©quemment si le compteur n'a pas chang√©
            old_count = self.get_channel_watchers(channel)
            
            # Mettre √† jour seulement si le nombre de watchers a chang√© ou toutes les 60 secondes
            update_interval = getattr(self, "_last_update_time", {}).get(channel, 0)
            force_update = current_time - update_interval > 60
            
            if old_count != len(active_watchers) or force_update:
                # Mettre √† jour le timestamp de derni√®re mise √† jour
                if not hasattr(self, "_last_update_time"):
                    self._last_update_time = {}
                self._last_update_time[channel] = current_time
                
                # Mettre √† jour le compteur dans le manager via le callback
                if self.update_watchers:
                    # Toujours mettre √† jour si on a des watchers actifs
                    if active_watchers:
                        logger.info(f"[{channel}] üë• MAJ compteur: {len(active_watchers)} watchers actifs (ancien: {old_count})")
                        if len(active_watchers) <= 10:  # Limiter la taille du log
                            logger.info(f"[{channel}] üë• IPs actives: {', '.join(active_watchers)}")
                        else:
                            logger.info(f"[{channel}] üë• {len(active_watchers)} IPs actives (trop nombreuses pour log)")
                        self.update_watchers(channel, len(active_watchers), "/hls/")
                    else:
                        # Ne pas remettre √† z√©ro trop facilement
                        if old_count > 0 and force_update:
                            logger.info(f"[{channel}] üë• R√©initialisation compteur: {old_count} -> 0 watchers (timeout)")
                            self.update_watchers(channel, 0, "/hls/")
                
                # Log pour debug
                if active_watchers and len(active_watchers) <= 10:  # Limiter la taille du log
                    logger.debug(f"[{channel}] üë• {len(active_watchers)} watchers actifs: {', '.join(active_watchers)}")
                elif active_watchers:
                    logger.debug(f"[{channel}] üë• {len(active_watchers)} watchers actifs (trop nombreux pour le log)")

        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour compteur watchers pour {channel}: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _prepare_log_file(self):
        """V√©rifie que le fichier de log existe et est accessible"""
        if not os.path.exists(self.log_path):
            logger.error(f"‚ùå Log file introuvable: {self.log_path}")
            return False

        # Test d'acc√®s en lecture
        try:
            with open(self.log_path, "r") as test_file:
                last_pos = test_file.seek(0, 2)  # Se positionne √† la fin
                logger.info(f"‚úÖ Fichier de log accessible, taille: {last_pos} bytes")
                return True
        except Exception as e:
            logger.error(f"‚ùå Impossible de lire le fichier de log: {e}")
            return False

    def _follow_log_file(self):
        """Lit et traite le fichier de log ligne par ligne"""
        with open(self.log_path, "r") as f:
            # Se positionne √† la fin du fichier
            f.seek(0, 2)

            logger.info(f"üëÅÔ∏è Monitoring actif sur {self.log_path}")

            last_activity_time = time.time()
            last_heartbeat_time = time.time()
            last_cleanup_time = time.time()

            while True:
                line = f.readline().strip()
                current_time = time.time()

                # T√¢ches p√©riodiques
                if current_time - last_cleanup_time > 10:
                    self._cleanup_loop()
                    last_cleanup_time = current_time

                if current_time - last_heartbeat_time > 60:
                    logger.info(
                        f"üíì ClientMonitor actif, derni√®re activit√© il y a {current_time - last_activity_time:.1f}s"
                    )
                    last_heartbeat_time = current_time

                    if not self._check_file_integrity(f):
                        break

                # Si pas de nouvelle ligne, attendre
                if not line:
                    # Si inactivit√© prolong√©e, relire du d√©but
                    if current_time - last_activity_time > 300:
                        f.seek(max(0, f.tell() - 10000))
                        last_activity_time = current_time

                    time.sleep(0.1)
                    continue

                # Une ligne a √©t√© lue
                last_activity_time = current_time

                # Traiter la ligne
                self._process_log_line(line)

    def _check_file_integrity(self, file_handle):
        """V√©rifie que le fichier log n'a pas √©t√© tronqu√© ou supprim√©"""
        try:
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log disparu: {self.log_path}")
                return False

            current_pos = file_handle.tell()
            file_size = os.path.getsize(self.log_path)
            if current_pos > file_size:
                logger.error(
                    f"‚ùå Fichier log tronqu√©: position {current_pos}, taille {file_size}"
                )
                return False

            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification fichier log: {e}")
            return False

    def check_log_status(self):
        """V√©rifie l'√©tat du monitoring des logs et effectue des actions correctives si n√©cessaire"""
        try:
            # V√©rifie que le fichier existe
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log nginx introuvable: {self.log_path}")
                return False

            # V√©rifie la taille du fichier
            file_size = os.path.getsize(self.log_path)

            # V√©rifie que la position de lecture est valide
            if hasattr(self, "last_position"):
                if self.last_position > file_size:
                    logger.warning(
                        f"‚ö†Ô∏è Position de lecture ({self.last_position}) > taille du fichier ({file_size})"
                    )
                    self.last_position = 0
                    logger.info("üîÑ R√©initialisation de la position de lecture")

                # V√©rifie si de nouvelles donn√©es ont √©t√© ajout√©es depuis la derni√®re lecture
                if file_size > self.last_position:
                    diff = file_size - self.last_position
                    logger.info(
                        f"üìä {diff} octets de nouveaux logs depuis la derni√®re lecture"
                    )
                else:
                    logger.info(f"‚ÑπÔ∏è Pas de nouveaux logs depuis la derni√®re lecture")

            # Tente de lire quelques lignes pour v√©rifier que le fichier est accessible
            try:
                with open(self.log_path, "r") as f:
                    f.seek(max(0, file_size - 1000))  # Lire les 1000 derniers octets
                    last_lines = f.readlines()
                    logger.info(
                        f"‚úÖ Lecture r√©ussie, {len(last_lines)} lignes r√©cup√©r√©es"
                    )

                    # Analyse des derni√®res lignes pour v√©rifier qu'elles contiennent des requ√™tes HLS
                    hls_requests = sum(1 for line in last_lines if "/hls/" in line)
                    if hls_requests == 0 and len(last_lines) > 0:
                        logger.warning(
                            "‚ö†Ô∏è Aucune requ√™te HLS dans les derni√®res lignes du log!"
                        )
                    else:
                        logger.info(
                            f"‚úÖ {hls_requests}/{len(last_lines)} requ√™tes HLS d√©tect√©es"
                        )

                    return True

            except Exception as e:
                logger.error(f"‚ùå Erreur lecture fichier log: {e}")
                return False

        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification logs: {e}")
            return False

    def run_client_monitor(self):
        """M√©thode principale qui suit le fichier de log nginx"""
        logger.info("üîÑ D√©marrage du suivi des logs nginx")
        
        # Augmenter le d√©lai avant de consid√©rer un watcher comme inactif
        # Utiliser les m√™mes timeouts que le TimeTracker pour coh√©rence
        self.SEGMENT_TIMEOUT = self.time_tracker.SEGMENT_TIMEOUT  # 5 minutes (300 secondes)
        self.PLAYLIST_TIMEOUT = self.time_tracker.PLAYLIST_TIMEOUT  # 5 minutes (300 secondes)
        self.WATCHER_INACTIVITY_TIMEOUT = self.time_tracker.WATCHER_INACTIVITY_TIMEOUT  # 10 minutes (600 secondes)
        
        logger.info(f"‚è±Ô∏è Timeouts reconfigur√©s - SEGMENT_TIMEOUT={self.SEGMENT_TIMEOUT}s, PLAYLIST_TIMEOUT={self.PLAYLIST_TIMEOUT}s, INACTIVE_TIMEOUT={self.WATCHER_INACTIVITY_TIMEOUT}s")
        
        # Initialiser le suivi des cha√Ænes modifi√©es
        self.modified_channels = set()
        self.last_update_time = time.time()
        
        while not self.stop_event.is_set():
            try:
                # V√©rifier que le fichier de log existe
                if not os.path.exists(self.log_path):
                    logger.error(f"‚ùå Fichier de log introuvable: {self.log_path}")
                    time.sleep(5)
                    continue

                # Ouvrir et suivre le fichier
                with open(self.log_path, 'r') as f:
                    # Aller √† la fin du fichier
                    f.seek(0, 2)
                    
                    while not self.stop_event.is_set():
                        line = f.readline()
                        if not line:
                            time.sleep(0.1)  # Petite pause pour ne pas surcharger le CPU
                            
                            # Appliquer r√©guli√®rement les mises √† jour en attente
                            self._apply_pending_updates()
                            continue
                            
                        # Traiter la ligne
                        if "/hls/" in line:
                            try:
                                # Journaliser chaque ligne trait√©e en d√©tail si elle contient un motif int√©ressant
                                if ".ts" in line or ".m3u8" in line:
                                    logger.info(f"üîç TRAITEMENT_HLS: {line.strip()[:100]}...")
                                
                                ip, channel, request_type, is_valid, user_agent = self._parse_access_log(line)
                                if channel and ip and is_valid:
                                    logger.info(f"‚úÖ LIGNE VALIDE: ip={ip}, channel={channel}, type={request_type}")
                                    
                                    if request_type == "segment":
                                        self._handle_segment_request(channel, ip, line, user_agent)
                                    elif request_type == "playlist":
                                        self._handle_playlist_request(channel, ip)
                                    
                                    # Ajouter la cha√Æne √† la liste des cha√Ænes modifi√©es
                                    if channel:
                                        self.modified_channels.add(channel)
                                    
                                    # Log pour le debug
                                    logger.debug(f"üìù Trait√©: {request_type} pour {channel} par {ip}")
                                else:
                                    # Si la ligne contient /hls/ mais n'est pas valide, logger pour debug
                                    logger.warning(f"‚ö†Ô∏è Ligne HLS non valide: ip={ip}, channel={channel}, valid={is_valid}")
                            except Exception as e:
                                logger.error(f"‚ùå Erreur traitement ligne: {e}")
                                logger.error(f"LIGNE: {line[:200]}")

            except Exception as e:
                logger.error(f"‚ùå Erreur suivi logs: {e}")
                import traceback
                logger.error(traceback.format_exc())
                time.sleep(5)  # Pause avant de r√©essayer