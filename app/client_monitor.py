import os
import time
import threading
from pathlib import Path
from config import logger
from typing import Dict, Tuple, List, Set, Optional
import re
from log_utils import parse_access_log
from time_tracker import TimeTracker
import json

os.environ['TZ'] = 'Europe/Paris'
time.tzset()  # Applique le changement

class ClientMonitor(threading.Thread):

    def __init__(self, log_path, update_watchers_callback, manager, stats_collector=None):
        super().__init__(daemon=True)
        self.log_path = log_path

        # Callback pour mettre √† jour les watchers dans le manager
        self.update_watchers = update_watchers_callback
        # Manager pour acc√©der aux segments et aux canaux
        self.manager = manager
        # StatsCollector pour les statistiques
        self.stats_collector = stats_collector

        # Initialiser le TimeTracker
        self.time_tracker = TimeTracker(stats_collector)

        # dictionnaire pour stocker les watchers actifs (utilis√© principalement pour le user_agent)
        self.watchers: Dict[str, Dict] = {}  # {ip: {"last_seen", "type", "user_agent", "current_channel", "last_activity"}}

        # dictionnaire pour stocker les segments demand√©s par chaque canal (Est-ce encore utilis√©?)
        self.segments_by_channel = {}  # {channel: {segment_id: last_requested_time}}

        # *** ADDED: Initialize _channel_watchers ***
        self._channel_watchers: Dict[str, int] = {} # {channel: count}
        # *** END ADDED ***

        # Pour √©viter les acc√®s concurrents
        self.lock = threading.Lock()

        # √âv√©nement pour l'arr√™t propre du thread de nettoyage (peut-√™tre plus n√©cessaire?)
        self.stop_event = threading.Event()

        # Initialisation des attributs de nettoyage (peut-√™tre plus n√©cessaire?)
        self.last_cleanup_log = time.time()
        # self.last_cleanup_time = time.time()
        # self.cleanup_interval = 30

        # logger.info(f"‚è±Ô∏è Timeouts configur√©s - Watcher inactif: {self.WATCHER_INACTIVITY_TIMEOUT}s, Segment: {self.SEGMENT_TIMEOUT}s, Playlist: {self.PLAYLIST_TIMEOUT}s")
        logger.info("‚è±Ô∏è Timeouts de watchers maintenant g√©r√©s par TimeTracker.")

        # Thread de nettoyage - D√âSACTIV√â
        # self.cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        # self.cleanup_thread.start()
        
        # Pour le logging p√©riodique (d√©plac√© dans la boucle principale?)
        # self.last_cleanup_log = time.time()

    def run(self):
        """M√©thode principale du thread"""
        logger.info("üöÄ D√©marrage du ClientMonitor")
        self.run_client_monitor() # Assurez-vous que run_client_monitor g√®re le nouveau logging p√©riodique si n√©cessaire

    def _cleanup_loop(self):
        """Nettoie les watchers inactifs et v√©rifie l'√©tat des logs - D√âSACTIV√â"""
        logger.info("üßπ Boucle de nettoyage interne de ClientMonitor d√©sactiv√©e (g√©r√©e par TimeTracker).")
        return # Ne rien faire
        # while not self.stop_event.is_set():
        #     try:
        #         # Utiliser le TimeTracker pour le nettoyage
        #         self.time_tracker.cleanup_inactive_watchers()
        #         
        #         # Forcer la mise √† jour des compteurs pour toutes les cha√Ænes (REDONDANT?)
        #         # ... (code existant)
        #         
        #         # Log p√©riodique des watchers actifs (REDONDANT?)
        #         # ... (code existant)
        #         
        #         time.sleep(5)  # V√©rification toutes les 5s
        #         
        #     except Exception as e:
        #         logger.error(f"‚ùå Erreur cleanup_loop: {e}")
        #         time.sleep(5)

    def _print_channels_summary(self):
        """Affiche un r√©sum√© des cha√Ænes et de leurs watchers"""
        try:
            active_channels = {}
            for ip, watcher in self.watchers.items():
                channel = watcher.get("current_channel", "unknown")
                if channel not in active_channels:
                    active_channels[channel] = set()
                active_channels[channel].add(ip)
            
            if active_channels:
                logger.info("üìä R√©sum√© des cha√Ænes:")
                for channel, watchers in active_channels.items():
                    logger.info(f"[{channel}] üë• {len(watchers)} watchers: {', '.join(watchers)}")
            else:
                logger.info("üìä Aucun watcher actif")
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©sum√© cha√Ænes: {e}")

    def get_channel_watchers(self, channel):
        """R√©cup√®re le nombre actuel de watchers pour une cha√Æne"""
        if hasattr(self.manager, "channels") and channel in self.manager.channels:
            return getattr(self.manager.channels[channel], "watchers_count", 0)
        return 0

    def _parse_access_log(self, line):
        """Version harmonis√©e qui utilise la fonction utilitaire"""
        return parse_access_log(line)

    def _process_log_line(self, line):
        """Traite une ligne de log nginx"""
        try:
            # Parse la ligne
            ip, channel, request_type, is_valid, user_agent = self._parse_access_log(line)

            # Log plus d√©taill√© pour le diagnostic
            if is_valid and channel and "/hls/" in line:
                logger.info(f"üìù TRAITEMENT LIGNE: ip={ip}, channel={channel}, type={request_type}, valid={is_valid}")

            # Si la ligne n'est pas valide ou pas de channel, on ignore
            if not is_valid or not channel:
                if "/hls/" in line and not is_valid:
                    logger.warning(f"‚ö†Ô∏è Ligne non valide ignor√©e: {line[:100]}...")
                return

            # Si c'est la playlist principale, on ignore
            if channel == "master_playlist":
                return

            # V√©rifier que la cha√Æne existe dans le manager
            if not hasattr(self.manager, "channels"):
                logger.error("‚ùå Le manager n'a pas d'attribut 'channels'")
                return

            # Log des cha√Ænes disponibles
            logger.debug(f"üìã Cha√Ænes disponibles: {list(self.manager.channels.keys())}")
            logger.debug(f"üîç Recherche de la cha√Æne: {channel}")

            if channel not in self.manager.channels:
                logger.debug(f"‚ö†Ô∏è Cha√Æne {channel} non trouv√©e dans le manager, ignor√©e")
                return

            # Log d√©taill√© de la requ√™te
            logger.debug(f"üìù Requ√™te d√©taill√©e: IP={ip}, Channel={channel}, Type={request_type}, User-Agent={user_agent}")

            # Mise √† jour du watcher avec la nouvelle structure
            self._update_watcher(ip, channel, request_type, user_agent, line)

            # Si c'est une requ√™te de playlist, on force une mise √† jour des watchers
            if request_type == "playlist":
                logger.debug(f"üîÑ Requ√™te playlist d√©tect√©e pour {channel} par {ip}")
                self._update_channel_watchers_count(channel)

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement ligne log: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _update_watcher(self, ip, channel, request_type, user_agent, line):
        """Met √† jour les informations d'un watcher sp√©cifique"""
        with self.lock:
            current_time = time.time()
            
            # Si le watcher n'existe pas, cr√©er un nouveau minuteur
            if ip not in self.watchers:
                self.watchers[ip] = {
                    "last_seen": current_time,
                    "type": request_type,
                    "user_agent": user_agent,
                    "current_channel": channel,
                    "last_activity": current_time
                }
                logger.info(f"üÜï Nouveau watcher d√©tect√©: {ip} sur {channel}")
                # Forcer une mise √† jour du compteur de watchers
                self._update_channel_watchers_count(channel)
            else:
                # V√©rifier si la cha√Æne a chang√©
                old_channel = self.watchers[ip].get("current_channel")
                if old_channel != channel:
                    logger.info(f"üîÑ Changement de cha√Æne pour {ip}: {old_channel} -> {channel}")
                    # Notifier le StatsCollector du changement de cha√Æne
                    if self.stats_collector:
                        self.stats_collector.handle_channel_change(ip, old_channel, channel)
                    self.watchers[ip]["current_channel"] = channel
                    
                    # Mettre √† jour les compteurs pour l'ancienne et la nouvelle cha√Æne
                    if old_channel:
                        self._update_channel_watchers_count(old_channel)
                    self._update_channel_watchers_count(channel)
                else:
                    # M√™me cha√Æne, v√©rifier le temps √©coul√© depuis la derni√®re requ√™te
                    last_seen = self.watchers[ip].get("last_seen", 0)
                    if current_time - last_seen < 0.5 and request_type == "playlist":  # R√©duit de 1.0 √† 0.5 secondes
                        # Ignorer les mises √† jour trop rapproch√©es pour √©viter le spam
                        logger.debug(f"Ignor√© mise √† jour rapproch√©e pour {ip} sur {channel} (interval: {current_time - last_seen:.2f}s)")
                        # On met quand m√™me √† jour last_activity pour garder le watcher actif
                        self.watchers[ip]["last_activity"] = current_time
                        return

                # Mise √† jour des infos
                self.watchers[ip]["last_seen"] = current_time
                self.watchers[ip]["type"] = request_type
                self.watchers[ip]["user_agent"] = user_agent
                self.watchers[ip]["last_activity"] = current_time

            # D√©l√©guer la collecte des statistiques au StatsCollector
            if self.stats_collector:
                if request_type == "segment":
                    self.stats_collector.handle_segment_request(channel, ip, line, user_agent)
                elif request_type == "playlist":
                    # Pour les playlists, on n'ajoute du temps que si √ßa fait au moins 1 seconde
                    # depuis la derni√®re requ√™te, pour √©viter les doublons
                    last_seen = self.watchers[ip].get("last_seen", 0)
                    if current_time - last_seen >= 1.0:  # R√©duit de 3.0 √† 1.0 secondes
                        elapsed = min(current_time - last_seen, 5.0)
                        self.stats_collector.handle_playlist_request(channel, ip, elapsed, user_agent)

            # Si c'est un segment ou une playlist, forcer la mise √† jour du compteur
            if request_type in ["segment", "playlist"]:
                # >>> COMMENT OUT THIS CALL - Updates are now pushed via _push_tracker_status_to_manager
                # self._update_channel_watchers_count(channel)
                logger.debug(f"[_update_watcher] Skipping redundant call to _update_channel_watchers_count for {channel}")
                pass # Explicitly do nothing here now

    def _check_log_file_exists(self, retry_count, max_retries):
        """V√©rifie si le fichier de log existe et est accessible"""
        if not os.path.exists(self.log_path):
            logger.error(f"‚ùå Log file introuvable: {self.log_path}")

            # Abandon apr√®s trop d'essais
            if retry_count > max_retries:
                logger.critical(
                    f"‚ùå Impossible de trouver le fichier de log apr√®s {max_retries} tentatives"
                )
                # Red√©marrage forc√© du monitoring
                time.sleep(30)
                return False
            return False

        # Test d'acc√®s en lecture
        try:
            with open(self.log_path, "r") as test_file:
                last_pos = test_file.seek(0, 2)  # Se positionne √† la fin
                logger.info(f"‚úÖ Fichier de log accessible, taille: {last_pos} bytes")
        except Exception as e:
            logger.error(f"‚ùå Impossible de lire le fichier de log: {e}")
            return False

        return True

    def _periodic_scan_thread(self):
        """Thread d√©di√© au scan initial uniquement"""
        try:
            # Attente initiale pour laisser le syst√®me d√©marrer
            time.sleep(5)  # R√©duit de 20s √† 5s

            # Un seul scan complet au d√©marrage
            logger.info("üîÑ Scan initial des cha√Ænes...")
            self.scan_channels(force=True)

            # Configuration unique de l'observateur ready_to_stream
            self._setup_ready_observer()

            # Ensuite, on bloque jusqu'√† l'arr√™t
            self.scan_thread_stop.wait()

        except Exception as e:
            logger.error(f"‚ùå Erreur dans le thread de scan: {e}")

        logger.info("üõë Thread de scan arr√™t√©")

    def _monitor_log_file(self):
        """Lit et traite le fichier de log ligne par ligne"""
        with open(self.log_path, "r") as f:
            # Se positionne √† la fin du fichier
            f.seek(0, 2)

            # Log pour debug
            logger.info(f"üëÅÔ∏è Monitoring actif sur {self.log_path}")

            last_activity_time = time.time()
            last_heartbeat_time = time.time()
            last_cleanup_time = time.time()

            while True:
                line = f.readline().strip()
                current_time = time.time()

                # V√©rifications p√©riodiques
                if self._handle_periodic_tasks(
                    current_time,
                    last_cleanup_time,
                    last_heartbeat_time,
                    last_activity_time,
                    f,
                ):
                    last_cleanup_time = current_time
                    last_heartbeat_time = current_time

                # Si pas de nouvelle ligne, attendre
                if not line:
                    # V√©rifier l'inactivit√© prolong√©e
                    if current_time - last_activity_time > 300:  # 5 minutes
                        f.seek(max(0, f.tell() - 10000))  # Retour en arri√®re de 10Ko
                        last_activity_time = current_time
                        logger.warning(
                            f"‚ö†Ô∏è Pas d'activit√© depuis 5 minutes, relecture forc√©e des derni√®res lignes"
                        )

                    time.sleep(0.1)  # R√©duit la charge CPU
                    continue

                # Une ligne a √©t√© lue, mise √† jour du temps d'activit√©
                last_activity_time = current_time

                # Traiter la ligne
                self._process_log_line(line)

    def process_client_log_lines(self):
        """Traite les nouvelles lignes ajout√©es au fichier de log nginx"""
        try:
            # V√©rification de l'existence du fichier
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log introuvable: {self.log_path}")
                return False

            # Initialisation de la position si c'est la premi√®re ex√©cution
            if not hasattr(self, "last_position"):
                # On se met √† la fin du fichier pour ne traiter que les nouvelles lignes
                with open(self.log_path, "r") as f:
                    f.seek(0, 2)  # Positionnement √† la fin
                    self.last_position = f.tell()
                return True

            file_size = os.path.getsize(self.log_path)

            # Si le fichier a √©t√© rotat√© (taille plus petite qu'avant)
            if file_size < self.last_position:
                logger.warning(f"‚ö†Ô∏è D√©tection rotation log: {self.log_path}")
                self.last_position = 0  # On repart du d√©but

            # Lecture des nouvelles lignes
            with open(self.log_path, "r") as f:
                f.seek(self.last_position)
                new_lines = f.readlines()

                # Mise √† jour de la position
                self.last_position = f.tell()

                if not new_lines:
                    return True  # Pas de nouvelles lignes, tout est ok

                # Traitement des nouvelles lignes
                for line in new_lines:
                    if not line.strip():
                        continue

                    # Traiter la ligne avec la nouvelle structure
                    self._process_log_line(line.strip())

                return True

        except Exception as e:
            logger.error(f"‚ùå Erreur traitement nouvelles lignes: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _apply_pending_updates(self):
        """Applique les mises √† jour en attente pour √©viter les doublons"""
        if not hasattr(self, "modified_channels") or not self.modified_channels:
            return

        current_time = time.time()

        # Pour √©viter les mises √† jour trop fr√©quentes
        if hasattr(self, "last_update_time"):
            elapsed = current_time - self.last_update_time
            if elapsed < 1:  # Au moins 1 seconde entre les mises √† jour (r√©duit de 2 √† 1)
                return

        channels_updated = 0

        # V√©rifier √©galement les cha√Ænes avec des watchers actifs via TimeTracker
        all_channels_to_update = set(self.modified_channels)
        
        # Ajouter toutes les cha√Ænes avec des watchers actifs dans TimeTracker
        if hasattr(self.time_tracker, "_active_segments"):
            for channel in self.time_tracker._active_segments:
                if channel and channel != "master_playlist":
                    all_channels_to_update.add(channel)

        with self.lock:
            for channel_to_update in list(all_channels_to_update):
                # IMPORTANT: Ignorer la playlist principale
                if channel_to_update == "master_playlist":
                    continue

                # Calcule les watchers actifs pour cette cha√Æne via TimeTracker (source unique de v√©rit√©)
                active_ips = self.time_tracker.get_active_watchers(channel_to_update, include_buffer=True)
                count = len(active_ips)

                # Obtenir l'ancien compte depuis le manager
                old_count = self.get_channel_watchers(channel_to_update)

                # D√©cider si une mise √† jour est n√©cessaire
                needs_update = (count != old_count)

                if needs_update:
                    # Loguer le changement d√©tect√©
                    active_ips_list = sorted(list(active_ips)) # Already have the list here
                    if old_count == 0 and count > 0: # Devenu actif
                        logger.info(f"[{channel_to_update}] ‚úÖ Watchers ACTIV√âS: {count}")
                        if len(active_ips_list) <= 10:
                             logger.info(f"[{channel_to_update}] üë• IPs actives: {', '.join(active_ips_list)}")
                        else:
                             logger.info(f"[{channel_to_update}] üë• {count} IPs actives (trop nombreuses pour log)")
                    elif old_count > 0 and count == 0: # Devenu inactif
                        logger.info(f"[{channel_to_update}] üÖæÔ∏è Watchers D√âSACTIV√âS (pr√©c√©dent: {old_count})")
                    else: # Changement de compte (X -> Y, ambos > 0)
                        logger.info(f"[{channel_to_update}] üîÑ Changement watchers: {old_count} ‚Üí {count}")
                        if len(active_ips_list) <= 10:
                             logger.info(f"[{channel_to_update}] üë• IPs actives: {', '.join(active_ips_list)}")
                        else:
                             logger.info(f"[{channel_to_update}] üë• {count} IPs actives (trop nombreuses pour log)")

                    # Effectuer la mise √† jour via le callback
                    if self.update_watchers:
                        # MODIFIED: Pass both count AND the list of IPs
                        self.update_watchers(channel_to_update, count, active_ips_list, "/hls/") 
                        channels_updated += 1
                    else:
                        logger.warning(f"[{channel_to_update}] ‚ö†Ô∏è Callback update_watchers non disponible")

                # Log p√©riodique (optionnel, gardons le en DEBUG pour l'instant)
                # elif count > 0 and (current_time - self.last_update_time > 60):

            # R√©initialise les cha√Ænes modifi√©es
            self.modified_channels.clear()
            self.last_update_time = current_time

        if channels_updated > 0:
            logger.debug(f"üîÑ {channels_updated} cha√Ænes mises √† jour en mode group√©")

    def _handle_periodic_tasks(
        self,
        current_time,
        last_cleanup_time,
        last_heartbeat_time,
        last_activity_time,
        file_handle,
    ):
        """G√®re les t√¢ches p√©riodiques (nettoyage, heartbeat, v√©rification fichier)"""
        tasks_executed = False

        # Nettoyage p√©riodique des watchers inactifs
        if current_time - last_cleanup_time > 10:  # Tous les 10 secondes
            self._cleanup_loop()
            tasks_executed = True

        # Heartbeat p√©riodique
        if current_time - last_heartbeat_time > 60:  # Toutes les minutes
            active_count = 0
            for ip, data in self.watchers.items():
                if isinstance(data, dict) and "timer" in data:
                    timer = data["timer"]
                    if timer.is_running():
                        active_count += 1
                        
            logger.info(
                f"üíì Heartbeat: {active_count} watchers actifs, {len(self.segments_by_channel)} cha√Ænes en suivi"
            )
            last_heartbeat_time = current_time

            # V√©rification p√©riodique du fichier
            if not self._verify_log_file_integrity(file_handle):
                return False

        return tasks_executed

    def _verify_log_file_integrity(self, file_handle):
        """V√©rifie que le fichier de log est toujours valide"""
        try:
            # V√©rifier que le fichier existe toujours
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log disparu: {self.log_path}")
                return False

            # V√©rifier que le fichier n'a pas √©t√© tronqu√©
            current_pos = file_handle.tell()
            file_size = os.path.getsize(self.log_path)
            if current_pos > file_size:
                logger.error(
                    f"‚ùå Fichier log tronqu√©: position {current_pos}, taille {file_size}"
                )
                return False

            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification fichier log: {e}")
            return False

    def _handle_segment_request(self, channel, ip, line, user_agent):
        """Traite une requ√™te de segment"""
        with self.lock:
            logger.debug(f"[{channel}] üîç Traitement requ√™te segment pour {ip}")
            
            # Mettre √† jour le watcher dans le dictionnaire
            current_time = time.time()
            if ip not in self.watchers:
                self.watchers[ip] = {
                    "last_seen": current_time,
                    "type": "segment",
                    "user_agent": user_agent,
                    "current_channel": channel,
                    "last_activity": current_time
                }
                logger.info(f"üÜï Nouveau watcher d√©tect√©: {ip} sur {channel}")
            else:
                # Mettre √† jour les informations du watcher
                self.watchers[ip]["last_seen"] = current_time
                self.watchers[ip]["type"] = "segment"
                self.watchers[ip]["user_agent"] = user_agent
                self.watchers[ip]["current_channel"] = channel
                self.watchers[ip]["last_activity"] = current_time
            
            # *** MODIFIED: Record activity with calculated expiry based on segment duration ***
            try:
                # Assume manager provides the segment duration (hls_time) used by FFmpeg for this channel
                segment_duration = self.manager.get_channel_segment_duration(channel) 

                if segment_duration and isinstance(segment_duration, (int, float)) and segment_duration > 0:
                    # Calculate expiry: segment duration + 20% buffer
                    expiry_duration = segment_duration * 1.2 
                    logger.debug(f"[{channel}] Calculated expiry for {ip}: {expiry_duration:.2f}s (segment: {segment_duration}s)")
                    # Call TimeTracker with the calculated expiry duration
                    # IMPORTANT: TimeTracker.record_activity must be modified to accept expiry_duration
                    self.time_tracker.record_activity(ip, channel, expiry_duration=expiry_duration)
                else:
                    # Fallback if duration is invalid or not found
                    if segment_duration is None:
                         logger.warning(f"[{channel}] Segment duration not found via manager for {ip}. Falling back to default TimeTracker timeout.")
                    else:
                         logger.warning(f"[{channel}] Invalid segment duration ({segment_duration}) from manager for {ip}. Falling back to default TimeTracker timeout.")
                    self.time_tracker.record_activity(ip, channel) # Fallback call

            except AttributeError:
                 logger.error(f"[{channel}] Manager missing 'get_channel_segment_duration' method. Cannot calculate expiry for {ip}. Falling back.")
                 self.time_tracker.record_activity(ip, channel) # Fallback call
            except Exception as e:
                 logger.error(f"[{channel}] Error getting segment duration or recording activity for {ip}: {e}")
                 self.time_tracker.record_activity(ip, channel) # Fallback call
            # *** END MODIFIED ***

            # Obtenir les watchers actifs et mettre √† jour le statut
            try:
                active_watchers = self.time_tracker.get_active_watchers(channel, include_buffer=True)
                calculated_count = len(active_watchers)
                
                # Obtenir le compte pr√©c√©dent pour comparaison
                old_count = self.get_channel_watchers(channel)
                
                # Mettre √† jour seulement si le nombre a chang√© ou toutes les 60 secondes
                last_update_ts = getattr(self, "_last_update_time", {}).get(channel, 0)
                force_update = current_time - last_update_ts > 60

                if old_count != calculated_count or force_update:
                    # Mettre √† jour le timestamp de la derni√®re MAJ
                    if not hasattr(self, "_last_update_time"):
                        self._last_update_time = {}
                    self._last_update_time[channel] = current_time
                    
                    # Log et mise √† jour via callback
                    if self.update_watchers:
                        # Log based on the type of change
                        if calculated_count != old_count:
                            if old_count == 0 and calculated_count > 0: # Became active
                                logger.info(f"[{channel}] üëÅÔ∏è Watchers devenus actifs: {calculated_count}")
                                if len(active_watchers) <= 10:
                                     logger.info(f"[{channel}] üë• IPs actives (TimeTracker): {', '.join(sorted(list(active_watchers)))}")
                                else:
                                     logger.info(f"[{channel}] üë• {calculated_count} IPs actives (TimeTracker) - trop nombreuses pour log")
                            elif old_count > 0 and calculated_count == 0: # Became inactive
                                logger.info(f"[{channel}] üëÅÔ∏è Watchers tomb√©s √† 0 (pr√©c√©dent: {old_count})")
                            else: # Count changed but still > 0
                                logger.debug(f"[{channel}] üëÅÔ∏è Changement nombre watchers: {old_count} ‚Üí {calculated_count}")
                        elif force_update and calculated_count > 0: # Periodic update, no change
                            logger.debug(f"[{channel}] ‚è±Ô∏è MAJ p√©riodique: {calculated_count} watchers actifs (TimeTracker)")

                        # Envoyer la mise √† jour avec la liste des watchers actifs
                        self.update_watchers(channel, calculated_count, list(active_watchers), "/hls/")
                    else:
                        logger.warning(f"[{channel}] ‚ö†Ô∏è Callback update_watchers non disponible pour MAJ {calculated_count} watchers.")

            except Exception as e:
                logger.error(f"‚ùå Erreur mise √† jour compteur watchers pour {channel}: {e}")
                import traceback
                logger.error(traceback.format_exc())

    def _update_channel_watchers_count(self, channel):
        """
        Met √† jour le compteur de watchers pour une cha√Æne en se basant uniquement sur TimeTracker.
        """
        try:
            current_time = time.time()
            
            # Obtenir les watchers actifs (y compris buffer) directement depuis TimeTracker
            active_watchers = self.time_tracker.get_active_watchers(channel, include_buffer=True)
            calculated_count = len(active_watchers)
            
            # Obtenir le compte pr√©c√©dent pour comparaison
            old_count = self.get_channel_watchers(channel)
            
            # Mettre √† jour seulement si le nombre a chang√© ou toutes les 60 secondes
            last_update_ts = getattr(self, "_last_update_time", {}).get(channel, 0)
            force_update = current_time - last_update_ts > 60

            if old_count != calculated_count or force_update:
                # Mettre √† jour le timestamp de la derni√®re MAJ
                if not hasattr(self, "_last_update_time"):
                    self._last_update_time = {}
                self._last_update_time[channel] = current_time
                
                # Log et mise √† jour via callback
                if self.update_watchers:
                    # Log based on the type of change
                    if calculated_count != old_count:
                        if old_count == 0 and calculated_count > 0: # Became active
                            logger.info(f"[{channel}] üëÅÔ∏è Watchers devenus actifs: {calculated_count}")
                            if len(active_watchers) <= 10:
                                 logger.info(f"[{channel}] üë• IPs actives (TimeTracker): {', '.join(sorted(list(active_watchers)))}")
                            else:
                                 logger.info(f"[{channel}] üë• {calculated_count} IPs actives (TimeTracker) - trop nombreuses pour log")
                        elif old_count > 0 and calculated_count == 0: # Became inactive
                            logger.info(f"[{channel}] üëÅÔ∏è Watchers tomb√©s √† 0 (pr√©c√©dent: {old_count})")
                        else: # Count changed but still > 0
                            logger.debug(f"[{channel}] üëÅÔ∏è Changement nombre watchers: {old_count} ‚Üí {calculated_count}")
                    elif force_update and calculated_count > 0: # Periodic update, no change
                        logger.debug(f"[{channel}] ‚è±Ô∏è MAJ p√©riodique: {calculated_count} watchers actifs (TimeTracker)")

                    # Envoyer la mise √† jour avec la liste des watchers actifs
                    self.update_watchers(channel, calculated_count, list(active_watchers), "/hls/")
                else:
                    logger.warning(f"[{channel}] ‚ö†Ô∏è Callback update_watchers non disponible pour MAJ {calculated_count} watchers.")

        except Exception as e:
            logger.error(f"‚ùå Erreur mise √† jour compteur watchers pour {channel}: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _prepare_log_file(self):
        """V√©rifie que le fichier de log existe et est accessible"""
        if not os.path.exists(self.log_path):
            logger.error(f"‚ùå Log file introuvable: {self.log_path}")
            return False

        # Test d'acc√®s en lecture
        try:
            with open(self.log_path, "r") as test_file:
                last_pos = test_file.seek(0, 2)  # Se positionne √† la fin
                logger.info(f"‚úÖ Fichier de log accessible, taille: {last_pos} bytes")
                return True
        except Exception as e:
            logger.error(f"‚ùå Impossible de lire le fichier de log: {e}")
            return False

    def _follow_log_file(self):
        """Lit et traite le fichier de log ligne par ligne"""
        with open(self.log_path, "r") as f:
            # Se positionne √† la fin du fichier
            f.seek(0, 2)

            logger.info(f"üëÅÔ∏è Monitoring actif sur {self.log_path}")

            last_activity_time = time.time()
            last_heartbeat_time = time.time()
            last_cleanup_time = time.time()

            while True:
                line = f.readline().strip()
                current_time = time.time()

                # T√¢ches p√©riodiques
                if current_time - last_cleanup_time > 10:
                    self._cleanup_loop()
                    last_cleanup_time = current_time

                if current_time - last_heartbeat_time > 60:
                    logger.info(
                        f"üíì ClientMonitor actif, derni√®re activit√© il y a {current_time - last_activity_time:.1f}s"
                    )
                    last_heartbeat_time = current_time

                    if not self._check_file_integrity(f):
                        break

                # Si pas de nouvelle ligne, attendre
                if not line:
                    # Si inactivit√© prolong√©e, relire du d√©but
                    if current_time - last_activity_time > 300:
                        f.seek(max(0, f.tell() - 10000))
                        last_activity_time = current_time

                    time.sleep(0.1)
                    continue

                # Une ligne a √©t√© lue
                last_activity_time = current_time

                # Traiter la ligne
                self._process_log_line(line)

    def _check_file_integrity(self, file_handle):
        """V√©rifie que le fichier log n'a pas √©t√© tronqu√© ou supprim√©"""
        try:
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log disparu: {self.log_path}")
                return False

            current_pos = file_handle.tell()
            file_size = os.path.getsize(self.log_path)
            if current_pos > file_size:
                logger.error(
                    f"‚ùå Fichier log tronqu√©: position {current_pos}, taille {file_size}"
                )
                return False

            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification fichier log: {e}")
            return False

    def check_log_status(self):
        """V√©rifie l'√©tat du monitoring des logs et effectue des actions correctives si n√©cessaire"""
        try:
            # V√©rifie que le fichier existe
            if not os.path.exists(self.log_path):
                logger.error(f"‚ùå Fichier log nginx introuvable: {self.log_path}")
                return False

            # V√©rifie la taille du fichier
            file_size = os.path.getsize(self.log_path)

            # V√©rifie que la position de lecture est valide
            if hasattr(self, "last_position"):
                if self.last_position > file_size:
                    logger.warning(
                        f"‚ö†Ô∏è Position de lecture ({self.last_position}) > taille du fichier ({file_size})"
                    )
                    self.last_position = 0
                    logger.info("üîÑ R√©initialisation de la position de lecture")

                # V√©rifie si de nouvelles donn√©es ont √©t√© ajout√©es depuis la derni√®re lecture
                if file_size > self.last_position:
                    diff = file_size - self.last_position
                    logger.info(
                        f"üìä {diff} octets de nouveaux logs depuis la derni√®re lecture"
                    )
                else:
                    logger.info(f"‚ÑπÔ∏è Pas de nouveaux logs depuis la derni√®re lecture")

            # Tente de lire quelques lignes pour v√©rifier que le fichier est accessible
            try:
                with open(self.log_path, "r") as f:
                    f.seek(max(0, file_size - 1000))  # Lire les 1000 derniers octets
                    last_lines = f.readlines()
                    logger.info(
                        f"‚úÖ Lecture r√©ussie, {len(last_lines)} lignes r√©cup√©r√©es"
                    )

                    # Analyse des derni√®res lignes pour v√©rifier qu'elles contiennent des requ√™tes HLS
                    hls_requests = sum(1 for line in last_lines if "/hls/" in line)
                    if hls_requests == 0 and len(last_lines) > 0:
                        logger.warning(
                            "‚ö†Ô∏è Aucune requ√™te HLS dans les derni√®res lignes du log!"
                        )
                    else:
                        logger.info(
                            f"‚úÖ {hls_requests}/{len(last_lines)} requ√™tes HLS d√©tect√©es"
                        )

                    return True

            except Exception as e:
                logger.error(f"‚ùå Erreur lecture fichier log: {e}")
                return False

        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification logs: {e}")
            return False

    def run_client_monitor(self):
        """M√©thode principale qui suit le fichier de log nginx"""
        logger.info("üîÑ D√©marrage du suivi des logs nginx dans ClientMonitor")

        # Enlever les timeouts ici, TimeTracker g√®re cela
        # self.SEGMENT_TIMEOUT = 300
        # self.PLAYLIST_TIMEOUT = 300
        # self.WATCHER_INACTIVITY_TIMEOUT = 600
        logger.info("‚è±Ô∏è Timeouts g√©r√©s par TimeTracker.")
        
        # Add a periodic force update during initialization
        def delayed_force_update():
            # Wait for system to initialize
            time.sleep(20)
            logger.info("üîÑ [INIT] Forcing first status update from TimeTracker")
            self.force_status_update()
            
            # Do one more update after a delay to catch any missed updates
            time.sleep(40)
            logger.info("üîÑ [INIT] Forcing second status update from TimeTracker")
            self.force_status_update()
            
        # Start the delayed update thread
        force_update_thread = threading.Thread(target=delayed_force_update, daemon=True)
        force_update_thread.start()
        logger.info("üîÑ [INIT] Scheduled delayed force updates")

        # Pas besoin de modified_channels avec l'approche simplifi√©e
        # self.modified_channels = set()
        # self.last_update_time = time.time()

        while not self.stop_event.is_set():
            try:
                if not os.path.exists(self.log_path):
                    logger.error(f"‚ùå Fichier de log introuvable: {self.log_path}")
                    time.sleep(5)
                    continue

                with open(self.log_path, 'r') as f:
                    f.seek(0, 2)
                    logger.info(f"üëÅÔ∏è ClientMonitor monitoring {self.log_path}")

                    while not self.stop_event.is_set():
                        line = f.readline()
                        if not line:  # This checks if readline returned an empty string (EOF)
                            time.sleep(0.1)
                            continue

                        # Strip the line after checking if it's None/empty
                        line = line.strip()
                        if not line:  # Skip empty lines after stripping
                            continue

                        if "/hls/" not in line:
                            continue

                        try:
                            # Improved logging to show raw line content with escaping for control chars
                            logger.info(f"---> RAW LINE READ: {repr(line)}")
                            ip, channel, request_type, is_valid, user_agent = self._parse_access_log(line)
                            logger.info(f"---> PARSED: ip={ip}, ch={channel}, type={request_type}, valid={is_valid}")
                            # <--- End Log
                            
                            # Si segment valide pour une cha√Æne connue
                            if (
                                is_valid
                                and ip # Make sure we have an IP
                                and channel
                                and channel != "master_playlist"
                                and hasattr(self.manager, "channels")
                                and channel in self.manager.channels
                            ):
                                if request_type == "segment":
                                    # 1. Enregistrer l'activit√© dans TimeTracker
                                    try:
                                        segment_duration = self.manager.get_channel_segment_duration(channel)
                                        if segment_duration and isinstance(segment_duration, (int, float)) and segment_duration > 0:
                                            expiry_duration = segment_duration * 1.2
                                            self.time_tracker.record_activity(ip, channel, expiry_duration=expiry_duration)
                                            logger.debug(f"[{channel}] Activity recorded for {ip} (expiry: {expiry_duration:.1f}s)")
                                        else:
                                            self.time_tracker.record_activity(ip, channel)
                                            logger.debug(f"[{channel}] Activity recorded for {ip} (default expiry)")
                                    except AttributeError:
                                        logger.error(f"[{channel}] Manager missing 'get_channel_segment_duration' method.")
                                        self.time_tracker.record_activity(ip, channel)
                                    except Exception as e:
                                        logger.error(f"[{channel}] Error recording activity for {ip}: {e}")
                                        self.time_tracker.record_activity(ip, channel)
                                    
                                    # 2. G√©rer la mise √† jour de statut (potentiellement double)
                                    self._handle_channel_activity_update(ip, channel)
                                    
                                elif request_type == "playlist":
                                    # Also record activity for playlist requests with default timeout
                                    logger.debug(f"[{channel}] Recording playlist activity for {ip}")
                                    self.time_tracker.record_activity(ip, channel)
                                    
                                    # Also update status for playlist requests to keep viewers active
                                    self._handle_channel_activity_update(ip, channel)

                            # The following condition is now redundant and should be removed
                            # elif is_valid and channel and request_type == "playlist":
                            #    logger.debug(f"Ignoring playlist request for status update: {channel} by {ip}")

                        except Exception as e:
                            logger.error(f"‚ùå Erreur traitement ligne HLS: {e}")
                            logger.error(f"LIGNE: {line[:200]}...")

            except Exception as e:
                logger.error(f"‚ùå Erreur suivi logs (boucle externe): {e}")
                import traceback
                logger.error(traceback.format_exc())
                time.sleep(5)

    def _handle_channel_activity_update(self, ip: str, current_channel: str):
        """Handles the status update when activity is detected for an IP on a channel."""
        previous_channel = None
        try:
            with self.lock:
                # Get previous channel for this IP, if known
                watcher_data = self.watchers.get(ip)
                if watcher_data:
                    previous_channel = watcher_data.get('current_channel')
                    # Update watcher's current channel and last seen time
                    watcher_data['current_channel'] = current_channel
                    watcher_data['last_activity'] = time.time() # Use last_activity consistent with _update_watcher
                    watcher_data['last_seen'] = time.time()
                else:
                    # Maybe add the watcher if completely new? Or rely on _update_watcher?
                    # For now, let's assume _update_watcher handles new watchers.
                    logger.warning(f"[_handle_channel_activity_update] Watcher {ip} not found in self.watchers, cannot determine previous channel.")

            # Force TimeTracker cleanup to ensure inactive viewers are removed immediately
            if hasattr(self, 'time_tracker') and self.time_tracker:
                logger.info(f"üßπ Forcing immediate cleanup due to channel activity")
                # Reset _last_cleanup_time to ensure it runs
                self.time_tracker._last_cleanup_time = 0
                self.time_tracker.cleanup_inactive_watchers()

            # If the channel changed, update the status of the PREVIOUS channel first
            if previous_channel and previous_channel != current_channel:
                logger.info(f"üîÑ Detected channel change for {ip}: {previous_channel} -> {current_channel}. Pushing status update for {previous_channel}.")
                self._push_tracker_status_to_manager(previous_channel)
            
            # Always push the status for the CURRENT channel where activity was detected
            logger.debug(f"Activity detected for {ip} on {current_channel}. Pushing status update.")
            self._push_tracker_status_to_manager(current_channel)

        except Exception as e:
            logger.error(f"‚ùå Erreur dans _handle_channel_activity_update pour ip={ip}, channel={current_channel}: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _push_tracker_status_to_manager(self, channel: str):
        """Gets current status from TimeTracker and pushes it to the manager."""
        try:
            if not self.update_watchers:
                logger.warning(f"[{channel}] Callback update_watchers non disponible.")
                return

            # Log TimeTracker state before getting watchers
            logger.info(f"[{channel}] üîç Getting watchers from TimeTracker (timeouts: {getattr(self.time_tracker, '_segment_timeout', 'N/A')}s)")
            
            active_watchers = self.time_tracker.get_active_watchers(channel, include_buffer=True)
            calculated_count = len(active_watchers)
            active_ips_list = list(active_watchers)

            # Always log this information for debugging
            if calculated_count > 0:
                logger.info(f"[{channel}] üìä Current status: {calculated_count} viewers - IPs: {active_ips_list}")
            else:
                logger.info(f"[{channel}] üìä No active viewers detected")

            # Pass source='tracker' to ensure it passes the gatekeeper
            self.update_watchers(channel, calculated_count, active_ips_list, "/hls/", source='tracker')
            logger.info(f"[{channel}] ‚úÖ Status pushed to manager (watchers: {calculated_count})")

        except Exception as e:
            logger.error(f"‚ùå Erreur dans _push_tracker_status_to_manager pour {channel}: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _update_channel_status(self, initial_call=False):
        """Update channel status for dashboard"""
        try:
            if not self.channel_status:
                logger.warning("‚ö†Ô∏è Channel status manager not initialized")
                return False
                
            # Ensure stats directory exists and has proper permissions
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            try:
                os.chmod(stats_dir, 0o777)
            except Exception as chmod_err:
                logger.warning(f"Could not chmod stats dir {stats_dir}: {chmod_err}")

            # Load current channel stats
            channel_stats_file = Path("/app/stats/channel_stats.json")
            if not channel_stats_file.exists():
                logger.error("‚ùå Channel stats file not found")
                return False

            try:
                with open(channel_stats_file, 'r') as f:
                    stats_data = json.load(f)
            except Exception as e:
                logger.error(f"‚ùå Error loading channel stats: {e}")
                return False

            # Prepare channel status data
            channels_dict = {}
            total_viewers = 0

            # Use scan_lock for iterating self.manager.channels safely
            with self.manager.scan_lock:
                for channel_name, channel in self.manager.channels.items():
                    if channel and hasattr(channel, 'is_ready'):
                        # Get current watchers from TimeTracker
                        active_watchers = self.time_tracker.get_active_watchers(channel_name, include_buffer=True)
                        watcher_count = len(active_watchers)
                        total_viewers += watcher_count

                        # Get stats from channel_stats.json
                        channel_stats = stats_data.get("channels", {}).get(channel_name, {})
                        unique_viewers = channel_stats.get("unique_viewers", [])
                        watchlist = channel_stats.get("watchlist", {})

                        status_data = {
                            "active": channel.is_ready(),
                            "streaming": channel.is_streaming() if hasattr(channel, 'is_streaming') else False,
                            "viewers": watcher_count,
                            "watchers": list(active_watchers),
                            "unique_viewers": unique_viewers,
                            "total_watch_time": channel_stats.get("total_watch_time", 0),
                            "watchlist": watchlist
                        }
                        channels_dict[channel_name] = status_data

            # If no channels are ready or available, don't wipe the status
            if not channels_dict:
                log_key = "_last_no_channels_log_time"
                now = time.time()
                if not hasattr(self, log_key) or now - getattr(self, log_key) > 60:
                    logger.info("ü§∑ No initialized channels found, skipping status update.")
                    setattr(self, log_key, now)
                return True

            # Update status with retry logic
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    # Call the method responsible for writing the combined status
                    success = self.channel_status.update_all_channels(channels_dict)
                    if success:
                        logger.debug(f"‚úÖ Channel status file updated successfully ({'initial' if initial_call else 'periodic'})")
                        return True
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status file (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error calling channel_status.update_all_channels (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to update channel status file after all retries")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error in _update_channel_status: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _status_update_loop(self):
        # ... existing code ...
        pass

    def init_channel_status_manager(self):
        """Initialize the channel status manager for dashboard"""
        try:
            # Si d√©j√† initialis√©, ne pas r√©initialiser
            if self.channel_status is not None:
                logger.info("‚ÑπÔ∏è Channel status manager d√©j√† initialis√©, skip")
                return

            logger.info("üöÄ Initialisation du gestionnaire de statuts des cha√Ænes")
            
            # Cr√©er le dossier stats s'il n'existe pas
            stats_dir = Path(os.path.dirname(CHANNELS_STATUS_FILE))
            stats_dir.mkdir(parents=True, exist_ok=True)
            # Use relaxed permissions here too
            try:
                os.chmod(stats_dir, 0o777)
            except Exception as chmod_err:
                 logger.warning(f"Could not chmod stats dir {stats_dir}: {chmod_err}")
            
            # Cr√©er le fichier de statut s'il n'existe pas ou est vide/invalide
            should_create_file = True
            if os.path.exists(CHANNELS_STATUS_FILE):
                try:
                    if os.path.getsize(CHANNELS_STATUS_FILE) > 0:
                         with open(CHANNELS_STATUS_FILE, 'r') as f:
                             json.load(f) # Try to parse existing json
                         should_create_file = False # File exists and is valid JSON
                    # else: file exists but is empty, will overwrite
                except (json.JSONDecodeError, OSError) as e:
                     logger.warning(f"Existing status file {CHANNELS_STATUS_FILE} is invalid or unreadable ({e}). Will overwrite.")
                     # File exists but is invalid, will overwrite
                     
            if should_create_file:
                 logger.info(f"Creating/Overwriting initial status file: {CHANNELS_STATUS_FILE}")
                 with open(CHANNELS_STATUS_FILE, 'w') as f:
                     # Initial state with 0 viewers
                     json.dump({
                         'channels': {},
                         'last_updated': int(time.time()),
                         'active_viewers': 0
                     }, f, indent=2)
                 try:
                     os.chmod(CHANNELS_STATUS_FILE, 0o666)
                 except Exception as chmod_err:
                     logger.warning(f"Could not chmod status file {CHANNELS_STATUS_FILE}: {chmod_err}")
            
            # Initialiser le gestionnaire de statuts
            from channel_status_manager import ChannelStatusManager
            self.channel_status = ChannelStatusManager(
                status_file=CHANNELS_STATUS_FILE
            )
            
            # Faire une mise √† jour initiale avec retry, PASSING initial_call=True
            max_retries = 3
            retry_delay = 1
            
            for attempt in range(max_retries):
                try:
                    # Pass initial_call=True here
                    success = self._update_channel_status(initial_call=True)
                    if success:
                        logger.info("‚úÖ Channel status manager initialized for dashboard (initial status set)")
                        return
                    else:
                        logger.warning(f"‚ö†Ô∏è Failed to update channel status during init (attempt {attempt + 1}/{max_retries})")
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay)
                except Exception as e:
                    logger.error(f"‚ùå Error calling _update_channel_status during init (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        time.sleep(retry_delay)
            
            logger.error("‚ùå Failed to initialize channel status manager after all retries")
            self.channel_status = None
            
        except Exception as e:
            logger.error(f"‚ùå Error initializing channel status manager: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.channel_status = None

    def _check_channels_timeout(self):
        # ... rest of the file ...
        pass

    def force_status_update(self):
        """Debug method to force update all channels status from TimeTracker to the JSON file."""
        logger.info("üîç [DEBUG] Forcing status update for all channels")
        
        try:
            if not hasattr(self, "manager") or not self.manager:
                logger.error("‚ùå Manager not available for status update")
                return False
                
            if not hasattr(self, "time_tracker") or not self.time_tracker:
                logger.error("‚ùå TimeTracker not available for status update")
                return False
                
            # Get all channels with active watchers from TimeTracker
            active_channels = set()
            if hasattr(self.time_tracker, "_active_segments"):
                for channel in self.time_tracker._active_segments:
                    if channel and channel != "master_playlist":
                        active_channels.add(channel)
                        
            # Add all known channels from manager
            if hasattr(self.manager, "channels"):
                for channel_name in self.manager.channels:
                    if channel_name and channel_name != "master_playlist":
                        active_channels.add(channel_name)
                        
            logger.info(f"üîç [DEBUG] Found {len(active_channels)} channels to update: {sorted(list(active_channels))}")
            
            # Push updates for all channels
            for channel in sorted(active_channels):
                logger.info(f"üîç [DEBUG] Forcing update for channel: {channel}")
                self._push_tracker_status_to_manager(channel)
                
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error in force_status_update: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False