#!/usr/bin/env python3
# stuck_stream_monitor.py - Outil de d√©tection et r√©paration des streams bloqu√©s
# √Ä ex√©cuter via crontab, par exemple:

import os
import sys
import time
import psutil
import signal
import logging
import subprocess
from pathlib import Path

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - [%(levelname)s] - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("/app/logs/stream_monitor.log"),
    ],
)
logger = logging.getLogger("STREAM_MONITOR")

# Configuration
TIMEOUT_NO_VIEWERS = int(os.getenv("TIMEOUT_NO_VIEWERS", "3600"))  # 1h par d√©faut
HLS_DIR = "/app/hls"
ADDITIONAL_TIMEOUT = 1800  # 30 minutes suppl√©mentaires de gr√¢ce


def get_ffmpeg_processes():
    """Identifie tous les processus FFmpeg et leurs cha√Ænes associ√©es"""
    ffmpeg_procs = {}

    for proc in psutil.process_iter(["pid", "name", "cmdline", "create_time"]):
        try:
            if proc.info["name"] and "ffmpeg" in proc.info["name"].lower():
                cmd_line = " ".join(proc.info["cmdline"] or [])
                
                # Recherche du pattern /hls/{channel}/
                import re
                channel_match = re.search(r'/hls/([^/]+)/', cmd_line)
                
                if channel_match:
                    channel_name = channel_match.group(1)
                    proc_info = {
                        "pid": proc.info["pid"],
                        "cmdline": cmd_line,
                        "runtime": time.time() - proc.info["create_time"],
                        "channel": channel_name
                    }
                    
                    if channel_name not in ffmpeg_procs:
                        ffmpeg_procs[channel_name] = []
                    
                    ffmpeg_procs[channel_name].append(proc_info)
        
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    return ffmpeg_procs


def check_channel_activity(channel_name):
    """V√©rifie si une cha√Æne a des viewers actifs et d√©tecte les probl√®mes de transition"""
    hls_path = Path(HLS_DIR) / channel_name
    
    # Si le dossier HLS n'existe pas, certainement pas d'activit√©
    if not hls_path.exists():
        return False
    
    # V√©rifie les segments .ts pour estimer l'activit√©
    segments = list(hls_path.glob("*.ts"))
    if not segments:
        logger.warning(f"[{channel_name}] Aucun segment trouv√©")
        return False
    
    # V√©rifie l'√¢ge du segment le plus r√©cent
    newest_segment = max(segments, key=lambda p: p.stat().st_mtime)
    segment_age = time.time() - newest_segment.stat().st_mtime
    
    # V√©rification plus stricte pour les segments r√©cents
    if segment_age > 30:  # R√©duit √† 30 secondes au lieu de 60
        logger.warning(f"[{channel_name}] Dernier segment vieux de {segment_age:.1f}s")
        return False
    
    # V√©rification des probl√®mes de transition vid√©o
    try:
        # 1. V√©rifier la playlist m3u8
        playlist_path = hls_path / "playlist.m3u8"
        if not playlist_path.exists():
            logger.warning(f"[{channel_name}] playlist.m3u8 introuvable")
            return False
        
        # Analyser la playlist pour extraire les segments r√©f√©renc√©s
        with open(playlist_path, "r") as f:
            playlist_lines = f.readlines()
        
        referenced_segments = []
        for line in playlist_lines:
            if line.strip().endswith(".ts"):
                referenced_segments.append(line.strip())
        
        if not referenced_segments:
            logger.warning(f"[{channel_name}] Aucun segment r√©f√©renc√© dans la playlist")
            return False
        
        # 2. V√©rifier les segments manquants (plus sensible: 20% au lieu de 30%)
        missing_segments = []
        for segment_name in referenced_segments:
            segment_path = hls_path / segment_name
            if not segment_path.exists():
                missing_segments.append(segment_name)
        
        # Si plus de 20% des segments r√©f√©renc√©s sont manquants, c'est un probl√®me
        if missing_segments:
            missing_percent = (len(missing_segments) / len(referenced_segments)) * 100
            if missing_percent > 20:  # Seuil r√©duit √† 20%
                logger.warning(f"[{channel_name}] ‚ö†Ô∏è {missing_percent:.1f}% des segments r√©f√©renc√©s sont manquants ({len(missing_segments)}/{len(referenced_segments)})")
                return False
        
        # 3. V√©rifier les sauts dans la num√©rotation des segments
        segment_numbers = []
        for seg in segments:
            try:
                # Extrait le num√©ro du segment √† partir du nom de fichier (ex: "segment_123.ts" -> 123)
                num = int(seg.stem.split('_')[1])
                segment_numbers.append((num, seg))
            except (ValueError, IndexError):
                continue
        
        if segment_numbers:
            # Tri par num√©ro de segment
            segment_numbers.sort(key=lambda x: x[0])
            
            # V√©rification des sauts dans la num√©rotation (plus sensible: 3 au lieu de 5)
            jumps = []
            for i in range(1, len(segment_numbers)):
                current_num = segment_numbers[i][0]
                prev_num = segment_numbers[i-1][0]
                gap = current_num - prev_num
                if gap > 3:  # Saut de plus de 3 segments (√©tait 5)
                    jumps.append((prev_num, current_num, gap))
            
            # V√©rifier aussi les dates de modification pour d√©tecter les saccades
            timestamp_jumps = []
            for i in range(1, len(segment_numbers)):
                current_segment = segment_numbers[i][1]
                prev_segment = segment_numbers[i-1][1]
                
                current_mtime = current_segment.stat().st_mtime
                prev_mtime = prev_segment.stat().st_mtime
                
                # Si l'√©cart temporel entre segments est anormal (> 5 secondes au lieu de 3)
                # Les √©carts de 3-5s peuvent √™tre normaux pour certaines cha√Ænes
                if current_mtime - prev_mtime > 5:
                    timestamp_jumps.append((
                        segment_numbers[i-1][0],
                        segment_numbers[i][0],
                        round(current_mtime - prev_mtime, 1)
                    ))
            
            # Si on a des sauts significatifs r√©cents ou des √©carts temporels anormaux
            recent_jumps = []
            if segment_numbers:
                # Segments r√©cents = 3 derniers segments (au lieu de 5)
                # Se concentrer sur les derniers segments pour √©viter les faux positifs
                latest_segments = segment_numbers[-3:] if len(segment_numbers) > 3 else segment_numbers
                latest_nums = [num for num, _ in latest_segments]
                
                # V√©rifier les sauts de num√©rotation r√©cents
                recent_jumps = [j for j in jumps if j[1] in latest_nums]
                
                # V√©rifier les sauts temporels r√©cents, mais seulement s'ils sont importants (> 8s)
                recent_timestamp_jumps = [j for j in timestamp_jumps if j[1] in latest_nums and j[2] > 8]
                
                # Si on a des probl√®mes r√©cents, signaler
                if recent_jumps:
                    jump_str = ", ".join([f"{prev}->{curr} (gap:{gap})" for prev, curr, gap in recent_jumps])
                    logger.warning(f"[{channel_name}] üö® Sauts de segments r√©cents: {jump_str}")
                    return False
                
                if recent_timestamp_jumps:
                    jump_str = ", ".join([f"{prev}->{curr} (temps:{gap}s)" for prev, curr, gap in recent_timestamp_jumps])
                    logger.warning(f"[{channel_name}] üö® Sauts temporels anormaux importants: {jump_str}")
                    return False
            
            # 4. V√©rifier les tailles des segments (pour d√©tecter les segments corrompus)
            segment_sizes = []
            for _, segment in segment_numbers:
                segment_sizes.append(segment.stat().st_size)
            
            # Calculer la taille moyenne
            if segment_sizes:
                avg_size = sum(segment_sizes) / len(segment_sizes)
                
                # V√©rifier les segments anormalement petits (< 30% de la moyenne)
                small_segments = []
                for i, (num, segment) in enumerate(segment_numbers):
                    if segment.stat().st_size < avg_size * 0.3:  # Segment anormalement petit
                        small_segments.append((num, segment.stat().st_size, round(segment.stat().st_size / avg_size * 100)))
                
                # Si les segments r√©cents sont anormalement petits
                recent_small_segments = []
                for small_seg in small_segments:
                    if small_seg[0] in latest_nums:
                        recent_small_segments.append(small_seg)
                
                if recent_small_segments:
                    small_str = ", ".join([f"segment_{num} ({size}B, {percent}%)" for num, size, percent in recent_small_segments])
                    logger.warning(f"[{channel_name}] üö® Segments anormalement petits d√©tect√©s: {small_str}")
                    return False
                    
        # 5. V√©rifier les logs d'erreur nginx pour les probl√®mes de ce flux
        try:
            error_cmd = f"tail -n 100 /app/nginx_logs/error.log | grep -i '{channel_name}' | grep -i 'no such file' | wc -l"
            error_result = subprocess.run(error_cmd, shell=True, capture_output=True, text=True)
            error_count = int(error_result.stdout.strip() or '0')
            
            if error_count > 3:  # Plusieurs erreurs r√©centes dans les logs
                logger.warning(f"[{channel_name}] üö® {error_count} erreurs nginx 'no such file' r√©centes")
                return False
        except Exception as e:
            logger.debug(f"[{channel_name}] Erreur v√©rification logs nginx: {e}")
    
    except Exception as e:
        logger.error(f"[{channel_name}] Erreur analyse segments: {e}")
    
    # Si on arrive ici, l'activit√© semble normale
    return True


def kill_processes(pids):
    """Tue les processus par PID avec un d√©lai entre chaque"""
    for pid in pids:
        try:
            os.kill(pid, signal.SIGTERM)
            logger.info(f"Signal SIGTERM envoy√© au processus {pid}")
            
            # Attendre un peu pour voir si le processus termine proprement
            time.sleep(1)
            
            # V√©rifier si le processus existe toujours
            if psutil.pid_exists(pid):
                # Si toujours en vie, envoyer SIGKILL
                os.kill(pid, signal.SIGKILL)
                logger.info(f"Signal SIGKILL envoy√© au processus {pid}")
            
            time.sleep(0.5)  # Petit d√©lai entre les processus
            
        except (ProcessLookupError, PermissionError) as e:
            logger.error(f"Erreur suppression du processus {pid}: {e}")


def main():
    """Fonction principale de d√©tection et correction"""
    logger.info("=== D√©but de la v√©rification des streams bloqu√©s ===")
    
    try:
        # R√©cup√®re tous les processus FFmpeg
        ffmpeg_processes = get_ffmpeg_processes()
        logger.info(f"Trouv√© {len(ffmpeg_processes)} cha√Ænes avec des processus FFmpeg")
        
        killed_count = 0
        restart_count = 0
        for channel_name, processes in ffmpeg_processes.items():
            # V√©rifier si la cha√Æne a une activit√© r√©cente et des probl√®mes de transition
            has_activity = check_channel_activity(channel_name)
            process_count = len(processes)
            
            # Si plusieurs processus pour la m√™me cha√Æne, c'est un probl√®me
            if process_count > 1:
                logger.warning(f"[{channel_name}] D√©tect√© {process_count} processus FFmpeg - conflit")
                
                # Trier par runtime (garder le plus r√©cent, tuer les autres)
                processes.sort(key=lambda p: p["runtime"])
                
                # Garder le plus r√©cent, tuer les autres
                pids_to_kill = [p["pid"] for p in processes[:-1]]
                logger.info(f"[{channel_name}] Suppression des {len(pids_to_kill)} processus les plus anciens")
                kill_processes(pids_to_kill)
                killed_count += len(pids_to_kill)
            
            # V√©rifier si l'activit√© est valide
            if not has_activity:
                # 1. V√©rifier si c'est un processus zombie (longue dur√©e sans activit√©)
                oldest_process = max(processes, key=lambda p: p["runtime"])
                runtime_hours = oldest_process["runtime"] / 3600
                
                # 2. V√©rifier s'il y a des viewers actifs
                has_viewers = check_channel_has_viewers(channel_name)
                
                # Si le processus est bloqu√© ou en erreur de transition
                if runtime_hours > (TIMEOUT_NO_VIEWERS + ADDITIONAL_TIMEOUT) / 3600:
                    logger.warning(
                        f"[{channel_name}] Processus bloqu√© d√©tect√©: {oldest_process['pid']} "
                        f"(dur√©e: {runtime_hours:.1f}h sans activit√©)"
                    )
                    
                    # Tuer ce processus
                    pids_to_kill = [p["pid"] for p in processes]
                    logger.info(f"[{channel_name}] Arr√™t forc√© des {len(pids_to_kill)} processus")
                    kill_processes(pids_to_kill)
                    killed_count += len(pids_to_kill)
                    
                    # Red√©marrer le processus si n√©cessaire
                    if has_viewers:
                        if restart_channel(channel_name):
                            restart_count += 1
                
                # 3. Si probl√®me de transition avec des viewers actifs, red√©marrer
                elif has_viewers:
                    logger.warning(f"[{channel_name}] Probl√®me de transition d√©tect√© avec viewers actifs")
                    
                    # On red√©marre le stream pour corriger les probl√®mes de transition
                    pids_to_kill = [p["pid"] for p in processes]
                    logger.info(f"[{channel_name}] Red√©marrage forc√© pour probl√®me de transition")
                    kill_processes(pids_to_kill)
                    killed_count += len(pids_to_kill)
                    
                    # Attendre un peu avant de red√©marrer
                    time.sleep(2)
                    
                    # Red√©marrer le processus
                    if restart_channel(channel_name):
                        restart_count += 1
                
                # 4. Si c'est la cha√Æne verite ou d'autres cha√Ænes sp√©cifiques avec probl√®mes r√©currents
                elif channel_name in ["verite", "lahaine", "defunes"]:
                    logger.warning(f"[{channel_name}] ‚ö†Ô∏è Cha√Æne connue pour avoir des probl√®mes de transition - red√©marrage forc√© m√™me sans viewers")
                    
                    # On red√©marre le stream pour corriger les probl√®mes de transition
                    pids_to_kill = [p["pid"] for p in processes]
                    logger.info(f"[{channel_name}] Red√©marrage forc√© pour cha√Æne probl√©matique")
                    kill_processes(pids_to_kill)
                    killed_count += len(pids_to_kill)
                    
                    # Attendre un peu avant de red√©marrer
                    time.sleep(2)
                    
                    # Red√©marrer le processus
                    if restart_channel(channel_name):
                        restart_count += 1
        
        logger.info(f"=== Fin de la v√©rification: {killed_count} processus termin√©s, {restart_count} streams red√©marr√©s ===")
        return 0
        
    except Exception as e:
        logger.error(f"Erreur dans le script de monitoring: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return 1


def check_channel_has_viewers(channel_name):
    """V√©rifie si une cha√Æne a des viewers actifs en consultant les logs d'acc√®s"""
    try:
        # V√©rifier les logs nginx pour des acc√®s r√©cents
        cmd = f"tail -n 500 /app/nginx_logs/access.log | grep -i '{channel_name}' | grep -v 'playlist.m3u8' | wc -l"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        # Compte les acc√®s r√©cents aux segments .ts
        access_count = int(result.stdout.strip() or '0')
        
        # Si on a des acc√®s r√©cents, il y a probablement des viewers
        logger.info(f"[{channel_name}] - nombre d'acc√®s r√©cents : {access_count}")
        return access_count > 0
        
    except Exception as e:
        logger.error(f"[{channel_name}] Erreur v√©rification viewers: {e}")
        return False


def restart_channel(channel_name):
    """Relance un flux pour une cha√Æne sp√©cifique via l'API client_monitor"""
    try:
        # On appelle un process Python directement plut√¥t qu'une API
        cmd = f"python3 /app/restart_channel.py {channel_name}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info(f"[{channel_name}] ‚úÖ Stream relanc√© avec succ√®s")
            return True
        else:
            logger.error(f"[{channel_name}] ‚ùå Erreur relance: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"[{channel_name}] ‚ùå Erreur restart_channel: {e}")
        return False


if __name__ == "__main__":
    sys.exit(main())